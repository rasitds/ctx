---
title: "ctx v0.3.0: The Discipline Release"
date: 2026-02-15
author: Jose Alekhinne
topics:
  - release
  - skills migration
  - consolidation
  - code quality
  - E/A/R framework
---

# ctx v0.3.0: The Discipline Release

![ctx](../images/ctx-banner.png)

## When the Ratio of Polish to Features Is 3:1, You Know Something Changed

*Jose Alekhinne / February 15, 2026*

!!! question "What does a release look like when most of the work is invisible?"
    No new headline feature. No architectural pivot. No rewrite.

    Just **35+ documentation and quality commits** against **~15 feature
    commits** -- and somehow, the tool feels like it grew up overnight.

Six days separate v0.2.0 from v0.3.0. Measured by calendar time, it is
nothing. Measured by what changed in how the project operates, it is
the most significant release yet.

v0.1.0 was the prototype. v0.2.0 was the [archaeology release][v020] --
making the past accessible. v0.3.0 is the **discipline release**:
the one that turned best practices into enforcement, suggestions into
structure, and a collection of commands into a system of skills.

[v020]: 2026-02-01-ctx-v0.2.0-the-archaeology-release.md

!!! info "The Release Window"
    **February 1 -- February 7, 2026**

    From the v0.2.0 tag to commit `2227f99`.
    78 files changed in the migration commit alone.

## The Migration: Commands to Skills

The largest single change was the migration from `.claude/commands/*.md`
to `.claude/skills/*/SKILL.md`.

This was not a rename. It was a rethinking of how AI agents discover
and execute project-specific workflows.

| Aspect          | Commands (before)              | Skills (after)                        |
|-----------------|--------------------------------|---------------------------------------|
| Structure       | Flat files in one directory    | Directory-per-skill with SKILL.md     |
| Description     | Optional, often vague          | Required, doubles as activation trigger |
| Quality gates   | None                           | "Before X-ing" pre-flight checklist   |
| Negative triggers | None                         | "When NOT to Use" in every skill      |
| Examples        | Rare                           | Good/bad pairs in every skill         |
| Average length  | ~15 lines                      | ~80 lines                             |

The description field became the single most important line in each
skill. In the old system, descriptions were titles. In the new system,
they are **activation conditions** -- the text the platform reads to
decide whether to surface a skill for a given prompt.

A description that says "Show context summary" activates too broadly
or not at all. A description that says "Show context summary. Use at
session start or when unclear about current project state" activates
at the right moment.

**78 files changed. 1,915 insertions.** Not because the skills got
bloated -- because they got *specific*.

## The Skill Sweep

After the structural migration, every skill was rewritten in a single
session. All 21 of them.

The rewrite was guided by a pattern that emerged during the process
itself -- a repeatable anatomy that effective skills share regardless
of their purpose:

1. **Before X-ing**: Pre-flight checks that prevent premature execution
2. **When to Use**: Positive triggers that narrow activation
3. **When NOT to Use**: Negative triggers that prevent misuse
4. **Usage Examples**: Invocation patterns the agent can pattern-match
5. **Quality Checklist**: Verification before claiming completion

The [Anatomy of a Skill That Works][anatomy] post covers the details.
What matters for the release story is the *result*: zero skills with
quality gates became twenty. Zero skills with negative triggers became
twenty. Three skills with examples became twenty.

[anatomy]: 2026-02-07-the-anatomy-of-a-skill-that-works.md

!!! tip "The Skill Trilogy as Design Spec"
    The three blog posts written during this window -- [Skills That Fight
    the Platform][fight], [You Can't Import Expertise][import], and
    [The Anatomy of a Skill That Works][anatomy] -- were not
    retrospective documentation. They were written *during* the rewrite,
    and the lessons fed back into the skills as they were being built.

    The blog was the design document. The skills were the implementation.

[fight]: 2026-02-04-skills-that-fight-the-platform.md
[import]: 2026-02-05-you-cant-import-expertise.md

## The Consolidation Sweep

The unglamorous work. The kind you only appreciate when you try to
change something later and it *just works*.

| What                    | Why It Matters                                   |
|-------------------------|--------------------------------------------------|
| Constants consolidation | Magic strings replaced with semantic constants   |
| Variable deshadowing    | Eliminated subtle scoping bugs                   |
| File splits             | Modules that were doing too much, broken apart   |
| Godoc standardization   | Every exported function documented to convention |

This is the work that doesn't get a changelog entry but makes every
future commit easier. When a new contributor (human or AI) reads the
codebase, they find consistent patterns instead of accumulated drift.

The consolidation was not an afterthought. It was scheduled --
deliberately, with the same priority as features. The
[3:1 ratio][refactor] that emerged during v0.2.0 development became an
explicit practice: three feature sessions, one consolidation session.

[refactor]: 2026-02-01-refactoring-with-intent.md

## The E/A/R Framework

On February 4th, we adopted the **E/A/R classification** as the
official standard for evaluating skills:

| Category      | Meaning                        | Target    |
|---------------|--------------------------------|-----------|
| **Expert**    | Knowledge Claude does not have | >70%      |
| **Activation**| When/how to trigger            | ~20%      |
| **Redundant** | What Claude already knows      | <10%      |

This came from reviewing approximately 30 external skill files and
discovering that most were redundant with Claude's built-in system
prompt. Only about 20% had salvageable content, and even those yielded
just a few heuristics each.

The E/A/R framework gave us a concrete, testable criterion: **a good
skill is Expert knowledge minus what Claude already knows.** If more
than 10% of a skill restates platform defaults, it is creating noise,
not signal.

Every skill in v0.3.0 was evaluated against this framework. Several
were deleted. The survivors are leaner and more focused.

## Backup and Monitoring Infrastructure

A tool that manages your project's memory needs ops maturity. v0.3.0
added two pieces of infrastructure that reflect this:

**Backup staleness hook**: A `UserPromptSubmit` hook that checks
whether the last `.context/` backup is more than two days old. If it
is, and the SMB mount is available, it reminds the user. No cron
job running when nobody is working. No redundant backups when nothing
has changed.

**Context size checkpoint**: A `PreToolUse` hook that estimates current
context window usage and warns when the session is getting heavy. This
hooks into the attention budget philosophy -- degradation is expected,
but it should be *visible*.

Both hooks use `$CLAUDE_PROJECT_DIR` instead of hardcoded paths, a
migration triggered by a username rename that broke every absolute path
in the hook configuration. That migration -- replacing `/home/user/...`
with `"$CLAUDE_PROJECT_DIR"/.claude/hooks/...` -- was one of those
changes that seems trivial but prevents an entire category of future
failures.

## The Numbers

| Metric                         | v0.2.0    | v0.3.0    |
|--------------------------------|-----------|-----------|
| Skills (was "commands")        | 11        | 21        |
| Skills with quality gates      | 0         | 21        |
| Skills with "When NOT to Use"  | 0         | 21        |
| Average skill body             | ~15 lines | ~80 lines |
| Hooks using $CLAUDE_PROJECT_DIR| 0         | All       |
| Documentation commits          | --        | 35+       |
| Feature/fix commits            | --        | ~15       |

That ratio -- 35+ documentation and quality commits to ~15 feature
commits -- is the defining characteristic of this release. It is not
a failure to ship features. It is the *deliberate choice* to make the
existing features reliable.

## What v0.3.0 Means

v0.1.0 asked: "Can we give AI persistent memory?"

v0.2.0 asked: "Can we make that memory accessible to humans too?"

v0.3.0 asks a different question: "Can we make the quality
*self-enforcing*?"

The answer is not a feature. It is a practice:

- Skills with quality gates enforce pre-flight checks.
- Negative triggers prevent misuse without human intervention.
- The E/A/R framework ensures skills contain signal, not noise.
- Consolidation sessions are scheduled, not improvised.
- Hook infrastructure makes degradation visible.

**Discipline is not the absence of velocity. It is the infrastructure
that makes velocity sustainable.**

## What Comes Next

The skill system is now mature enough to support real workflows without
constant human correction. The hooks infrastructure is portable and
resilient. The consolidation practice is documented and repeatable.

The next chapter is about what you build *on top of* discipline:
multi-agent coordination, deeper integration patterns, and the question
of whether context management is a tool concern or an infrastructure
concern.

But those are future posts.

This one is about the release that proved **polish is not the opposite
of progress**. It is what turns a prototype into a product.

---

!!! quote "The Discipline Release"
    v0.1.0 shipped features. v0.2.0 shipped archaeology.
    v0.3.0 shipped **the habits that make everything else trustworthy**.

    The most important code in this release is the code that
    **prevents bad code from shipping**.

---

*This post was drafted using `/ctx-blog` with access to the full git
history between v0.2.0 and v0.3.0, decision logs, learning logs, and
the session files from the skill rewrite window. The meta continues.*
