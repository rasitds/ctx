{"config":{"separator":"[\\s\\-_,:!=\\[\\]()\\\\\"`/]+|\\.(?!\\d)"},"items":[{"location":"","level":1,"title":"Getting Started","text":"","path":["Getting Started"],"tags":[]},{"location":"#ctx","level":2,"title":"<code>ctx</code>","text":"<p><code>ctx</code> (Context) is a file-based system that enables AI coding assistants to persist project knowledge across sessions. Instead of re-explaining your codebase every time, context files let AI tools remember decisions, conventions, and learnings:</p> <ul> <li>A session is interactive.</li> <li><code>ctx</code> enables cognitive continuity.</li> <li>Cognitive continuity enables durable, symbiotic-like human–AI workflows.</li> </ul>","path":["Getting Started"],"tags":[]},{"location":"#community","level":2,"title":"Community","text":"<p>Open source is better together.</p> <p>Help <code>ctx</code> Change How AI Remembers</p> <p>If the idea behind <code>ctx</code> resonates, a star helps it reach engineers  who run into context drift every day.</p> <p>→ https://github.com/ActiveMemory/ctx</p> <p><code>ctx</code> is free and open source software, and contributions are always welcome and appreciated.</p> <p>Join the community to ask questions, share feedback, and connect with other users:</p> <ul> <li> IRC:     join <code>#ctx</code> on <code>irc.libera.chat</code></li> <li> GitHub:   Star the repo, report issues, contribute</li> </ul>","path":["Getting Started"],"tags":[]},{"location":"#why","level":2,"title":"Why?","text":"<p>Most AI-driven development fails not because models are weak—they fail because  context is ephemeral. Every new session starts near zero:</p> <ul> <li>You re-explain architecture</li> <li>The AI repeats past mistakes</li> <li>Decisions get rediscovered instead of remembered</li> </ul> <p><code>ctx</code> solves this by treating context as infrastructure:  files that version with your code and persist across sessions.</p>","path":["Getting Started"],"tags":[]},{"location":"#installation","level":2,"title":"Installation","text":"","path":["Getting Started"],"tags":[]},{"location":"#build-from-source-recommended","level":3,"title":"Build from Source (Recommended)","text":"<p>Requires Go 1.25+:</p> <pre><code>git clone https://github.com/ActiveMemory/ctx.git\ncd ctx\nmake build\nsudo make install\n# or:\n# sudo mv ctx /usr/local/bin/\n</code></pre> <p>Building from source gives you the latest features and bug fixes. </p> <p>Since <code>ctx</code> is predominantly a developer tool, this is the  recommended approach: </p> <p>You get the freshest code and can inspect what you are installing.</p>","path":["Getting Started"],"tags":[]},{"location":"#binary-downloads","level":3,"title":"Binary Downloads","text":"<p>Pre-built binaries are available from the releases page if you prefer not to build from source.</p> Linux (x86_64)Linux (ARM64)macOS (Apple Silicon)macOS (Intel)Windows <pre><code>curl -LO https://github.com/ActiveMemory/ctx/releases/download/v0.3.0/ctx-0.3.0-linux-amd64\nchmod +x ctx-0.3.0-linux-amd64\nsudo mv ctx-0.3.0-linux-amd64 /usr/local/bin/ctx\n</code></pre> <pre><code>curl -LO https://github.com/ActiveMemory/ctx/releases/download/v0.3.0/ctx-0.3.0-linux-arm64\nchmod +x ctx-0.3.0-linux-arm64\nsudo mv ctx-0.3.0-linux-arm64 /usr/local/bin/ctx\n</code></pre> <pre><code>curl -LO https://github.com/ActiveMemory/ctx/releases/download/v0.3.0/ctx-0.3.0-darwin-arm64\nchmod +x ctx-0.3.0-darwin-arm64\nsudo mv ctx-0.3.0-darwin-arm64 /usr/local/bin/ctx\n</code></pre> <pre><code>curl -LO https://github.com/ActiveMemory/ctx/releases/download/v0.3.0/ctx-0.3.0-darwin-amd64\nchmod +x ctx-0.3.0-darwin-amd64\nsudo mv ctx-0.3.0-darwin-amd64 /usr/local/bin/ctx\n</code></pre> <p>Download <code>ctx-0.3.0-windows-amd64.exe</code> from the releases page and add it to your <code>PATH</code>.</p>","path":["Getting Started"],"tags":[]},{"location":"#verifying-checksums","level":4,"title":"Verifying Checksums","text":"<p>Each binary has a corresponding <code>.sha256</code> checksum file. To verify your download:</p> <pre><code># Download the checksum file\ncurl -LO https://github.com/ActiveMemory/ctx/releases/download/v0.3.0/ctx-0.3.0-linux-amd64.sha256\n\n# Verify the binary\nsha256sum -c ctx-0.3.0-linux-amd64.sha256\n</code></pre> <p>On macOS, use <code>shasum -a 256 -c</code> instead of <code>sha256sum -c</code>.</p> <p>Verify installation:</p> <pre><code>ctx --version\n</code></pre>","path":["Getting Started"],"tags":[]},{"location":"#version-control-strongly-recommended","level":3,"title":"Version Control (Strongly Recommended)","text":"<p><code>ctx</code> does not require git, but using version control with your <code>.context/</code> directory is strongly recommended. AI sessions occasionally modify or overwrite context files inadvertently. With git, the AI can check history and restore lost content — without it, the data is gone. Several <code>ctx</code> features (journal changelog, blog generation) also use git history directly.</p>","path":["Getting Started"],"tags":[]},{"location":"#quick-start","level":2,"title":"Quick Start","text":"","path":["Getting Started"],"tags":[]},{"location":"#1-initialize-context","level":3,"title":"1. Initialize Context","text":"<pre><code>cd your-project\nctx init\n</code></pre> <p>This creates a <code>.context/</code> directory with template files and configures  AI tool hooks (for Claude Code).</p>","path":["Getting Started"],"tags":[]},{"location":"#2-check-status","level":3,"title":"2. Check Status","text":"<pre><code>ctx status\n</code></pre> <p>Shows context summary: files present, token estimate, and recent activity.</p>","path":["Getting Started"],"tags":[]},{"location":"#3-start-using-with-ai","level":3,"title":"3. Start Using with AI","text":"<p>With Claude Code, context loads automatically via hooks. For other tools, paste the output of:</p> <pre><code>ctx agent --budget 8000\n</code></pre>","path":["Getting Started"],"tags":[]},{"location":"#4-verify-it-works","level":3,"title":"4. Verify It Works","text":"<p>Ask your AI: \"Do you remember?\"</p> <p>It should cite specific context: current tasks, recent decisions,  or previous session topics.</p>","path":["Getting Started"],"tags":[]},{"location":"#what-gets-created","level":2,"title":"What Gets Created","text":"<pre><code>.context/\n├── CONSTITUTION.md     # Hard rules — NEVER violate these\n├── TASKS.md            # Current and planned work\n├── CONVENTIONS.md      # Project patterns and standards\n├── ARCHITECTURE.md     # System overview\n├── DECISIONS.md        # Architectural decisions with rationale\n├── LEARNINGS.md        # Lessons learned, gotchas, tips\n├── GLOSSARY.md         # Domain terms and abbreviations\n├── AGENT_PLAYBOOK.md   # How AI tools should use this\n└── sessions/           # Session snapshots\n\n.claude/                # Claude Code integration (if detected)\n├── hooks/              # Auto-save and enforcement scripts\n├── skills/             # ctx Agent Skills (agentskills.io spec)\n└── settings.local.json # Hook configuration\n</code></pre> <p>See Context Files for detailed documentation of each file.</p>","path":["Getting Started"],"tags":[]},{"location":"#common-workflows","level":2,"title":"Common Workflows","text":"","path":["Getting Started"],"tags":[]},{"location":"#track-context","level":3,"title":"Track Context","text":"<pre><code># Add a task\nctx add task \"Implement user authentication\"\n\n# Record a decision (full ADR fields required)\nctx add decision \"Use PostgreSQL for primary database\" \\\n  --context \"Need a reliable database for production\" \\\n  --rationale \"PostgreSQL offers ACID compliance and JSON support\" \\\n  --consequences \"Team needs PostgreSQL training\"\n\n# Note a learning\nctx add learning \"Mock functions must be hoisted in Jest\" \\\n  --context \"Tests failed with undefined mock errors\" \\\n  --lesson \"Jest hoists mock calls to top of file\" \\\n  --application \"Place jest.mock() before imports\"\n\n# Mark task complete\nctx complete \"user auth\"\n</code></pre>","path":["Getting Started"],"tags":[]},{"location":"#check-context-health","level":3,"title":"Check Context Health","text":"<pre><code># Detect stale paths, missing files, potential secrets\nctx drift\n\n# See full context summary\nctx status\n</code></pre>","path":["Getting Started"],"tags":[]},{"location":"#browse-session-history","level":3,"title":"Browse Session History","text":"<p>Export AI session transcripts to a browsable journal site:</p> <pre><code># Export all sessions to .context/journal/\nctx recall export --all\n\n# Generate and serve the journal site\nctx journal site --serve\n</code></pre> <p>Then open http://localhost:8000.</p> <p>To update the journal after new sessions, run the same two commands again; <code>recall export</code> preserves existing YAML frontmatter and only updates conversation content.</p> <p>See Session Journal for the full pipeline including enrichment and normalization.</p>","path":["Getting Started"],"tags":[]},{"location":"#save-and-restore-sessions","level":3,"title":"Save and Restore Sessions","text":"<pre><code># Save a snapshot of current context\nctx session save \"before-refactor\"\n\n# List saved sessions\nctx session list\n\n# Load a previous session\nctx session load \"before-refactor\"\n</code></pre>","path":["Getting Started"],"tags":[]},{"location":"#run-an-autonomous-loop","level":3,"title":"Run an Autonomous Loop","text":"<p>Generate a script that iterates an AI agent until a completion signal is detected:</p> <pre><code>ctx loop\nchmod +x loop.sh\n./loop.sh\n</code></pre> <p>See Autonomous Loops for configuration and advanced usage.</p>","path":["Getting Started"],"tags":[]},{"location":"#next-steps","level":2,"title":"Next Steps","text":"<ul> <li>Prompting Guide — Effective prompts for AI sessions</li> <li>CLI Reference — All commands and options</li> <li>Context Files — File formats and structure</li> <li>Session Journal — Browse and search session history</li> <li>Autonomous Loops — Iterative AI development workflows</li> <li>Integrations — Setup for Claude Code, Cursor, Aider</li> <li>Blog — Stories and lessons from building ctx</li> </ul>","path":["Getting Started"],"tags":[]},{"location":"autonomous-loop/","level":1,"title":"Autonomous Loops","text":"","path":["Autonomous Loops"],"tags":[]},{"location":"autonomous-loop/#autonomous-ai-development","level":2,"title":"Autonomous AI Development","text":"<p>Iterate until done.</p> <p>An autonomous loop is an iterative AI development workflow where an agent works on tasks until completion—without constant human intervention. Context (<code>ctx</code>) provides the memory that makes this possible:</p> <ul> <li><code>ctx</code> provides the memory: persistent context that survives across iterations</li> <li>The loop provides the automation: continuous execution until done</li> </ul> <p>Together, they enable fully autonomous AI development where the agent remembers everything across iterations.</p> <p>Origin</p> <p>This pattern is inspired by Geoffrey Huntley's Ralph Wiggum technique. We use generic terminology here so the concepts remain clear regardless of trends.</p>","path":["Autonomous Loops"],"tags":[]},{"location":"autonomous-loop/#how-it-works","level":2,"title":"How It Works","text":"<pre><code>graph TD\n    A[Start Loop] --&gt; B[Load PROMPT.md]\n    B --&gt; C[AI reads .context/]\n    C --&gt; D[AI picks task from TASKS.md]\n    D --&gt; E[AI completes task]\n    E --&gt; F[AI updates context files]\n    F --&gt; G[AI commits changes]\n    G --&gt; H{Check signals}\n    H --&gt;|SYSTEM_CONVERGED| I[Done - all tasks complete]\n    H --&gt;|SYSTEM_BLOCKED| J[Done - needs human input]\n    H --&gt;|Continue| B</code></pre> <ol> <li>Loop reads <code>PROMPT.md</code> and invokes AI</li> <li>AI loads context from <code>.context/</code></li> <li>AI picks one task and completes it</li> <li>AI updates context files (mark task done, add learnings)</li> <li>AI commits changes</li> <li>Loop checks for completion signals</li> <li>Repeat until converged or blocked</li> </ol>","path":["Autonomous Loops"],"tags":[]},{"location":"autonomous-loop/#quick-start-shell-while-loop-recommended","level":2,"title":"Quick Start: Shell While Loop (Recommended)","text":"<p>The best way to run an autonomous loop is a plain shell script that invokes your AI tool in a fresh process on each iteration. This is \"pure ralph\": the only state that carries between iterations is what lives in <code>.context/</code> and the git history. No context window bleed, no accumulated tokens, no hidden state.</p> <p>Create a <code>loop.sh</code>:</p> <pre><code>#!/bin/bash\n# loop.sh — an autonomous iteration loop\n\nPROMPT_FILE=\"${1:-PROMPT.md}\"\nMAX_ITERATIONS=\"${2:-10}\"\nOUTPUT_FILE=\"/tmp/loop_output.txt\"\n\nfor i in $(seq 1 $MAX_ITERATIONS); do\n  echo \"=== Iteration $i ===\"\n\n  # Invoke AI with prompt\n  cat \"$PROMPT_FILE\" | claude --print &gt; \"$OUTPUT_FILE\" 2&gt;&amp;1\n\n  # Display output\n  cat \"$OUTPUT_FILE\"\n\n  # Check for completion signals\n  if grep -q \"SYSTEM_CONVERGED\" \"$OUTPUT_FILE\"; then\n    echo \"Loop complete: All tasks done\"\n    break\n  fi\n\n  if grep -q \"SYSTEM_BLOCKED\" \"$OUTPUT_FILE\"; then\n    echo \"Loop blocked: Needs human input\"\n    break\n  fi\n\n  sleep 2\ndone\n</code></pre> <p>Make it executable and run:</p> <pre><code>chmod +x loop.sh\n./loop.sh\n</code></pre> <p>You can also generate this script with <code>ctx loop</code> (see CLI Reference).</p>","path":["Autonomous Loops"],"tags":[]},{"location":"autonomous-loop/#why-a-shell-loop","level":3,"title":"Why a Shell Loop?","text":"<p>Each iteration starts a fresh AI process with zero context window history. The agent knows only what it reads from <code>.context/</code> files — exactly the information you chose to persist. This is the core Ralph principle: memory is explicit, not accidental.</p>","path":["Autonomous Loops"],"tags":[]},{"location":"autonomous-loop/#alternative-claude-codes-built-in-loop","level":2,"title":"Alternative: Claude Code's Built-in Loop","text":"<p>Claude Code has built-in loop support:</p> <pre><code># Start autonomous loop\n/loop\n\n# Cancel running loop\n/cancel-loop\n</code></pre> <p>This is convenient for quick iterations, but be aware of important caveats:</p> <p>Not Pure Ralph</p> <p>Claude Code's <code>/loop</code> runs all iterations within the same session. This means:</p> <ul> <li>State leaks between iterations. The context window accumulates   output from every previous iteration. The agent \"remembers\" things   it saw earlier — even if they were never persisted to <code>.context/</code>.</li> <li>Token budget degrades. Each iteration adds to the context window,   leaving less room for actual work in later iterations.</li> <li>Not ergonomic for long runs. Users report that the built-in loop   is less predictable for 10+ iteration runs compared to a shell loop.</li> </ul> <p>For short explorations (2-5 iterations) or interactive use, <code>/loop</code> works fine. For overnight unattended runs or anything where iteration independence matters, use the shell while loop instead.</p>","path":["Autonomous Loops"],"tags":[]},{"location":"autonomous-loop/#the-promptmd-file","level":2,"title":"The PROMPT.md File","text":"<p>The prompt file instructs the AI on how to work autonomously. Here's a template:</p> <pre><code># Autonomous Development Prompt\n\nYou are working on this project autonomously. Follow these steps:\n\n## 1. Load Context\n\nRead these files in order:\n1. `.context/CONSTITUTION.md` — NEVER violate these rules\n2. `.context/TASKS.md` — Find work to do\n3. `.context/CONVENTIONS.md` — Follow these patterns\n4. `.context/DECISIONS.md` — Understand past choices\n\n## 2. Pick One Task\n\nFrom `.context/TASKS.md`, select ONE task that is:\n- Not blocked\n- Highest priority available\n- Within your capabilities\n\n## 3. Complete the Task\n\n- Write code following conventions\n- Run tests if applicable\n- Keep changes focused and minimal\n\n## 4. Update Context\n\nAfter completing work:\n- Mark task complete in TASKS.md\n- Add any learnings to LEARNINGS.md\n- Add any decisions to DECISIONS.md\n\n## 5. Commit Changes\n\nCreate a focused commit with clear message.\n\n## 6. Signal Status\n\nEnd your response with exactly ONE of:\n\n- `SYSTEM_CONVERGED` — All tasks in TASKS.md are complete\n- `SYSTEM_BLOCKED` — Cannot proceed, need human input (explain why)\n- (no signal) — More work remains, continue to next iteration\n\n## Rules\n\n- ONE task per iteration\n- NEVER skip tests\n- NEVER violate CONSTITUTION.md\n- Commit after each task\n</code></pre>","path":["Autonomous Loops"],"tags":[]},{"location":"autonomous-loop/#completion-signals","level":2,"title":"Completion Signals","text":"<p>The loop watches for these signals in AI output:</p> Signal Meaning When to Use <code>SYSTEM_CONVERGED</code> All tasks complete No pending tasks in TASKS.md <code>SYSTEM_BLOCKED</code> Cannot proceed Needs clarification, access, or decision <code>BOOTSTRAP_COMPLETE</code> Initial setup done Project scaffolding finished","path":["Autonomous Loops"],"tags":[]},{"location":"autonomous-loop/#example-usage","level":3,"title":"Example Usage","text":"<pre><code>I've completed all tasks in TASKS.md:\n- [x] Set up project structure\n- [x] Implement core API\n- [x] Add authentication\n- [x] Write tests\n\nNo pending tasks remain.\n\nSYSTEM_CONVERGED\n</code></pre> <pre><code>I cannot proceed with the \"Deploy to production\" task because:\n- Missing AWS credentials\n- Need confirmation on region selection\n\nPlease provide credentials and confirm deployment region.\n\nSYSTEM_BLOCKED\n</code></pre>","path":["Autonomous Loops"],"tags":[]},{"location":"autonomous-loop/#why-context-loops-work-well-together","level":2,"title":"Why Context + Loops Work Well Together","text":"Without ctx With ctx Each iteration starts fresh Each iteration has full history Decisions get re-made Decisions persist in DECISIONS.md Learnings are lost Learnings accumulate in LEARNINGS.md Tasks can be forgotten Tasks tracked in TASKS.md","path":["Autonomous Loops"],"tags":[]},{"location":"autonomous-loop/#automatic-context-updates","level":3,"title":"Automatic Context Updates","text":"<p>During the loop, the AI should update context files:</p> <p>Mark task complete: <pre><code>ctx complete \"implement user auth\"\n</code></pre></p> <p>Or emit an update command (parsed by <code>ctx watch</code>): <pre><code>&lt;context-update type=\"complete\"&gt;user auth&lt;/context-update&gt;\n</code></pre></p> <p>Add learning: <pre><code>ctx add learning \"Rate limiting requires Redis connection\"\n</code></pre></p> <p>Or via update command: <pre><code>&lt;context-update type=\"learning\"&gt;Rate limiting requires Redis connection&lt;/context-update&gt;\n</code></pre></p> <p>Record decision: <pre><code>ctx add decision \"Use JWT tokens for API authentication\"\n</code></pre></p>","path":["Autonomous Loops"],"tags":[]},{"location":"autonomous-loop/#advanced-watch-mode","level":2,"title":"Advanced: Watch Mode","text":"<p>Run <code>ctx watch</code> alongside the loop to automatically process context updates:</p> <pre><code># Terminal 1: Run the loop\n./loop.sh 2&gt;&amp;1 | tee /tmp/loop.log\n\n# Terminal 2: Watch for context updates\nctx watch --log /tmp/loop.log --auto-save\n</code></pre> <p>The <code>--auto-save</code> flag periodically saves session snapshots, creating a history of the loop's progress.</p>","path":["Autonomous Loops"],"tags":[]},{"location":"autonomous-loop/#project-setup","level":2,"title":"Project Setup","text":"<p>Initialize a project for autonomous loop operation:</p> <pre><code># Initialize with autonomous agent behavior\nctx init --ralph\n</code></pre> <p>The <code>--ralph</code> flag creates a <code>PROMPT.md</code> where the agent:</p> <ul> <li>Works autonomously without asking clarifying questions</li> <li>Follows one-task-per-iteration discipline</li> <li>Uses <code>SYSTEM_CONVERGED</code> / <code>SYSTEM_BLOCKED</code> signals</li> </ul> <p>Without <code>--ralph</code>, the agent is encouraged to ask questions when requirements are unclear — better for collaborative human-agent sessions.</p>","path":["Autonomous Loops"],"tags":[]},{"location":"autonomous-loop/#example-project-structure","level":2,"title":"Example Project Structure","text":"<pre><code>my-project/\n├── .context/\n│   ├── CONSTITUTION.md\n│   ├── TASKS.md          # Work items for the loop\n│   ├── DECISIONS.md\n│   ├── LEARNINGS.md\n│   ├── CONVENTIONS.md\n│   └── sessions/         # Loop iteration history\n├── PROMPT.md             # Instructions for the AI\n├── IMPLEMENTATION_PLAN.md # High-level project direction\n├── loop.sh               # Loop script (if not using Claude Code)\n└── src/                  # Your code\n</code></pre>","path":["Autonomous Loops"],"tags":[]},{"location":"autonomous-loop/#sample-tasksmd-for-autonomous-loops","level":3,"title":"Sample TASKS.md for Autonomous Loops","text":"<pre><code># Tasks\n\n## Phase 1: Setup\n\n- [x] Initialize project structure\n- [x] Set up testing framework\n\n## Phase 2: Core Features\n\n- [ ] Implement user registration `#priority:high`\n- [ ] Add email verification `#priority:high`\n- [ ] Create password reset flow `#priority:medium`\n\n## Phase 3: Polish\n\n- [ ] Add rate limiting `#priority:medium`\n- [ ] Improve error messages `#priority:low`\n</code></pre> <p>The loop will work through these systematically, marking each complete.</p>","path":["Autonomous Loops"],"tags":[]},{"location":"autonomous-loop/#troubleshooting","level":2,"title":"Troubleshooting","text":"","path":["Autonomous Loops"],"tags":[]},{"location":"autonomous-loop/#loop-runs-forever","level":3,"title":"Loop Runs Forever","text":"<p>Cause: AI not emitting completion signals</p> <p>Fix: Ensure PROMPT.md explicitly instructs signaling: <pre><code>End EVERY response with one of:\n- SYSTEM_CONVERGED (if all tasks done)\n- SYSTEM_BLOCKED (if stuck)\n</code></pre></p>","path":["Autonomous Loops"],"tags":[]},{"location":"autonomous-loop/#context-not-persisting","level":3,"title":"Context Not Persisting","text":"<p>Cause: AI not updating context files</p> <p>Fix: Add explicit instructions to PROMPT.md: <pre><code>After completing a task, you MUST:\n1. Run: ctx complete \"&lt;task&gt;\"\n2. Add learnings: ctx add learning \"...\"\n</code></pre></p>","path":["Autonomous Loops"],"tags":[]},{"location":"autonomous-loop/#tasks-getting-repeated","level":3,"title":"Tasks Getting Repeated","text":"<p>Cause: Task not marked complete before next iteration</p> <p>Fix: Ensure commit happens after context update: <pre><code>Order of operations:\n1. Complete coding work\n2. Update context files (ctx complete, ctx add)\n3. Commit ALL changes including .context/\n4. Then signal status\n</code></pre></p>","path":["Autonomous Loops"],"tags":[]},{"location":"autonomous-loop/#ai-violating-constitution","level":3,"title":"AI Violating Constitution","text":"<p>Cause: Constitution not read first</p> <p>Fix: Make constitution check explicit in PROMPT.md: <pre><code>BEFORE any work:\n1. Read .context/CONSTITUTION.md\n2. If task would violate ANY rule, emit SYSTEM_BLOCKED\n3. Explain which rule prevents the work\n</code></pre></p>","path":["Autonomous Loops"],"tags":[]},{"location":"autonomous-loop/#resources","level":2,"title":"Resources","text":"<ul> <li>Geoffrey Huntley's Ralph Wiggum Technique — Original inspiration</li> <li>Context CLI — Command reference</li> <li>Integrations — Tool-specific setup</li> </ul>","path":["Autonomous Loops"],"tags":[]},{"location":"cli-reference/","level":1,"title":"CLI Reference","text":"","path":["CLI Reference"],"tags":[]},{"location":"cli-reference/#ctx-cli","level":2,"title":"<code>ctx</code> CLI","text":"<p>This is a complete reference for all <code>ctx</code> commands.</p>","path":["CLI Reference"],"tags":[]},{"location":"cli-reference/#global-options","level":2,"title":"Global Options","text":"<p>All commands support these flags:</p> Flag Description <code>--help</code> Show command help <code>--version</code> Show version <code>--context-dir &lt;path&gt;</code> Override context directory (default: <code>.context/</code>) <code>--no-color</code> Disable colored output <p>The <code>NO_COLOR=1</code> environment variable also disables colored output.</p>","path":["CLI Reference"],"tags":[]},{"location":"cli-reference/#commands","level":2,"title":"Commands","text":"Command Description <code>ctx init</code> Initialize <code>.context/</code> directory with templates and hooks <code>ctx status</code> Show context summary (files, tokens, drift) <code>ctx agent</code> Print token-budgeted context packet for AI consumption <code>ctx load</code> Output assembled context in read order <code>ctx add</code> Add a task, decision, learning, or convention <code>ctx complete</code> Mark a task as done <code>ctx drift</code> Detect stale paths, secrets, missing files <code>ctx sync</code> Reconcile context with codebase state <code>ctx compact</code> Archive completed tasks, clean up files <code>ctx tasks</code> Task archival and snapshots <code>ctx decisions</code> Reindex DECISIONS.md <code>ctx learnings</code> Reindex LEARNINGS.md <code>ctx recall</code> Browse and export AI session history <code>ctx journal</code> Generate static site from journal entries <code>ctx serve</code> Serve static site locally <code>ctx session</code> Save, list, load, and parse session snapshots <code>ctx watch</code> Auto-apply context updates from AI output <code>ctx hook</code> Generate AI tool integration configs <code>ctx loop</code> Generate autonomous loop script","path":["CLI Reference"],"tags":[]},{"location":"cli-reference/#ctx-init","level":3,"title":"<code>ctx init</code>","text":"<p>Initialize a new <code>.context/</code> directory with template files.</p> <pre><code>ctx init [flags]\n</code></pre> <p>Flags:</p> Flag Short Description <code>--force</code> <code>-f</code> Overwrite existing context files <code>--minimal</code> <code>-m</code> Only create essential files (TASKS.md, DECISIONS.md, CONSTITUTION.md) <code>--merge</code> Auto-merge ctx content into existing CLAUDE.md and PROMPT.md <code>--ralph</code> Agent works autonomously without asking questions <p>Creates:</p> <ul> <li><code>.context/</code> directory with all template files</li> <li><code>.claude/hooks/</code> with auto-save and enforcement scripts (for Claude Code)</li> <li><code>.claude/skills/</code> with ctx Agent Skills (following agentskills.io spec)</li> <li><code>.claude/settings.local.json</code> with hook configuration and pre-approved ctx permissions</li> <li><code>PROMPT.md</code> with session prompt (autonomous mode with <code>--ralph</code>)</li> <li><code>IMPLEMENTATION_PLAN.md</code> with high-level project direction</li> <li><code>CLAUDE.md</code> with bootstrap instructions (or merges into existing)</li> </ul> <p>Example:</p> <pre><code># Collaborative mode (agent asks questions when unclear)\nctx init\n\n# Autonomous mode (agent works independently)\nctx init --ralph\n\n# Minimal setup (just core files)\nctx init --minimal\n\n# Force overwrite existing\nctx init --force\n\n# Merge into existing files\nctx init --merge\n</code></pre>","path":["CLI Reference"],"tags":[]},{"location":"cli-reference/#ctx-status","level":3,"title":"<code>ctx status</code>","text":"<p>Show the current context summary.</p> <pre><code>ctx status [flags]\n</code></pre> <p>Flags:</p> Flag Short Description <code>--json</code> Output as JSON <code>--verbose</code> <code>-v</code> Include file contents summary <p>Output:</p> <ul> <li>Context directory path</li> <li>Total files and token estimate</li> <li>Status of each file (loaded, empty, missing)</li> <li>Recent activity (modification times)</li> <li>Drift warnings if any</li> </ul> <p>Example:</p> <pre><code>ctx status\nctx status --json\nctx status --verbose\n</code></pre>","path":["CLI Reference"],"tags":[]},{"location":"cli-reference/#ctx-agent","level":3,"title":"<code>ctx agent</code>","text":"<p>Print an AI-ready context packet optimized for LLM consumption.</p> <pre><code>ctx agent [flags]\n</code></pre> <p>Flags:</p> Flag Description <code>--budget &lt;tokens&gt;</code> Token budget (default: 8000) <code>--format md\\|json</code> Output format (default: md) <p>Output:</p> <ul> <li>Read order for context files</li> <li>Constitution rules (never truncated)</li> <li>Current tasks</li> <li>Key conventions</li> <li>Recent decisions</li> </ul> <p>Flags:</p> Flag Default Description <code>--budget</code> 8000 Token budget for context packet <code>--format</code> md Output format: <code>md</code> or <code>json</code> <code>--cooldown</code> 10m Suppress repeated output within this duration <code>--session</code> (none) Session ID for cooldown isolation (e.g., <code>$PPID</code>) <p>Example:</p> <pre><code># Default (8000 tokens, markdown)\nctx agent\n\n# Custom budget\nctx agent --budget 4000\n\n# JSON format\nctx agent --format json\n\n# With cooldown (outputs once, then silent for 10m)\nctx agent --budget 4000 --session $PPID\n</code></pre> <p>Use case: Copy-paste into AI chat, pipe to system prompt, or use in hooks.</p>","path":["CLI Reference"],"tags":[]},{"location":"cli-reference/#ctx-load","level":3,"title":"<code>ctx load</code>","text":"<p>Load and display assembled context as AI would see it.</p> <pre><code>ctx load [flags]\n</code></pre> <p>Flags:</p> Flag Description <code>--budget &lt;tokens&gt;</code> Token budget for assembly (default: 8000) <code>--raw</code> Output raw file contents without assembly <p>Example:</p> <pre><code>ctx load\nctx load --budget 16000\nctx load --raw\n</code></pre>","path":["CLI Reference"],"tags":[]},{"location":"cli-reference/#ctx-add","level":3,"title":"<code>ctx add</code>","text":"<p>Add a new item to a context file.</p> <pre><code>ctx add &lt;type&gt; &lt;content&gt; [flags]\n</code></pre> <p>Types:</p> Type Target File <code>task</code> TASKS.md <code>decision</code> DECISIONS.md <code>learning</code> LEARNINGS.md <code>convention</code> CONVENTIONS.md <p>Flags:</p> Flag Short Description <code>--priority &lt;level&gt;</code> Priority for tasks: <code>high</code>, <code>medium</code>, <code>low</code> <code>--section &lt;name&gt;</code> <code>-s</code> Target section within file <code>--context</code> <code>-c</code> Context (required for decisions and learnings) <code>--rationale</code> <code>-r</code> Rationale for decisions (required for decisions) <code>--consequences</code> Consequences for decisions (required for decisions) <code>--lesson</code> <code>-l</code> Key insight (required for learnings) <code>--application</code> <code>-a</code> How to apply going forward (required for learnings) <code>--file</code> <code>-f</code> Read content from file instead of argument <p>Examples:</p> <pre><code># Add a task\nctx add task \"Implement user authentication\"\nctx add task \"Fix login bug\" --priority high\n\n# Record a decision (requires all ADR—Architectural Decision Record—fields)\nctx add decision \"Use PostgreSQL for primary database\" \\\n  --context \"Need a reliable database for production\" \\\n  --rationale \"PostgreSQL offers ACID compliance and JSON support\" \\\n  --consequences \"Team needs PostgreSQL training\"\n\n# Note a learning (requires context, lesson, and application)\nctx add learning \"Vitest mocks must be hoisted\" \\\n  --context \"Tests failed with undefined mock errors\" \\\n  --lesson \"Vitest hoists vi.mock() calls to top of file\" \\\n  --application \"Always place vi.mock() before imports in test files\"\n\n# Add to specific section\nctx add convention \"Use kebab-case for filenames\" --section \"Naming\"\n</code></pre>","path":["CLI Reference"],"tags":[]},{"location":"cli-reference/#ctx-complete","level":3,"title":"<code>ctx complete</code>","text":"<p>Mark a task as completed.</p> <pre><code>ctx complete &lt;task-id-or-text&gt;\n</code></pre> <p>Arguments:</p> <ul> <li><code>task-id-or-text</code>: Task number or partial text match</li> </ul> <p>Examples:</p> <pre><code># By text (partial match)\nctx complete \"user auth\"\n\n# By task number\nctx complete 3\n</code></pre>","path":["CLI Reference"],"tags":[]},{"location":"cli-reference/#ctx-drift","level":3,"title":"<code>ctx drift</code>","text":"<p>Detect stale or invalid context.</p> <pre><code>ctx drift [flags]\n</code></pre> <p>Flags:</p> Flag Description <code>--json</code> Output machine-readable JSON <code>--fix</code> Auto-fix simple issues <p>Checks:</p> <ul> <li>Path references in ARCHITECTURE.md and CONVENTIONS.md exist</li> <li>Task references are valid</li> <li>Constitution rules aren't violated (heuristic)</li> <li>Staleness indicators (old files, many completed tasks)</li> </ul> <p>Example:</p> <pre><code>ctx drift\nctx drift --json\nctx drift --fix\n</code></pre> <p>Exit codes:</p> Code Meaning 0 All checks passed 1 Warnings found 3 Violations found","path":["CLI Reference"],"tags":[]},{"location":"cli-reference/#ctx-sync","level":3,"title":"<code>ctx sync</code>","text":"<p>Reconcile context with the current codebase state.</p> <pre><code>ctx sync [flags]\n</code></pre> <p>Flags:</p> Flag Description <code>--dry-run</code> Show what would change without modifying <p>What it does:</p> <ul> <li>Scans codebase for structural changes</li> <li>Compares with ARCHITECTURE.md</li> <li>Suggests documenting dependencies if package files exist</li> <li>Identifies stale or outdated context</li> </ul> <p>Example:</p> <pre><code>ctx sync\nctx sync --dry-run\n</code></pre>","path":["CLI Reference"],"tags":[]},{"location":"cli-reference/#ctx-compact","level":3,"title":"<code>ctx compact</code>","text":"<p>Consolidate and clean up context files.</p> <ul> <li>Moves completed tasks older than 7 days to the archive</li> <li>Deduplicates the \"learning\"s with similar content</li> <li>Removes empty sections</li> </ul> <pre><code>ctx compact [flags]\n</code></pre> <p>Flags:</p> Flag Description <code>--archive</code> Create <code>.context/archive/</code> for old content <code>--no-auto-save</code> Skip auto-saving session before compact <p>Example:</p> <pre><code>ctx compact\nctx compact --archive\nctx compact --no-auto-save\n</code></pre>","path":["CLI Reference"],"tags":[]},{"location":"cli-reference/#ctx-completion","level":3,"title":"<code>ctx completion</code>","text":"<p>Generate shell autocompletion scripts.</p> <pre><code>ctx completion &lt;shell&gt;\n</code></pre>","path":["CLI Reference"],"tags":[]},{"location":"cli-reference/#subcommands","level":4,"title":"Subcommands","text":"Shell Command <code>bash</code> <code>ctx completion bash</code> <code>zsh</code> <code>ctx completion zsh</code> <code>fish</code> <code>ctx completion fish</code> <code>powershell</code> <code>ctx completion powershell</code>","path":["CLI Reference"],"tags":[]},{"location":"cli-reference/#installation","level":4,"title":"Installation","text":"BashZshFish <pre><code># Add to ~/.bashrc\nsource &lt;(ctx completion bash)\n</code></pre> <pre><code># Add to ~/.zshrc\nsource &lt;(ctx completion zsh)\n</code></pre> <pre><code>ctx completion fish | source\n# Or save to completions directory\nctx completion fish &gt; ~/.config/fish/completions/ctx.fish\n</code></pre>","path":["CLI Reference"],"tags":[]},{"location":"cli-reference/#ctx-tasks","level":3,"title":"<code>ctx tasks</code>","text":"<p>Manage task archival and snapshots.</p> <pre><code>ctx tasks &lt;subcommand&gt;\n</code></pre>","path":["CLI Reference"],"tags":[]},{"location":"cli-reference/#ctx-tasks-archive","level":4,"title":"<code>ctx tasks archive</code>","text":"<p>Move completed tasks from TASKS.md to a timestamped archive file.</p> <pre><code>ctx tasks archive [flags]\n</code></pre> <p>Flags:</p> Flag Description <code>--dry-run</code> Preview changes without modifying files <p>Archive files are stored in <code>.context/archive/</code> with timestamped names (<code>tasks-YYYY-MM-DD.md</code>). Completed tasks (marked with <code>[x]</code>) are moved; pending tasks (<code>[ ]</code>) remain in TASKS.md.</p> <p>Example:</p> <pre><code>ctx tasks archive\nctx tasks archive --dry-run\n</code></pre>","path":["CLI Reference"],"tags":[]},{"location":"cli-reference/#ctx-tasks-snapshot","level":4,"title":"<code>ctx tasks snapshot</code>","text":"<p>Create a point-in-time snapshot of TASKS.md without modifying the original.</p> <pre><code>ctx tasks snapshot [name]\n</code></pre> <p>Arguments:</p> <ul> <li><code>name</code>: Optional name for the snapshot (defaults to \"snapshot\")</li> </ul> <p>Snapshots are stored in <code>.context/archive/</code> with timestamped names (<code>tasks-&lt;name&gt;-YYYY-MM-DD-HHMM.md</code>).</p> <p>Example:</p> <pre><code>ctx tasks snapshot\nctx tasks snapshot \"before-refactor\"\n</code></pre>","path":["CLI Reference"],"tags":[]},{"location":"cli-reference/#ctx-decisions","level":3,"title":"<code>ctx decisions</code>","text":"<p>Manage the DECISIONS.md file.</p> <pre><code>ctx decisions &lt;subcommand&gt;\n</code></pre>","path":["CLI Reference"],"tags":[]},{"location":"cli-reference/#ctx-decisions-reindex","level":4,"title":"<code>ctx decisions reindex</code>","text":"<p>Regenerate the quick-reference index at the top of DECISIONS.md.</p> <pre><code>ctx decisions reindex\n</code></pre> <p>The index is a compact table showing date and title for each decision, allowing AI tools to quickly scan entries without reading the full file.</p> <p>Use this after manual edits to DECISIONS.md or when migrating existing files to use the index format.</p> <p>Example:</p> <pre><code>ctx decisions reindex\n# ✓ Index regenerated with 12 entries\n</code></pre>","path":["CLI Reference"],"tags":[]},{"location":"cli-reference/#ctx-learnings","level":3,"title":"<code>ctx learnings</code>","text":"<p>Manage the LEARNINGS.md file.</p> <pre><code>ctx learnings &lt;subcommand&gt;\n</code></pre>","path":["CLI Reference"],"tags":[]},{"location":"cli-reference/#ctx-learnings-reindex","level":4,"title":"<code>ctx learnings reindex</code>","text":"<p>Regenerate the quick-reference index at the top of LEARNINGS.md.</p> <pre><code>ctx learnings reindex\n</code></pre> <p>The index is a compact table showing date and title for each learning, allowing AI tools to quickly scan entries without reading the full file.</p> <p>Use this after manual edits to LEARNINGS.md or when migrating existing files to use the index format.</p> <p>Example:</p> <pre><code>ctx learnings reindex\n# ✓ Index regenerated with 8 entries\n</code></pre>","path":["CLI Reference"],"tags":[]},{"location":"cli-reference/#ctx-recall","level":3,"title":"<code>ctx recall</code>","text":"<p>Browse and search AI session history from Claude Code and other tools.</p> <pre><code>ctx recall &lt;subcommand&gt;\n</code></pre>","path":["CLI Reference"],"tags":[]},{"location":"cli-reference/#ctx-recall-list","level":4,"title":"<code>ctx recall list</code>","text":"<p>List all parsed sessions.</p> <pre><code>ctx recall list [flags]\n</code></pre> <p>Flags:</p> Flag Short Description <code>--limit</code> <code>-n</code> Maximum sessions to display (default: 20) <code>--project</code> <code>-p</code> Filter by project name <code>--tool</code> <code>-t</code> Filter by tool (e.g., <code>claude-code</code>) <code>--all-projects</code> Include sessions from all projects <p>Sessions are sorted by date (newest first) and display slug, project, start time, duration, turn count, and token usage.</p> <p>Example:</p> <pre><code>ctx recall list\nctx recall list --limit 5\nctx recall list --project ctx\nctx recall list --tool claude-code\n</code></pre>","path":["CLI Reference"],"tags":[]},{"location":"cli-reference/#ctx-recall-show","level":4,"title":"<code>ctx recall show</code>","text":"<p>Show details of a specific session.</p> <pre><code>ctx recall show [session-id] [flags]\n</code></pre> <p>Flags:</p> Flag Description <code>--latest</code> Show the most recent session <code>--full</code> Show full message content <code>--all-projects</code> Search across all projects <p>The session ID can be a full UUID, partial match, or session slug name.</p> <p>Example:</p> <pre><code>ctx recall show abc123\nctx recall show gleaming-wobbling-sutherland\nctx recall show --latest\nctx recall show --latest --full\n</code></pre>","path":["CLI Reference"],"tags":[]},{"location":"cli-reference/#ctx-recall-export","level":4,"title":"<code>ctx recall export</code>","text":"<p>Export sessions to editable journal files in <code>.context/journal/</code>.</p> <pre><code>ctx recall export [session-id] [flags]\n</code></pre> <p>Flags:</p> Flag Description <code>--all</code> Export all sessions <code>--all-projects</code> Export from all projects <code>--force</code> Overwrite existing files completely (discard frontmatter) <code>--skip-existing</code> Skip files that already exist <p>Exported files include session metadata, tool usage summary, and the full conversation. When re-exporting, YAML frontmatter from enrichment (topics, type, outcome, etc.) is preserved by default; only the conversation content is regenerated.</p> <p>The <code>journal/</code> directory should be gitignored (like <code>sessions/</code>) since it contains raw conversation data.</p> <p>Example:</p> <pre><code>ctx recall export abc123                # Export one session\nctx recall export --all                 # Export/update all sessions\nctx recall export --all --skip-existing # Skip files that already exist\nctx recall export --all --force         # Overwrite completely (lose frontmatter)\n</code></pre>","path":["CLI Reference"],"tags":[]},{"location":"cli-reference/#ctx-journal","level":3,"title":"<code>ctx journal</code>","text":"<p>Analyze and synthesize exported session files.</p> <pre><code>ctx journal &lt;subcommand&gt;\n</code></pre>","path":["CLI Reference"],"tags":[]},{"location":"cli-reference/#ctx-journal-site","level":4,"title":"<code>ctx journal site</code>","text":"<p>Generate a static site from journal entries in <code>.context/journal/</code>.</p> <pre><code>ctx journal site [flags]\n</code></pre> <p>Flags:</p> Flag Short Description <code>--output</code> <code>-o</code> Output directory (default: .context/journal-site) <code>--build</code> Run zensical build after generating <code>--serve</code> Run zensical serve after generating <p>Creates a <code>zensical</code>-compatible site structure with an index page listing all sessions by date, and individual pages for each journal entry.</p> <p>Requires <code>zensical</code> to be installed for <code>--build</code> or <code>--serve</code>:</p> <pre><code>pip install zensical\n</code></pre> <p>Example:</p> <pre><code>ctx journal site                    # Generate in .context/journal-site/\nctx journal site --output ~/public  # Custom output directory\nctx journal site --build            # Generate and build HTML\nctx journal site --serve            # Generate and serve locally\n</code></pre>","path":["CLI Reference"],"tags":[]},{"location":"cli-reference/#ctx-serve","level":3,"title":"<code>ctx serve</code>","text":"<p>Serve a static site locally via <code>zensical</code>.</p> <pre><code>ctx serve [directory]\n</code></pre> <p>If no directory is specified, serves the journal site (<code>.context/journal-site</code>).</p> <p>Requires <code>zensical</code> to be installed:</p> <pre><code>pip install zensical\n</code></pre> <p>Example:</p> <pre><code>ctx serve                           # Serve journal site\nctx serve .context/journal-site     # Serve specific directory\nctx serve ./docs                    # Serve docs folder\n</code></pre>","path":["CLI Reference"],"tags":[]},{"location":"cli-reference/#ctx-watch","level":3,"title":"<code>ctx watch</code>","text":"<p>Watch for AI output and auto-apply context updates.</p> <p>Parses <code>&lt;context-update&gt;</code> XML commands from AI output and applies them to context files.</p> <pre><code>ctx watch [flags]\n</code></pre> <p>Flags:</p> Flag Description <code>--log &lt;file&gt;</code> Log file to watch (default: stdin) <code>--dry-run</code> Preview updates without applying <code>--auto-save</code> Periodically save session snapshots <p>Example:</p> <pre><code># Watch stdin\nai-tool | ctx watch\n\n# Watch a log file\nctx watch --log /path/to/ai-output.log\n\n# Preview without applying\nctx watch --dry-run\n</code></pre>","path":["CLI Reference"],"tags":[]},{"location":"cli-reference/#ctx-hook","level":3,"title":"<code>ctx hook</code>","text":"<p>Generate AI tool integration configuration.</p> <pre><code>ctx hook &lt;tool&gt;\n</code></pre> <p>Supported tools:</p> Tool Description <code>claude-code</code> Claude Code CLI <code>cursor</code> Cursor IDE <code>aider</code> Aider CLI <code>copilot</code> GitHub Copilot <code>windsurf</code> Windsurf IDE <p>Example:</p> <pre><code>ctx hook claude-code\nctx hook cursor\nctx hook aider\n</code></pre>","path":["CLI Reference"],"tags":[]},{"location":"cli-reference/#ctx-session","level":3,"title":"<code>ctx session</code>","text":"<p>Manage session snapshots.</p>","path":["CLI Reference"],"tags":[]},{"location":"cli-reference/#ctx-session-save","level":4,"title":"ctx session save","text":"<p>Save the current context snapshot.</p> <pre><code>ctx session save [topic] [flags]\n</code></pre> <p>Flags:</p> Flag Short Description <code>--type &lt;type&gt;</code> <code>-t</code> Session type: <code>feature</code>, <code>bugfix</code>, <code>refactor</code>, <code>session</code> <p>Example:</p> <pre><code>ctx session save\nctx session save \"feature-auth\"\nctx session save \"bugfix\" --type bugfix\n</code></pre>","path":["CLI Reference"],"tags":[]},{"location":"cli-reference/#ctx-session-list","level":4,"title":"<code>ctx session list</code>","text":"<p>List saved sessions.</p> <pre><code>ctx session list [flags]\n</code></pre> <p>Flags:</p> Flag Short Description <code>--limit</code> <code>-n</code> Maximum sessions to display (default: 10) <p>Output: Table of sessions with index, date, topic, and type.</p> <p>Example:</p> <pre><code>ctx session list\nctx session list --limit 5\n</code></pre>","path":["CLI Reference"],"tags":[]},{"location":"cli-reference/#ctx-session-load","level":4,"title":"<code>ctx session load</code>","text":"<p>Load and display a previous session.</p> <pre><code>ctx session load &lt;index|date|topic&gt;\n</code></pre> <p>Arguments:</p> <ul> <li><code>index</code>: Numeric index from <code>session list</code></li> <li><code>date</code>: Date pattern (e.g., <code>2026-01-21</code>)</li> <li><code>topic</code>: Topic keyword match</li> </ul> <p>Example:</p> <pre><code>ctx session load 1           # by index\nctx session load 2026-01-21  # by date\nctx session load auth        # by topic\n</code></pre>","path":["CLI Reference"],"tags":[]},{"location":"cli-reference/#ctx-session-parse","level":4,"title":"<code>ctx session parse</code>","text":"<p>Parse JSONL transcript to readable markdown.</p> <pre><code>ctx session parse &lt;file&gt; [flags]\n</code></pre> <p>Flags:</p> Flag Short Description <code>--output</code> <code>-o</code> Output file (default: stdout) <code>--extract</code> Extract decisions and learnings from transcript <p>Example:</p> <pre><code>ctx session parse ~/.claude/projects/.../transcript.jsonl\nctx session parse transcript.jsonl --extract\nctx session parse transcript.jsonl -o conversation.md\n</code></pre>","path":["CLI Reference"],"tags":[]},{"location":"cli-reference/#ctx-loop","level":3,"title":"<code>ctx loop</code>","text":"<p>Generate a shell script for running an autonomous loop.</p> <p>An autonomous loop continuously runs an AI assistant with the same prompt until a completion signal is detected, enabling iterative development where the AI builds on its previous work.</p> <pre><code>ctx loop [flags]\n</code></pre> <p>Flags:</p> Flag Short Description Default <code>--tool &lt;tool&gt;</code> <code>-t</code> AI tool: <code>claude</code>, <code>aider</code>, or <code>generic</code> <code>claude</code> <code>--prompt &lt;file&gt;</code> <code>-p</code> Prompt file to use <code>PROMPT.md</code> <code>--max-iterations &lt;n&gt;</code> <code>-n</code> Maximum iterations (0 = unlimited) <code>0</code> <code>--completion &lt;signal&gt;</code> <code>-c</code> Completion signal to detect <code>SYSTEM_CONVERGED</code> <code>--output &lt;file&gt;</code> <code>-o</code> Output script filename <code>loop.sh</code> <p>Example:</p> <pre><code># Generate loop.sh for Claude Code\nctx loop\n\n# Generate for Aider with custom prompt\nctx loop --tool aider --prompt TASKS.md\n\n# Limit to 10 iterations\nctx loop --max-iterations 10\n\n# Output to custom file\nctx loop -o my-loop.sh\n</code></pre> <p>Usage:</p> <pre><code># Generate and run the loop\nctx loop\nchmod +x loop.sh\n./loop.sh\n</code></pre> <p>See Autonomous Loops for detailed workflow documentation.</p>","path":["CLI Reference"],"tags":[]},{"location":"cli-reference/#exit-codes","level":2,"title":"Exit Codes","text":"Code Meaning 0 Success 1 General error 2 Context not found 3 Invalid arguments 4 File operation error","path":["CLI Reference"],"tags":[]},{"location":"cli-reference/#environment-variables","level":2,"title":"Environment Variables","text":"Variable Description <code>CTX_DIR</code> Override default context directory path <code>CTX_TOKEN_BUDGET</code> Override default token budget <code>NO_COLOR</code> Disable colored output when set","path":["CLI Reference"],"tags":[]},{"location":"cli-reference/#configuration-file","level":2,"title":"Configuration File","text":"<p>Optional <code>.contextrc</code> (YAML format) at project root:</p> <pre><code># .contextrc\ncontext_dir: .context # Context directory name\ntoken_budget: 8000    # Default token budget\npriority_order:       # File loading priority\n  - TASKS.md\n  - DECISIONS.md\n  - CONVENTIONS.md\nauto_archive: true    # Auto-archive old items\narchive_after_days: 7 # Days before archiving\n</code></pre> <p>Priority order: CLI flags &gt; Environment variables &gt; <code>.contextrc</code> &gt; Defaults</p> <p>All settings are optional. Missing values use defaults.</p>","path":["CLI Reference"],"tags":[]},{"location":"comparison/","level":1,"title":"ctx and Similar Tools","text":"","path":["ctx and Similar Tools"],"tags":[]},{"location":"comparison/#high-level-mental-model","level":2,"title":"High-Level Mental Model","text":"<p>Many tools help AI think.</p> <p><code>ctx</code> helps AI remember.</p> <ul> <li>Not by storing thoughts,</li> <li>but by preserving intent.</li> </ul>","path":["ctx and Similar Tools"],"tags":[]},{"location":"comparison/#how-ctx-differs-from-similar-tools","level":2,"title":"How <code>ctx</code> Differs from Similar Tools","text":"<p>There are many tools in the AI ecosystem that touch parts of the context problem:</p> <ul> <li>Some manage prompts.  </li> <li>Some retrieve data.  </li> <li>Some provide runtime context objects.  </li> <li>Some offer enterprise platforms.</li> </ul> <p><code>ctx</code> focuses on a different layer entirely.</p> <p>This page explains where <code>ctx</code> fits, and where it intentionally does not.</p>","path":["ctx and Similar Tools"],"tags":[]},{"location":"comparison/#the-core-distinction","level":2,"title":"The Core Distinction","text":"<p>Most tools treat context as input.</p> <p><code>ctx</code> treats context as infrastructure.</p> <p>That single difference explains nearly all of <code>ctx</code>'s design choices.</p> Question Most tools ctx Where does context live? In prompts or APIs In files How long does it last? One request / one session Across time Who can read it? The model Humans and tools How is it updated? Implicitly Explicitly Is it inspectable? Rarely Always","path":["ctx and Similar Tools"],"tags":[]},{"location":"comparison/#prompt-management-tools","level":2,"title":"Prompt Management Tools","text":"<p>Examples include:</p> <ul> <li>prompt templates</li> <li>reusable system prompts</li> <li>prompt libraries</li> <li>prompt versioning tools</li> </ul> <p>These tools help you start a session.</p> <p>They do not help you continue one.</p> <p>Prompt tools:</p> <ul> <li>inject text at session start</li> <li>are ephemeral by design</li> <li>do not evolve with the project</li> </ul> <p><code>ctx</code>:</p> <ul> <li>persists knowledge over time</li> <li>accumulates decisions and learnings</li> <li>makes the context part of the repository itself</li> </ul> <p>Prompt tooling and <code>ctx</code> are complementary; not competing.  Yet they operate in different layers.</p>","path":["ctx and Similar Tools"],"tags":[]},{"location":"comparison/#retrieval-augmented-generation-rag","level":2,"title":"Retrieval-Augmented Generation (RAG)","text":"<p>RAG systems typically:</p> <ul> <li>index documents</li> <li>embed text</li> <li>retrieve chunks dynamically at runtime</li> </ul> <p>They are excellent for:</p> <ul> <li>large knowledge bases</li> <li>static documentation</li> <li>reference material</li> </ul> <p>RAG answers questions like:</p> <p>\"What information might be relevant right now?\"</p> <p><code>ctx</code> answers a different question:</p> <p>\"What have we already decided, learned, or committed to?\"</p> <p>Here are some key differences:</p> RAG ctx Statistical relevance Intentional relevance Embedding-based File-based Opaque retrieval Explicit structure Runtime query Persistent memory <p><code>ctx</code> does not replace RAG. Instead, it defines a persistent context layer that RAG can optionally augment.</p> <p>RAG belongs to the data plane; ctx defines the context control plane.</p> <p>It focuses on project memory, not knowledge search.</p>","path":["ctx and Similar Tools"],"tags":[]},{"location":"comparison/#agent-frameworks","level":2,"title":"Agent Frameworks","text":"<p>Agent frameworks often provide:</p> <ul> <li>task loops</li> <li>tool orchestration</li> <li>planner/executor patterns</li> <li>autonomous iteration</li> </ul> <p>These systems are powerful, but they typically assume that:</p> <ul> <li>memory is external</li> <li>context is injected</li> <li>state is transient</li> </ul> <p>Agent frameworks answer:</p> <p>\"How should the agent act?\"</p> <p><code>ctx</code> answers:</p> <p>\"What should the agent remember?\"</p> <p>Without persistent context, agents tend to:</p> <ul> <li>rediscover decisions</li> <li>repeat mistakes</li> <li>lose architectural intent</li> </ul> <p>This is why <code>ctx</code> pairs well with autonomous loop workflows:</p> <ul> <li>The loop provides iteration</li> <li><code>ctx</code> provides continuity</li> </ul> <p>Together, loops become cumulative instead of forgetful.</p>","path":["ctx and Similar Tools"],"tags":[]},{"location":"comparison/#sdk-level-context-objects","level":2,"title":"SDK-Level Context Objects","text":"<p>Some SDKs expose \"context\" objects that exist:</p> <ul> <li>inside a process</li> <li>during a request</li> <li>for the lifetime of a call chain</li> </ul> <p>These are extremely useful and completely different.</p> <p>SDK context objects:</p> <ul> <li>are in-memory</li> <li>disappear when the process ends</li> <li>are not shared across sessions</li> </ul> <p><code>ctx</code>:</p> <ul> <li>survives process restarts</li> <li>survives new chats</li> <li>survives new days</li> </ul> <p>They share a name, not a purpose.</p>","path":["ctx and Similar Tools"],"tags":[]},{"location":"comparison/#enterprise-context-platforms","level":2,"title":"Enterprise Context Platforms","text":"<p>Enterprise platforms often provide:</p> <ul> <li>centralized context services</li> <li>dashboards</li> <li>access control</li> <li>organizational knowledge layers</li> </ul> <p>These tools are designed for:</p> <ul> <li>teams</li> <li>governance</li> <li>compliance</li> <li>managed environments</li> </ul> <p><code>ctx</code> is intentionally:</p> <ul> <li>local-first</li> <li>file-based</li> <li>dependency-free</li> <li>CLI-driven</li> <li>developer-controlled</li> </ul> <p>It does not require:</p> <ul> <li>a server</li> <li>a database</li> <li>an account</li> <li>a SaaS backend</li> </ul> <p><code>ctx</code> optimizes for individual and small-team workflows where context should live next to code; not behind a service boundary.</p>","path":["ctx and Similar Tools"],"tags":[]},{"location":"comparison/#when-ctx-is-a-good-fit","level":2,"title":"When <code>ctx</code> Is a Good Fit","text":"<p><code>ctx</code> works best when:</p> <ul> <li>you want AI work to compound over time</li> <li>architectural decisions matter</li> <li>context must be inspectable</li> <li>humans and AI must share the same source of truth</li> <li>Git history should include why, not just what</li> </ul>","path":["ctx and Similar Tools"],"tags":[]},{"location":"comparison/#when-ctx-is-not-the-right-tool","level":2,"title":"When <code>ctx</code> Is Not the Right Tool","text":"<p><code>ctx</code> is probably not what you want if:</p> <ul> <li>you only need one-off prompts</li> <li>you rely exclusively on RAG</li> <li>you want autonomous agents without a human-readable state</li> <li>you require centralized enterprise control</li> <li>you want black-box memory systems</li> </ul> <p>These are valid goals; just different ones.</p>","path":["ctx and Similar Tools"],"tags":[]},{"location":"context-files/","level":1,"title":"Context Files","text":"","path":["Context Files"],"tags":[]},{"location":"context-files/#context","level":2,"title":"<code>.context/</code>","text":"<p>Each context file in <code>.context/</code> serves a specific purpose. </p> <p>Files are designed to be human-readable, AI-parseable, and token-efficient.</p>","path":["Context Files"],"tags":[]},{"location":"context-files/#file-overview","level":2,"title":"File Overview","text":"File Purpose Priority CONSTITUTION.md Hard rules that must NEVER be violated 1 (highest) TASKS.md Current and planned work 2 CONVENTIONS.md Project patterns and standards 3 ARCHITECTURE.md System overview and components 4 DECISIONS.md Architectural decisions with rationale 5 LEARNINGS.md Lessons learned, gotchas, tips 6 GLOSSARY.md Domain terms and abbreviations 7 AGENT_PLAYBOOK.md Instructions for AI tools 8 (lowest)","path":["Context Files"],"tags":[]},{"location":"context-files/#read-order-rationale","level":2,"title":"Read Order Rationale","text":"<p>The priority order follows a logical progression for AI tools:</p> <ol> <li><code>CONSTITUTION.md</code>: Inviolable rules first. The AI tool must know what it    cannot do before attempting anything.</li> <li><code>TASKS.md</code>: Current work items. What the AI tool should focus on.</li> <li><code>CONVENTIONS.md</code>: How to write code. Patterns and standards to follow    when implementing tasks.</li> <li><code>ARCHITECTURE.md</code>: System structure. Understanding of components and    boundaries before making changes.</li> <li><code>DECISIONS.md</code>: Historical context. Why things are the way they are,    to avoid re-debating settled decisions.</li> <li><code>LEARNINGS.md</code>: Gotchas and tips. Lessons from past work that inform    the current implementation.</li> <li><code>GLOSSARY.md</code>: Reference material. Domain terms and abbreviations for    lookup as needed.</li> <li><code>AGENT_PLAYBOOK.md</code>: Meta instructions last. How to use this context    system itself. Loaded last because the agent should understand the    content (rules, tasks, patterns) before the operating manual.</li> </ol>","path":["Context Files"],"tags":[]},{"location":"context-files/#constitutionmd","level":2,"title":"<code>CONSTITUTION.md</code>","text":"<p>Purpose: Define hard invariants—rules that must NEVER be violated,  regardless of the task.</p> <p>AI tools read this first and should refuse tasks that violate these rules.</p>","path":["Context Files"],"tags":[]},{"location":"context-files/#structure","level":3,"title":"Structure","text":"<pre><code># Constitution\n\nThese rules are INVIOLABLE. If a task requires violating these, the task \nis wrong.\n\n## Security Invariants\n\n- [ ] Never commit secrets, tokens, API keys, or credentials\n- [ ] Never store customer/user data in context files\n- [ ] Never disable security linters without documented exception\n\n## Quality Invariants\n\n- [ ] All code must pass tests before commit\n- [ ] No `any` types in TypeScript without documented reason\n- [ ] No TODO comments in main branch (move to TASKS.md)\n\n## Process Invariants\n\n- [ ] All architectural changes require a decision record\n- [ ] Breaking changes require version bump\n- [ ] Generated files are never committed\n</code></pre>","path":["Context Files"],"tags":[]},{"location":"context-files/#guidelines","level":3,"title":"Guidelines","text":"<ul> <li>Keep rules minimal and absolute</li> <li>Each rule should be enforceable (can verify compliance)</li> <li>Use checkbox format for clarity</li> <li>Never compromise on these rules</li> </ul>","path":["Context Files"],"tags":[]},{"location":"context-files/#tasksmd","level":2,"title":"<code>TASKS.md</code>","text":"<p>Purpose: Track current work, planned work, and blockers.</p>","path":["Context Files"],"tags":[]},{"location":"context-files/#structure_1","level":3,"title":"Structure","text":"<p>Tasks are organized by Phase — logical groupings that preserve order and enable replay. Tasks stay in their Phase permanently; status is tracked via checkboxes and inline tags.</p> <pre><code># Tasks\n\n## Phase 1: Initial Setup\n\n- [x] Set up project structure\n- [x] Configure linting and formatting\n- [ ] Add CI/CD pipeline `#in-progress`\n\n## Phase 2: Core Features\n\n- [ ] Implement user authentication `#priority:high`\n- [ ] Add API rate limiting `#priority:medium`\n  - Blocked by: Need to finalize auth first\n\n## Backlog\n\n- [ ] Performance optimization `#priority:low`\n- [ ] Add metrics dashboard `#priority:deferred`\n</code></pre> <p>Key principles:</p> <ul> <li>Tasks never move between sections — mark as <code>[x]</code> or <code>[-]</code> in place</li> <li>Use <code>#in-progress</code> inline tag to indicate current work</li> <li>Phase headers provide structure and replay order</li> <li>Backlog section for unscheduled work</li> </ul>","path":["Context Files"],"tags":[]},{"location":"context-files/#tags","level":3,"title":"Tags","text":"<p>Use inline backtick-wrapped tags for metadata:</p> Tag Values Purpose <code>#priority</code> <code>high</code>, <code>medium</code>, <code>low</code> Task urgency <code>#area</code> <code>core</code>, <code>cli</code>, <code>docs</code>, <code>tests</code> Codebase area <code>#estimate</code> <code>1h</code>, <code>4h</code>, <code>1d</code> Time estimate (optional) <code>#in-progress</code> (none) Currently being worked on <p>Lifecycle tags (for session correlation):</p> Tag Format When to add <code>#added</code> <code>YYYY-MM-DD-HHMMSS</code> Auto-added by <code>ctx add task</code> <code>#started</code> <code>YYYY-MM-DD-HHMMSS</code> When beginning work on the task <code>#done</code> <code>YYYY-MM-DD-HHMMSS</code> When marking the task <code>[x]</code> <p>These timestamps help correlate tasks with session files and track which session started vs completed work.</p>","path":["Context Files"],"tags":[]},{"location":"context-files/#status-markers","level":3,"title":"Status Markers","text":"Marker Meaning <code>[ ]</code> Pending <code>[x]</code> Completed <code>[-]</code> Skipped (include reason)","path":["Context Files"],"tags":[]},{"location":"context-files/#guidelines_1","level":3,"title":"Guidelines","text":"<ul> <li>Never delete tasks — mark as <code>[x]</code> completed or <code>[-]</code> skipped</li> <li>Never move tasks between sections — use inline tags for status</li> <li>Use <code>ctx tasks archive</code> periodically to move completed tasks to archive</li> <li>Mark current work with <code>#in-progress</code> inline tag</li> </ul>","path":["Context Files"],"tags":[]},{"location":"context-files/#decisionsmd","level":2,"title":"<code>DECISIONS.md</code>","text":"<p>Purpose: Record architectural decisions with rationale so they don't get re-debated.</p>","path":["Context Files"],"tags":[]},{"location":"context-files/#structure_2","level":3,"title":"Structure","text":"<pre><code># Decisions\n\n## [YYYY-MM-DD] Decision Title\n\n**Status**: Accepted | Superseded | Deprecated\n\n**Context**: What situation prompted this decision?\n\n**Decision**: What was decided?\n\n**Rationale**: Why was this the right choice?\n\n**Consequences**: What are the implications?\n\n**Alternatives Considered**:\n- Alternative A: Why rejected\n- Alternative B: Why rejected\n</code></pre>","path":["Context Files"],"tags":[]},{"location":"context-files/#example","level":3,"title":"Example","text":"<pre><code>## [2025-01-15] Use TypeScript Strict Mode\n\n**Status**: Accepted\n\n**Context**: Starting new project, need to choose type checking level.\n\n**Decision**: Enable TypeScript strict mode with all strict flags.\n\n**Rationale**: Catches more bugs at compile time. Team has experience\nwith strict mode. Upfront cost pays off in reduced runtime errors.\n\n**Consequences**: More verbose type annotations required. Some\nthird-party libraries need type assertions.\n\n**Alternatives Considered**:\n- Basic TypeScript: Rejected because it misses null checks\n- JavaScript with JSDoc: Rejected because tooling support is weaker\n</code></pre>","path":["Context Files"],"tags":[]},{"location":"context-files/#status-values","level":3,"title":"Status Values","text":"Status Meaning Accepted Current, active decision Superseded Replaced by newer decision (link to it) Deprecated No longer relevant","path":["Context Files"],"tags":[]},{"location":"context-files/#learningsmd","level":2,"title":"<code>LEARNINGS.md</code>","text":"<p>Purpose: Capture lessons learned, gotchas, and tips that shouldn't be forgotten.</p>","path":["Context Files"],"tags":[]},{"location":"context-files/#structure_3","level":3,"title":"Structure","text":"<pre><code># Learnings\n\n## Category Name\n\n### Learning Title\n\n**Discovered**: YYYY-MM-DD\n\n**Context**: When/how was this learned?\n\n**Lesson**: What's the takeaway?\n\n**Application**: How should this inform future work?\n</code></pre>","path":["Context Files"],"tags":[]},{"location":"context-files/#example_1","level":3,"title":"Example","text":"<pre><code>## Testing\n\n### Vitest Mocks Must Be Hoisted\n\n**Discovered**: 2025-01-15\n\n**Context**: Tests were failing intermittently when mocking fs module.\n\n**Lesson**: Vitest requires `vi.mock()` calls to be hoisted to the\ntop of the file. Dynamic mocks need `vi.doMock()` instead.\n\n**Application**: Always use `vi.mock()` at file top. Use `vi.doMock()`\nonly when mock needs runtime values.\n</code></pre>","path":["Context Files"],"tags":[]},{"location":"context-files/#categories","level":3,"title":"Categories","text":"<p>Organize learnings by topic:</p> <ul> <li>Testing</li> <li>Build &amp; Deploy</li> <li>Performance</li> <li>Security</li> <li>Third-Party Libraries</li> <li>Git &amp; Workflow</li> </ul>","path":["Context Files"],"tags":[]},{"location":"context-files/#conventionsmd","level":2,"title":"<code>CONVENTIONS.md</code>","text":"<p>Purpose: Document project patterns, naming conventions, and standards.</p>","path":["Context Files"],"tags":[]},{"location":"context-files/#structure_4","level":3,"title":"Structure","text":"<pre><code># Conventions\n\n## Naming\n\n* **Files**: kebab-case for all source files\n* **Components**: PascalCase for React components\n* **Functions**: camelCase, verb-first (getUser, parseConfig)\n* **Constants**: SCREAMING_SNAKE_CASE\n\n## Patterns\n\n### Pattern Name\n\n**When to use**: Situation description\n\n**Implementation**:\n// in triple backticks\n// Example code\n\n**Why**: Rationale for this pattern\n</code></pre>","path":["Context Files"],"tags":[]},{"location":"context-files/#guidelines_2","level":3,"title":"Guidelines","text":"<ul> <li>Include concrete examples</li> <li>Explain the \"why\" not just the \"what\"</li> <li>Keep patterns minimal—only document what's non-obvious</li> </ul>","path":["Context Files"],"tags":[]},{"location":"context-files/#architecturemd","level":2,"title":"<code>ARCHITECTURE.md</code>","text":"<p>Purpose: Provide system overview and component relationships.</p>","path":["Context Files"],"tags":[]},{"location":"context-files/#structure_5","level":3,"title":"Structure","text":"<pre><code># Architecture\n\n## Overview\n\nBrief description of what the system does and how it's organized.\n\n## Components\n\n### Component Name\n\n**Responsibility**: What this component does\n\n**Dependencies**: What it depends on\n\n**Dependents**: What depends on it\n\n**Key Files**:\n- path/to/file.ts — Description\n\n## Data Flow\n\nDescription or diagram of how data moves through the system.\n\n## Boundaries\n\nWhat's in scope vs out of scope for this codebase.\n</code></pre>","path":["Context Files"],"tags":[]},{"location":"context-files/#guidelines_3","level":3,"title":"Guidelines","text":"<ul> <li>Keep diagrams simple (Mermaid works well)</li> <li>Focus on boundaries and interfaces</li> <li>Update when major structural changes occur</li> </ul>","path":["Context Files"],"tags":[]},{"location":"context-files/#glossarymd","level":2,"title":"<code>GLOSSARY.md</code>","text":"<p>Purpose: Define domain terms, abbreviations, and project vocabulary.</p>","path":["Context Files"],"tags":[]},{"location":"context-files/#structure_6","level":3,"title":"Structure","text":"<pre><code># Glossary\n\n## Domain Terms\n\n### Term Name\n\n**Definition**: What it means in this project's context\n\n**Not to be confused with**: Similar terms that mean different things\n\n**Example**: How it's used\n\n## Abbreviations\n\n| Abbrev | Expansion                     | Context                |\n|--------|-------------------------------|------------------------|\n| ADR    | Architectural Decision Record | Decision documentation |\n| SUT    | System Under Test             | Testing                |\n</code></pre>","path":["Context Files"],"tags":[]},{"location":"context-files/#guidelines_4","level":3,"title":"Guidelines","text":"<ul> <li>Define project-specific meanings</li> <li>Clarify potentially ambiguous terms</li> <li>Include abbreviations used in code or docs</li> </ul>","path":["Context Files"],"tags":[]},{"location":"context-files/#agent_playbookmd","level":2,"title":"<code>AGENT_PLAYBOOK.md</code>","text":"<p>Purpose: Explicit instructions for how AI tools should read, apply,  and update context.</p>","path":["Context Files"],"tags":[]},{"location":"context-files/#key-sections","level":3,"title":"Key Sections","text":"<p>Read Order: Priority order for loading context files</p> <p>When to Update: Events that trigger context updates</p> <p>How to Avoid Hallucinating Memory: Critical rules:</p> <ol> <li>Never assume—if not in files, you don't know it</li> <li>Never invent history—don't claim \"we discussed\" without evidence</li> <li>Verify before referencing—search files before citing</li> <li>When uncertain, say so</li> <li>Trust files over intuition</li> </ol> <p>Context Update Commands: Format for automated updates via <code>ctx watch</code>:</p> <pre><code>&lt;context-update type=\"learning\"&gt;Key takeaway from today's work&lt;/context-update&gt;\n&lt;context-update type=\"decision\"&gt;Use Redis for caching&lt;/context-update&gt;\n&lt;context-update type=\"complete\"&gt;user auth&lt;/context-update&gt;\n</code></pre> <p>See Integrations for full documentation.</p>","path":["Context Files"],"tags":[]},{"location":"context-files/#parsing-rules","level":2,"title":"Parsing Rules","text":"<p>All context files follow these conventions:</p> <ol> <li>Headers define structure — <code>#</code> for title, <code>##</code> for sections, <code>###</code> for     items</li> <li>Bold keys for fields — <code>**Key**:</code> followed by value</li> <li>Code blocks are literal — Never parse code block content as structure</li> <li>Lists are ordered — Items appear in priority/chronological order</li> <li>Tags are inline — Backtick-wrapped tags like <code>#priority:high</code></li> </ol>","path":["Context Files"],"tags":[]},{"location":"context-files/#token-efficiency","level":2,"title":"Token Efficiency","text":"<p>Keep context files concise:</p> <ul> <li>Use abbreviations in tags, not prose</li> <li>Omit obvious words (\"The\", \"This\")</li> <li>Prefer bullet points over paragraphs</li> <li>Keep examples minimal but illustrative</li> <li>Archive old completed items periodically</li> </ul>","path":["Context Files"],"tags":[]},{"location":"integrations/","level":1,"title":"AI Tool Integrations","text":"","path":["AI Tool Integrations"],"tags":[]},{"location":"integrations/#ai-tool-integrations","level":2,"title":"AI Tool Integrations","text":"<p>Context works with any AI tool that can read files. This guide covers setup  for popular AI coding assistants.</p>","path":["AI Tool Integrations"],"tags":[]},{"location":"integrations/#claude-code-full-integration","level":2,"title":"Claude Code (Full Integration)","text":"<p>Claude Code has the deepest integration with automatic context loading and  session persistence.</p>","path":["AI Tool Integrations"],"tags":[]},{"location":"integrations/#automatic-setup","level":3,"title":"Automatic Setup","text":"<p>Running <code>ctx init</code> automatically configures Claude Code:</p> <pre><code>ctx init\n</code></pre> <p>This creates:</p> File/Directory Purpose <code>.context/</code> All context files <code>.claude/hooks/</code> Auto-save scripts <code>.claude/settings.local.json</code> Hook configuration <code>CLAUDE.md</code> Bootstrap instructions","path":["AI Tool Integrations"],"tags":[]},{"location":"integrations/#how-it-works","level":3,"title":"How It Works","text":"<pre><code>graph TD\n    A[Session Start] --&gt; B[Claude reads CLAUDE.md]\n    B --&gt; C[PreToolUse hook runs]\n    C --&gt; D[ctx agent loads context]\n    D --&gt; E[Work happens]\n    E --&gt; F[Session End]\n    F --&gt; G[SessionEnd hook saves snapshot]</code></pre> <ol> <li>Session start: Claude reads <code>CLAUDE.md</code>, which tells it to check <code>.context/</code></li> <li>First tool use: <code>PreToolUse</code> hook runs <code>ctx agent</code> and emits the context    packet (subsequent invocations within the cooldown window are silent)</li> <li>Session end: <code>SessionEnd</code> hook saves context snapshot to <code>.context/sessions/</code></li> <li>Next session: Claude sees previous sessions and continues with context</li> </ol>","path":["AI Tool Integrations"],"tags":[]},{"location":"integrations/#generated-configuration","level":3,"title":"Generated Configuration","text":"<p><code>.claude/settings.local.json</code>:</p> <pre><code>{\n  \"hooks\": {\n    \"PreToolUse\": [\n      {\n        \"matcher\": \".*\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"ctx agent --budget 4000 --session $PPID 2&gt;/dev/null || true\"\n          }\n        ]\n      }\n    ],\n    \"SessionEnd\": [\n      {\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \".claude/hooks/auto-save-session.sh\"\n          }\n        ]\n      }\n    ]\n  }\n}\n</code></pre>","path":["AI Tool Integrations"],"tags":[]},{"location":"integrations/#customizing-token-budget-and-cooldown","level":3,"title":"Customizing Token Budget and Cooldown","text":"<p>Edit the PreToolUse command to change the token budget or cooldown:</p> <pre><code>\"command\": \"ctx agent --budget 8000 --session $PPID 2&gt;/dev/null || true\"\n\"command\": \"ctx agent --budget 4000 --cooldown 5m --session $PPID 2&gt;/dev/null || true\"\n</code></pre> <p>The <code>--session $PPID</code> flag isolates the cooldown per session — <code>$PPID</code> resolves to the Claude Code process PID, so concurrent sessions don't interfere. The default cooldown is 10 minutes; use <code>--cooldown 0</code> to disable it.</p>","path":["AI Tool Integrations"],"tags":[]},{"location":"integrations/#verifying-setup","level":3,"title":"Verifying Setup","text":"<ol> <li>Start a new Claude Code session</li> <li>Ask: \"Do you remember?\"</li> <li>Claude should cite specific context:</li> <li>Current tasks from <code>.context/TASKS.md</code></li> <li>Recent decisions or learnings</li> <li>Previous session topics from <code>.context/sessions/</code></li> </ol>","path":["AI Tool Integrations"],"tags":[]},{"location":"integrations/#troubleshooting","level":3,"title":"Troubleshooting","text":"Issue Solution Context not loading Check <code>ctx</code> is in PATH: <code>which ctx</code> No sessions saved Verify <code>.claude/settings.local.json</code> has <code>SessionEnd</code> hook Hook errors Check script permissions: <code>chmod +x .claude/hooks/*.sh</code> Missing sessions dir Create it: <code>mkdir -p .context/sessions</code>","path":["AI Tool Integrations"],"tags":[]},{"location":"integrations/#manual-context-load","level":3,"title":"Manual Context Load","text":"<p>If hooks aren't working, manually load context:</p> <pre><code># Get context packet\nctx agent --budget 4000\n\n# Or paste into conversation\ncat .context/TASKS.md\n</code></pre>","path":["AI Tool Integrations"],"tags":[]},{"location":"integrations/#agent-skills","level":3,"title":"Agent Skills","text":"<p><code>ctx init</code> installs Agent Skills to <code>.claude/skills/</code> following the agentskills.io specification. These are invoked in Claude Code with <code>/skill-name</code>.</p>","path":["AI Tool Integrations"],"tags":[]},{"location":"integrations/#context-skills","level":4,"title":"Context Skills","text":"Skill Description <code>/ctx-status</code> Show context summary (tasks, decisions, learnings) <code>/ctx-agent</code> Get AI-optimized context packet <code>/ctx-drift</code> Detect and fix context drift (structural + semantic) <code>/ctx-alignment-audit</code> Audit doc claims against playbook instructions <code>/ctx-save</code> Save current session to <code>.context/sessions/</code> <code>/ctx-reflect</code> Review session and suggest what to persist","path":["AI Tool Integrations"],"tags":[]},{"location":"integrations/#context-persistence-skills","level":4,"title":"Context Persistence Skills","text":"Command Description <code>/ctx-add-task</code> Add a task to TASKS.md <code>/ctx-add-learning</code> Add a learning to LEARNINGS.md <code>/ctx-add-decision</code> Add a decision with context/rationale/consequences <code>/ctx-add-convention</code> Add a coding convention to CONVENTIONS.md <code>/ctx-archive</code> Archive completed tasks","path":["AI Tool Integrations"],"tags":[]},{"location":"integrations/#session-history-skills","level":4,"title":"Session History Skills","text":"Command Description <code>/ctx-recall</code> Browse AI session history <code>/ctx-journal-enrich</code> Enrich a journal entry with frontmatter/tags <code>/ctx-journal-enrich-all</code> Batch-enrich all unenriched journal entries","path":["AI Tool Integrations"],"tags":[]},{"location":"integrations/#blogging-skills","level":4,"title":"Blogging Skills","text":"<p>Blogging is a Better Way of Creating Release Notes</p> <p>The blogging workflow can also double as generating release notes:</p> <p>AI reads your git commit history and creates a \"narrative\", which is essentially what a release note is for.</p> Command Description <code>/ctx-blog</code> Generate blog post from recent activity <code>/ctx-blog-changelog</code> Generate blog post from commit range with theme","path":["AI Tool Integrations"],"tags":[]},{"location":"integrations/#development-skills","level":4,"title":"Development Skills","text":"Command Description <code>/ctx-loop</code> Generate a Ralph Loop iteration script <code>/ctx-prompt-audit</code> Analyze session logs for vague prompts","path":["AI Tool Integrations"],"tags":[]},{"location":"integrations/#usage-examples","level":4,"title":"Usage Examples","text":"<pre><code>/ctx-status\n/ctx-add-learning \"Token refresh requires explicit cache invalidation\"\n/ctx-journal-enrich twinkly-stirring-kettle\n</code></pre> <p>Skills support partial matching where applicable (e.g., session slugs).</p>","path":["AI Tool Integrations"],"tags":[]},{"location":"integrations/#cursor-ide","level":2,"title":"Cursor IDE","text":"<p>Cursor can use context files through its system prompt or by reading  files directly.</p>","path":["AI Tool Integrations"],"tags":[]},{"location":"integrations/#setup","level":3,"title":"Setup","text":"<pre><code># Generate Cursor configuration\nctx hook cursor\n\n# Initialize context\nctx init --minimal\n</code></pre>","path":["AI Tool Integrations"],"tags":[]},{"location":"integrations/#configuration","level":3,"title":"Configuration","text":"<p>Add to Cursor settings (<code>.cursor/settings.json</code>):</p> <pre><code>// split to multiple lines for readability\n{\n  \"ai.systemPrompt\": \"Read .context/TASKS.md and \n  .context/CONVENTIONS.md before responding. \n  Follow rules in .context/CONSTITUTION.md.\",\n}\n</code></pre>","path":["AI Tool Integrations"],"tags":[]},{"location":"integrations/#usage","level":3,"title":"Usage","text":"<ol> <li>Open your project in Cursor</li> <li>Context files are available in the file tree</li> <li>Reference them in prompts:     \"Check .context/DECISIONS.md for our approach to...\"</li> </ol>","path":["AI Tool Integrations"],"tags":[]},{"location":"integrations/#manual-context-injection","level":3,"title":"Manual Context Injection","text":"<p>For more control, paste context directly:</p> <pre><code># Get AI-ready packet\nctx agent --budget 4000 | pbcopy  # macOS\nctx agent --budget 4000 | xclip  # Linux\n</code></pre> <p>Paste into Cursor's chat.</p>","path":["AI Tool Integrations"],"tags":[]},{"location":"integrations/#aider","level":2,"title":"Aider","text":"<p>Aider works well with context files through its <code>--read</code> flag.</p>","path":["AI Tool Integrations"],"tags":[]},{"location":"integrations/#setup_1","level":3,"title":"Setup","text":"<pre><code># Generate Aider configuration\nctx hook aider\n\n# Initialize context\nctx init\n</code></pre>","path":["AI Tool Integrations"],"tags":[]},{"location":"integrations/#configuration_1","level":3,"title":"Configuration","text":"<p>Create <code>.aider.conf.yml</code>:</p> <pre><code>read:\n  - .context/CONSTITUTION.md\n  - .context/TASKS.md\n  - .context/CONVENTIONS.md\n  - .context/DECISIONS.md\n</code></pre>","path":["AI Tool Integrations"],"tags":[]},{"location":"integrations/#usage_1","level":3,"title":"Usage","text":"<pre><code># Start Aider (reads context files automatically)\naider\n\n# Or specify files explicitly\naider --read .context/TASKS.md --read .context/CONVENTIONS.md\n</code></pre>","path":["AI Tool Integrations"],"tags":[]},{"location":"integrations/#with-watch-mode","level":3,"title":"With Watch Mode","text":"<p>Run <code>ctx watch</code> alongside Aider to capture context updates:</p> <pre><code># Terminal 1: Run Aider\naider 2&gt;&amp;1 | tee /tmp/aider.log\n\n# Terminal 2: Watch for context updates\nctx watch --log /tmp/aider.log\n</code></pre>","path":["AI Tool Integrations"],"tags":[]},{"location":"integrations/#github-copilot","level":2,"title":"GitHub Copilot","text":"<p>Copilot reads open files for context. Keep context files open or reference  them in comments.</p>","path":["AI Tool Integrations"],"tags":[]},{"location":"integrations/#setup_2","level":3,"title":"Setup","text":"<pre><code># Generate Copilot tips\nctx hook copilot\n\n# Initialize context\nctx init --minimal\n</code></pre>","path":["AI Tool Integrations"],"tags":[]},{"location":"integrations/#usage-patterns","level":3,"title":"Usage Patterns","text":"<p>Pattern 1: Keep context files open</p> <p>Open <code>.context/CONVENTIONS.md</code> in a split pane. Copilot will reference it.</p> <p>Pattern 2: Reference in comments</p> <pre><code>// See .context/CONVENTIONS.md for naming patterns\n// Following decision in .context/DECISIONS.md: Use PostgreSQL\n\nfunction getUserById(id: string) {\n  // Copilot now has context\n}\n</code></pre> <p>Pattern 3: Paste context into Copilot Chat</p> <pre><code>ctx agent --budget 2000\n</code></pre> <p>Paste output into Copilot Chat for context-aware responses.</p>","path":["AI Tool Integrations"],"tags":[]},{"location":"integrations/#windsurf-ide","level":2,"title":"Windsurf IDE","text":"<p>Windsurf supports custom instructions and file-based context.</p>","path":["AI Tool Integrations"],"tags":[]},{"location":"integrations/#setup_3","level":3,"title":"Setup","text":"<pre><code># Generate Windsurf configuration\nctx hook windsurf\n\n# Initialize context\nctx init\n</code></pre>","path":["AI Tool Integrations"],"tags":[]},{"location":"integrations/#configuration_2","level":3,"title":"Configuration","text":"<p>Add to Windsurf settings:</p> <pre><code>// Split to multiple lines for readability\n{\n  \"ai.customInstructions\": \"Always read .context/CONSTITUTION.md first. \n  Check .context/TASKS.md for current work. \n  Follow patterns in .context/CONVENTIONS.md.\"\n}\n</code></pre>","path":["AI Tool Integrations"],"tags":[]},{"location":"integrations/#usage_2","level":3,"title":"Usage","text":"<p>Context files appear in the file tree. Reference them when chatting:</p> <ul> <li>\"What's in our task list?\" → AI reads <code>.context/TASKS.md</code></li> <li>\"What convention do we use for naming?\" → AI reads <code>.context/CONVENTIONS.md</code></li> </ul>","path":["AI Tool Integrations"],"tags":[]},{"location":"integrations/#generic-integration","level":2,"title":"Generic Integration","text":"<p>For any AI tool that can read files, use these patterns:</p>","path":["AI Tool Integrations"],"tags":[]},{"location":"integrations/#manual-context-loading","level":3,"title":"Manual Context Loading","text":"<pre><code># Get full context\nctx load\n\n# Get AI-optimized packet\nctx agent --budget 8000\n\n# Get specific file\ncat .context/TASKS.md\n</code></pre>","path":["AI Tool Integrations"],"tags":[]},{"location":"integrations/#system-prompt-template","level":3,"title":"System Prompt Template","text":"<pre><code>You are working on a project with persistent context in .context/\n\nBefore responding:\n1. Read .context/CONSTITUTION.md - NEVER violate these rules\n2. Check .context/TASKS.md for current work\n3. Follow .context/CONVENTIONS.md patterns\n4. Reference .context/DECISIONS.md for architectural choices\n\nWhen you learn something new, note it for .context/LEARNINGS.md\nWhen you make a decision, document it for .context/DECISIONS.md\n</code></pre>","path":["AI Tool Integrations"],"tags":[]},{"location":"integrations/#automated-updates","level":3,"title":"Automated Updates","text":"<p>If your AI tool outputs to a log, use <code>ctx watch</code>:</p> <pre><code># Watch log file for context-update commands\nyour-ai-tool 2&gt;&amp;1 | tee /tmp/ai.log &amp;\nctx watch --log /tmp/ai.log\n</code></pre> <p>The AI can emit updates like:</p> <pre><code>&lt;context-update type=\"learning\"&gt;Important thing learned today&lt;/context-update&gt;\n&lt;context-update type=\"complete\"&gt;implement caching&lt;/context-update&gt;\n</code></pre>","path":["AI Tool Integrations"],"tags":[]},{"location":"integrations/#context-update-commands","level":2,"title":"Context Update Commands","text":"<p>The <code>ctx watch</code> command parses update commands from AI output. Use this format:</p> <pre><code>&lt;context-update type=\"TYPE\" [attributes]&gt;Content&lt;/context-update&gt;\n</code></pre>","path":["AI Tool Integrations"],"tags":[]},{"location":"integrations/#supported-types","level":3,"title":"Supported Types","text":"Type Target File Required Attributes <code>task</code> TASKS.md None <code>decision</code> DECISIONS.md <code>context</code>, <code>rationale</code>, <code>consequences</code> <code>learning</code> LEARNINGS.md <code>context</code>, <code>lesson</code>, <code>application</code> <code>convention</code> CONVENTIONS.md None <code>complete</code> TASKS.md None","path":["AI Tool Integrations"],"tags":[]},{"location":"integrations/#simple-format-tasks-conventions-complete","level":3,"title":"Simple Format (tasks, conventions, complete)","text":"<pre><code>&lt;context-update type=\"task\"&gt;Implement rate limiting&lt;/context-update&gt;\n&lt;context-update type=\"convention\"&gt;Use kebab-case for files&lt;/context-update&gt;\n&lt;context-update type=\"complete\"&gt;rate limiting&lt;/context-update&gt;\n</code></pre>","path":["AI Tool Integrations"],"tags":[]},{"location":"integrations/#structured-format-learnings-decisions","level":3,"title":"Structured Format (learnings, decisions)","text":"<p>Learnings and decisions support structured attributes for better documentation:</p> <p>Learning with full structure:</p> <pre><code>&lt;context-update type=\"learning\"\n  context=\"Debugging Claude Code hooks\"\n  lesson=\"Hooks receive JSON via stdin, not environment variables\"\n  application=\"Use jq to parse: COMMAND=$(echo $INPUT | jq -r .tool_input.command)\"\n&gt;Hook Input Format&lt;/context-update&gt;\n</code></pre> <p>Decision with full structure:</p> <pre><code>&lt;context-update type=\"decision\"\n  context=\"Need a caching layer for API responses\"\n  rationale=\"Redis is fast, well-supported, and team has experience\"\n  consequences=\"Must provision Redis infrastructure; team training on Redis patterns\"\n&gt;Use Redis for caching&lt;/context-update&gt;\n</code></pre> <p>Learnings require: <code>context</code>, <code>lesson</code>, <code>application</code> attributes. Decisions require: <code>context</code>, <code>rationale</code>, <code>consequences</code> attributes. Updates missing required attributes are rejected with an error.</p>","path":["AI Tool Integrations"],"tags":[]},{"location":"integrations/#usage-with-ctx-watch","level":3,"title":"Usage with ctx watch","text":"<pre><code># Pipe AI output through watch\nyour-ai-tool | ctx watch\n\n# Or watch a log file\nctx watch --log /tmp/ai-output.log\n\n# Preview without applying\nctx watch --dry-run\n</code></pre>","path":["AI Tool Integrations"],"tags":[]},{"location":"prompting-guide/","level":1,"title":"Prompting Guide","text":"","path":["Prompting Guide"],"tags":[]},{"location":"prompting-guide/#prompting-guide","level":2,"title":"Prompting Guide","text":"<p>Effective prompts for working with AI assistants in <code>ctx</code>-enabled projects.</p> <p>Tip</p> <p>AI assistants may not automatically read context files.</p> <p>The right prompt triggers the right behavior. </p> <p>This guide documents prompts that reliably produce good results.</p>","path":["Prompting Guide"],"tags":[]},{"location":"prompting-guide/#session-start","level":2,"title":"Session Start","text":"","path":["Prompting Guide"],"tags":[]},{"location":"prompting-guide/#do-you-remember","level":3,"title":"\"Do you remember?\"","text":"<p>Triggers the AI to silently read <code>TASKS.md</code>, <code>DECISIONS.md</code>, <code>LEARNINGS.md</code>, and <code>sessions/</code> before responding with a structured readback:</p> <ol> <li>Last session: most recent session topic and date</li> <li>Active work: pending or in-progress tasks</li> <li>Recent context: 1-2 recent decisions or learnings</li> <li>Next step: offer to continue or ask what to focus on</li> </ol> <p>Use this at the start of every important session.</p> <pre><code>Do you remember what we were working on?\n</code></pre> <p>This question implies prior context exists. The AI checks files rather than admitting ignorance. The expected response cites specific context (session names, task counts, decisions), not vague summaries.</p> <p>If the AI instead narrates its discovery process (\"Let me check if there are files...\"), it has not loaded <code>CLAUDE.md</code> or <code>AGENT_PLAYBOOK.md</code> properly.</p>","path":["Prompting Guide"],"tags":[]},{"location":"prompting-guide/#whats-the-current-state","level":3,"title":"\"What's the current state?\"","text":"<p>Prompts reading of <code>TASKS.md</code>, recent sessions, and status overview.</p> <p>Use this when resuming work after a break.</p> <p>Variants:</p> <ul> <li>\"Where did we leave off?\"</li> <li>\"What's in progress?\"</li> <li>\"Show me the open tasks\"</li> </ul>","path":["Prompting Guide"],"tags":[]},{"location":"prompting-guide/#during-work","level":2,"title":"During Work","text":"","path":["Prompting Guide"],"tags":[]},{"location":"prompting-guide/#why-doesnt-x-work","level":3,"title":"\"Why doesn't X work?\"","text":"<p>This triggers root cause analysis rather than surface-level fixes.</p> <p>Use this when something fails unexpectedly.</p> <p>Framing as \"why\" encourages investigation before action. The AI will trace  through code, check configurations, and identify the actual cause.</p> <p>Real Example</p> <p>\"Why can't I run /ctx-save?\" led to discovering missing permissions in settings.local.json bootstrapping—a fix that benefited all users.</p>","path":["Prompting Guide"],"tags":[]},{"location":"prompting-guide/#is-this-consistent-with-our-decisions","level":3,"title":"\"Is this consistent with our decisions?\"","text":"<p>This prompts checking <code>DECISIONS.md</code> before implementing.</p> <p>Use this before making architectural choices.</p> <p>Variants:</p> <ul> <li>\"Check if we've decided on this before\"</li> <li>\"Does this align with our conventions?\"</li> </ul>","path":["Prompting Guide"],"tags":[]},{"location":"prompting-guide/#what-would-break-if-we","level":3,"title":"\"What would break if we...\"","text":"<p>This triggers defensive thinking and impact analysis.</p> <p>Use this before making significant changes.</p> <pre><code>What would break if we change the Settings struct?\n</code></pre>","path":["Prompting Guide"],"tags":[]},{"location":"prompting-guide/#before-you-start-read-x","level":3,"title":"\"Before you start, read X\"","text":"<p>This ensures specific context is loaded before work begins.</p> <p>Use this when you know the relevant context exists in a specific file.</p> <pre><code>Before you start, read .context/sessions/2026-01-20-auth-discussion.md\n</code></pre>","path":["Prompting Guide"],"tags":[]},{"location":"prompting-guide/#scope-control","level":3,"title":"Scope Control","text":"<p>Constrain the AI to prevent sprawl. These are some of the most useful prompts in day-to-day work.</p> <pre><code>Only change files in internal/cli/add/. Nothing else.\n</code></pre> <pre><code>No new files. Modify the existing implementation.\n</code></pre> <pre><code>Keep the public API unchanged. Internal refactor only.\n</code></pre> <p>Use these when the AI tends to \"helpfully\" modify adjacent code, add documentation you didn't ask for, or create new abstractions.</p>","path":["Prompting Guide"],"tags":[]},{"location":"prompting-guide/#course-correction","level":3,"title":"Course Correction","text":"<p>Steer the AI when it goes off-track. Don't wait for it to finish a wrong approach.</p> <pre><code>Stop. That's not what I meant. Let me clarify.\n</code></pre> <pre><code>Let's step back. Explain what you're about to do before changing anything.\n</code></pre> <pre><code>Undo that last change and try a different approach.\n</code></pre> <p>These work because they interrupt momentum. Without explicit course correction, the AI tends to commit harder to a wrong path rather than reconsidering.</p>","path":["Prompting Guide"],"tags":[]},{"location":"prompting-guide/#reflection-and-persistence","level":2,"title":"Reflection and Persistence","text":"","path":["Prompting Guide"],"tags":[]},{"location":"prompting-guide/#what-did-we-learn","level":3,"title":"\"What did we learn?\"","text":"<p>This prompts reflection on the session and often triggers adding learnings to <code>LEARNINGS.md</code>.</p> <p>Use this after completing a task or debugging session.</p> <p>This is an explicit reflection prompt. The AI will summarize insights and often offer to persist them.</p>","path":["Prompting Guide"],"tags":[]},{"location":"prompting-guide/#add-this-as-a-learningdecision","level":3,"title":"\"Add this as a learning/decision\"","text":"<p>This is an explicit persistence request.</p> <p>Use this when you have discovered something worth remembering.</p> <pre><code>Add this as a learning: \"JSON marshal escapes angle brackets by default\"\n\n# or simply.\nAdd this as a learning.\n# and let the AI autonomously infer and summarize.\n</code></pre>","path":["Prompting Guide"],"tags":[]},{"location":"prompting-guide/#save-context-before-we-end","level":3,"title":"\"Save context before we end\"","text":"<p>This triggers context persistence before the session closes.</p> <p>Use it at the end of the session or before switching topics.</p> <p>Variants:</p> <ul> <li>\"Let's persist what we did\"</li> <li>\"Update the context files\"</li> <li><code>/ctx-save</code> (Agent Skill in Claude Code)</li> </ul>","path":["Prompting Guide"],"tags":[]},{"location":"prompting-guide/#exploration-and-research","level":2,"title":"Exploration and Research","text":"","path":["Prompting Guide"],"tags":[]},{"location":"prompting-guide/#explore-the-codebase-for-x","level":3,"title":"\"Explore the codebase for X\"","text":"<p>This triggers thorough codebase search rather than guessing.</p> <p>Use this when you need to understand how something works.</p> <p>This works because \"Explore\" signals that investigation is needed,  not immediate action.</p>","path":["Prompting Guide"],"tags":[]},{"location":"prompting-guide/#how-does-x-work-in-this-codebase","level":3,"title":"\"How does X work in this codebase?\"","text":"<p>This prompts reading actual code rather than explaining general concepts.</p> <p>Use this to understand the existing implementation.</p> <pre><code>How does session saving work in this codebase?\n</code></pre>","path":["Prompting Guide"],"tags":[]},{"location":"prompting-guide/#find-all-places-where-x","level":3,"title":"\"Find all places where X\"","text":"<p>This triggers a comprehensive search across the codebase.</p> <p>Use this before refactoring or understanding the impact.</p>","path":["Prompting Guide"],"tags":[]},{"location":"prompting-guide/#meta-and-process","level":2,"title":"Meta and Process","text":"","path":["Prompting Guide"],"tags":[]},{"location":"prompting-guide/#what-should-we-document-from-this","level":3,"title":"\"What should we document from this?\"","text":"<p>This prompts identifying learnings, decisions, and conventions worth persisting.</p> <p>Use this after complex discussions or implementations.</p>","path":["Prompting Guide"],"tags":[]},{"location":"prompting-guide/#is-this-the-right-approach","level":3,"title":"\"Is this the right approach?\"","text":"<p>This invites the AI to challenge the current direction.</p> <p>Use this when you want a sanity check.</p> <p>This works because it allows AI to disagree.  AIs often default to agreeing; this prompt signals you want an  honest assessment.</p>","path":["Prompting Guide"],"tags":[]},{"location":"prompting-guide/#what-am-i-missing","level":3,"title":"\"What am I missing?\"","text":"<p>This prompts thinking about edge cases, overlooked requirements, or unconsidered approaches.</p> <p>Use this before finalizing a design or implementation.</p>","path":["Prompting Guide"],"tags":[]},{"location":"prompting-guide/#cli-commands-as-prompts","level":2,"title":"CLI Commands as Prompts","text":"<p>Asking the AI to run <code>ctx</code> commands is itself a prompt. These load context or trigger specific behaviors:</p> Command What it does \"Run <code>ctx status</code>\" Shows context summary, file presence, staleness \"Run <code>ctx agent</code>\" Loads token-budgeted context packet \"Run <code>ctx drift</code>\" Detects dead paths, stale files, missing context","path":["Prompting Guide"],"tags":[]},{"location":"prompting-guide/#agent-skills-claude-code","level":3,"title":"Agent Skills (Claude Code)","text":"<p>Skills are formalized prompts. Use them by name:</p> Skill When to use <code>/ctx-save</code> Persist session context at a milestone <code>/ctx-reflect</code> Structured reflection checkpoint <code>/ctx-recall</code> Browse session history for past discussions <code>/ctx-status</code> Quick context summary <code>/ctx-agent</code> Load full context packet <code>/consolidate</code> Detect and fix code-level drift <code>/update-docs</code> Sync docs and conventions after code changes <code>/verify</code> Verify before claiming work is complete <code>/qa</code> Run QA checks before committing <p>Skills combine a prompt, tool permissions, and domain knowledge into a single invocation. See Integrations for setup details.</p>","path":["Prompting Guide"],"tags":[]},{"location":"prompting-guide/#anti-patterns","level":2,"title":"Anti-Patterns","text":"<p>Based on our <code>ctx</code> development experience (i.e., \"sipping our own champagne\") so far, here are some prompts that tend to produce poor results:</p> Prompt Problem Better Alternative \"Fix this\" Too vague, may patch symptoms \"Why is this failing?\" \"Make it work\" Encourages quick hacks \"What's the right way to solve this?\" \"Just do it\" Skips planning \"Plan this, then implement\" \"You should remember\" Confrontational \"Do you remember?\" \"Obviously...\" Discourages questions State the requirement directly \"Idiomatic X\" Triggers language priors \"Follow project conventions\" \"Implement everything\" No phasing, sprawl risk Break into tasks, implement one at a time \"You should know this\" Assumes context is loaded \"Before you start, read X\"","path":["Prompting Guide"],"tags":[]},{"location":"prompting-guide/#quick-reference","level":2,"title":"Quick Reference","text":"Goal Prompt Load context \"Do you remember?\" Resume work \"What's the current state?\" Debug \"Why doesn't X work?\" Validate \"Is this consistent with our decisions?\" Impact analysis \"What would break if we...\" Reflect \"What did we learn?\" Persist \"Add this as a learning\" Explore \"How does X work in this codebase?\" Sanity check \"Is this the right approach?\" Completeness \"What am I missing?\" Constrain scope \"Only change files in X. Nothing else.\" Course correct \"Stop. That's not what I meant.\" Check health \"Run <code>ctx drift</code>\" Save context <code>/ctx-save</code>","path":["Prompting Guide"],"tags":[]},{"location":"prompting-guide/#explore-plan-implement","level":2,"title":"Explore → Plan → Implement","text":"<p>For non-trivial work, name the phase you want:</p> <pre><code>Explore src/auth and summarize the current flow.\nThen propose a plan. After I approve, implement with tests.\n</code></pre> <p>This prevents the AI from jumping straight to code. The three phases map to different modes of thinking:</p> <ul> <li>Explore: read, search, understand — no changes</li> <li>Plan: propose approach, trade-offs, scope — no changes</li> <li>Implement: write code, run tests, verify — changes</li> </ul> <p>Small fixes skip straight to implement. Complex or uncertain work benefits from all three.</p>","path":["Prompting Guide"],"tags":[]},{"location":"prompting-guide/#prompts-by-task-type","level":2,"title":"Prompts by Task Type","text":"<p>Different tasks need different prompt structures. The pattern: symptom + location + verification.</p>","path":["Prompting Guide"],"tags":[]},{"location":"prompting-guide/#bugfix","level":3,"title":"Bugfix","text":"<pre><code>Users report search returns empty results for queries with hyphens.\nReproduce in src/search/. Write a failing test for \"foo-bar\",\nfix the root cause, run: go test ./internal/search/...\n</code></pre>","path":["Prompting Guide"],"tags":[]},{"location":"prompting-guide/#refactor","level":3,"title":"Refactor","text":"<pre><code>Inspect src/auth/ and list duplication hotspots.\nPropose a refactor plan scoped to one module.\nAfter approval, remove duplication without changing behavior.\nAdd a test if coverage is missing. Run: make audit\n</code></pre>","path":["Prompting Guide"],"tags":[]},{"location":"prompting-guide/#research","level":3,"title":"Research","text":"<pre><code>Explore the request flow around src/api/.\nSummarize likely bottlenecks with evidence.\nPropose 2-3 hypotheses. Do not implement yet.\n</code></pre>","path":["Prompting Guide"],"tags":[]},{"location":"prompting-guide/#docs","level":3,"title":"Docs","text":"<pre><code>Update docs/cli-reference.md to reflect the new --format flag.\nConfirm the flag exists in the code and the example works.\n</code></pre> <p>Notice each prompt includes what to verify and how. Without that, you get \"should work now\" instead of evidence.</p>","path":["Prompting Guide"],"tags":[]},{"location":"prompting-guide/#writing-tasks-as-prompts","level":2,"title":"Writing Tasks as Prompts","text":"<p>Tasks in <code>TASKS.md</code> are indirect prompts to the AI. How you write them shapes how the AI approaches the work.</p>","path":["Prompting Guide"],"tags":[]},{"location":"prompting-guide/#state-the-deliverable-not-just-steps","level":3,"title":"State the Deliverable, Not Just Steps","text":"<p>Bad task (implementation-focused): <pre><code>- [ ] T1.1.0: Parser system\n  - [ ] Define data structures\n  - [ ] Implement line parser\n  - [ ] Implement session grouper\n</code></pre></p> <p>The AI may complete all subtasks but miss the actual goal. What does \"Parser system\" deliver to the user?</p> <p>Good task (deliverable-focused): <pre><code>- [ ] T1.1.0: Parser CLI command\n  **Deliverable**: `ctx recall list` command that shows parsed sessions\n  - [ ] Define data structures\n  - [ ] Implement line parser\n  - [ ] Implement session grouper\n</code></pre></p> <p>Now the AI knows the subtasks serve a specific user-facing deliverable.</p>","path":["Prompting Guide"],"tags":[]},{"location":"prompting-guide/#use-acceptance-criteria","level":3,"title":"Use Acceptance Criteria","text":"<p>For complex tasks, add explicit \"done when\" criteria:</p> <pre><code>- [ ] T2.0: Authentication system\n  **Done when**:\n  - [ ] User can register with email\n  - [ ] User can log in and get a token\n  - [ ] Protected routes reject unauthenticated requests\n</code></pre> <p>This prevents premature \"task complete\" when only the implementation details are done but the feature doesn't actually work.</p>","path":["Prompting Guide"],"tags":[]},{"location":"prompting-guide/#subtasks-parent-task","level":3,"title":"Subtasks ≠ Parent Task","text":"<p>Completing all subtasks does not mean the parent task is complete.</p> <p>The parent task describes what the user gets. Subtasks describe how to build it.</p> <p>Always re-read the parent task description before marking it complete. Verify the stated deliverable exists and works.</p>","path":["Prompting Guide"],"tags":[]},{"location":"prompting-guide/#contributing","level":2,"title":"Contributing","text":"<p>Found a prompt that works well? Open an issue or PR with:</p> <ol> <li>The prompt text</li> <li>What behavior it triggers</li> <li>When to use it</li> <li>Why it works (optional but helpful)</li> </ol>","path":["Prompting Guide"],"tags":[]},{"location":"security/","level":1,"title":"Security","text":"","path":["Security"],"tags":[]},{"location":"security/#reporting-vulnerabilities","level":2,"title":"Reporting Vulnerabilities","text":"<p>At <code>ctx</code> we take security very seriously.</p> <p>If you discover a security vulnerability in <code>ctx</code>, please report it responsibly.</p> <p>Do NOT open a public issue for security vulnerabilities.</p>","path":["Security"],"tags":[]},{"location":"security/#email","level":3,"title":"Email","text":"<p>Send details to security@ctx.ist</p>","path":["Security"],"tags":[]},{"location":"security/#github-private-reporting","level":3,"title":"GitHub Private Reporting","text":"<ol> <li>Go to the Security tab</li> <li>Click \"Report a vulnerability\"</li> <li>Provide a detailed description</li> </ol>","path":["Security"],"tags":[]},{"location":"security/#what-to-include","level":3,"title":"What to Include","text":"<ul> <li>Description of the vulnerability</li> <li>Steps to reproduce</li> <li>Potential impact</li> <li>Suggested fix (if any)</li> </ul>","path":["Security"],"tags":[]},{"location":"security/#response-timeline","level":3,"title":"Response Timeline","text":"Stage Timeframe Acknowledgment Within 48 hours Initial assessment Within 7 days Resolution target Within 30 days (depending on severity)","path":["Security"],"tags":[]},{"location":"security/#trust-model","level":2,"title":"Trust Model","text":"<p><code>ctx</code> operates within a single trust boundary: the local filesystem.</p> <p>The person who authors <code>.context/</code> files is the same person who runs the agent that reads them. There is no remote input, no shared state, and no server component.</p> <p>This means:</p> <ul> <li><code>ctx</code> does not sanitize context files for prompt injection. This is a   deliberate design choice, not an oversight. The files are authored by the   developer who owns the machine: Sanitizing their own instructions back   to them would be counterproductive.</li> <li>If you place adversarial instructions in your own <code>.context/</code> files,   your agent will follow them. This is expected behavior. You control the   context; the agent trusts it.</li> </ul> <p>Shared Repositories</p> <p>In shared repositories, <code>.context/</code> files should be reviewed in code review (the same way you would review CI/CD config or Makefiles). A malicious contributor could add harmful instructions to <code>CONSTITUTION.md</code> or <code>TASKS.md</code>.</p>","path":["Security"],"tags":[]},{"location":"security/#security-design","level":2,"title":"Security Design","text":"<p><code>ctx</code> is designed with security in mind:</p> <ul> <li>No secrets in context: The constitution explicitly forbids storing   secrets, tokens, API keys, or credentials in <code>.context/</code> files</li> <li>Local only: <code>ctx</code> runs entirely locally with no external network calls</li> <li>No code execution: ctx reads and writes Markdown files only; it does   not execute arbitrary code</li> <li>Git-tracked: Core context files are meant to be committed, so they should   never contain sensitive data. Exception: <code>sessions/</code> and <code>journal/</code> contain   raw conversation data and should be gitignored</li> </ul>","path":["Security"],"tags":[]},{"location":"security/#best-practices","level":2,"title":"Best Practices","text":"<ol> <li>Review before committing: Always review <code>.context/</code> files before committing</li> <li>Use .gitignore: If you must store sensitive notes locally,    add them to <code>.gitignore</code></li> <li>Drift detection: Run <code>ctx drift</code> to check for potential issues</li> </ol>","path":["Security"],"tags":[]},{"location":"security/#attribution","level":2,"title":"Attribution","text":"<p>We appreciate responsible disclosure and will acknowledge security researchers who report valid vulnerabilities (unless they prefer to remain anonymous).</p>","path":["Security"],"tags":[]},{"location":"session-journal/","level":1,"title":"The Session Journal","text":"<p>Important Security Note</p> <p>Session journals contain sensitive data such as file contents, commands, API keys, internal discussions,  error messages with stack traces, and more. </p> <p>The <code>.context/journal-site/</code> directory MUST be <code>..gitignore</code>d.</p> <ul> <li>DO NOT host your journal publicly.</li> <li>DO NOT commit your journal files to version control.</li> </ul>","path":["The Session Journal"],"tags":[]},{"location":"session-journal/#browse-your-session-history","level":2,"title":"Browse Your Session History","text":"<p><code>ctx</code>'s Session Journal turns your AI coding sessions into a browsable,  searchable, and editable archive.</p>","path":["The Session Journal"],"tags":[]},{"location":"session-journal/#quick-start","level":2,"title":"Quick Start","text":"<p>After using <code>ctx</code> for a couple of sessions, you can generate a  journal site with:</p> <pre><code># Export all sessions to markdown\nctx recall export --all\n\n# Generate and serve the journal site\nctx journal site --serve\n</code></pre> <p>Then open http://localhost:8000 to browse your sessions.</p>","path":["The Session Journal"],"tags":[]},{"location":"session-journal/#what-you-get","level":2,"title":"What You Get","text":"<p>The Session Journal gives you:</p> <ul> <li>Browsable history: Navigate through all your AI sessions by date</li> <li>Full conversations: See every message, tool use, and result</li> <li>Token usage: Track how many tokens each session consumed</li> <li>Search: Find sessions by content, project, or date</li> <li>Dark mode: Easy on the eyes for late-night archaeology</li> </ul> <p>Each session page includes the following sections:</p> Section Content Metadata Date, time, duration, model, project, git branch Summary Space for your notes (editable) Tool Usage Which tools were used and how often Conversation Full transcript with timestamps","path":["The Session Journal"],"tags":[]},{"location":"session-journal/#the-workflow","level":2,"title":"The Workflow","text":"","path":["The Session Journal"],"tags":[]},{"location":"session-journal/#1-export-sessions","level":3,"title":"1. Export Sessions","text":"<pre><code># Export all sessions from current project\nctx recall export --all\n\n# Export sessions from all projects\nctx recall export --all --all-projects\n\n# Export a specific session by ID\nctx recall export abc123\n\n# Re-export (updates conversation, preserves YAML frontmatter)\nctx recall export --all\n\n# Full overwrite (discards frontmatter enrichments)\nctx recall export --all --force\n</code></pre> <p>Exported sessions go to <code>.context/journal/</code> as editable Markdown files.</p>","path":["The Session Journal"],"tags":[]},{"location":"session-journal/#2-generate-the-site","level":3,"title":"2. Generate the Site","text":"<pre><code># Generate site structure\nctx journal site\n\n# Generate and build static HTML\nctx journal site --build\n\n# Generate and serve locally\nctx journal site --serve\n\n# Custom output directory\nctx journal site --output ~/my-journal\n</code></pre> <p>The site is generated in <code>.context/journal-site/</code> by default.</p>","path":["The Session Journal"],"tags":[]},{"location":"session-journal/#3-browse-and-search","level":3,"title":"3. Browse and Search","text":"<p>Open http://localhost:8000 after running <code>--serve</code>.</p> <ul> <li>Use the sidebar to navigate by date</li> <li>Use search (<code>/</code> key) to find specific content</li> <li>Click any session to see the full conversation</li> </ul>","path":["The Session Journal"],"tags":[]},{"location":"session-journal/#editing-sessions","level":2,"title":"Editing Sessions","text":"<p>Exported sessions are plain Markdown in <code>.context/journal/</code>. You can:</p> <ul> <li>Add summaries - Fill in the <code>## Summary</code> section</li> <li>Add notes - Insert your own commentary anywhere</li> <li>Highlight key moments - Use Markdown formatting</li> <li>Delete noise - Remove irrelevant tool outputs</li> </ul> <p>After editing, regenerate the site:</p> <pre><code>ctx journal site --serve\n</code></pre> <p>Re-exporting preserves your enrichments</p> <p>Running <code>ctx recall export --all</code> updates existing files by default: YAML frontmatter (topics, type, outcome, etc.) is preserved, and only the conversation content is regenerated.</p> <p>Use <code>--skip-existing</code> to leave existing files completely untouched, or <code>--force</code> to overwrite everything (frontmatter will be lost).</p>","path":["The Session Journal"],"tags":[]},{"location":"session-journal/#large-sessions","level":2,"title":"Large Sessions","text":"<p>Sessions with many messages (200+) are automatically split into multiple parts  for better browser performance. Navigation links connect the parts:</p> <pre><code>session-abc123.md      (Part 1 of 3)\nsession-abc123-p2.md   (Part 2 of 3)\nsession-abc123-p3.md   (Part 3 of 3)\n</code></pre>","path":["The Session Journal"],"tags":[]},{"location":"session-journal/#suggestion-sessions","level":2,"title":"Suggestion Sessions","text":"<p>Claude Code generates \"suggestion\" sessions for auto-complete prompts. These  are separated in the index under a \"Suggestions\" section to keep your main  session list focused.</p>","path":["The Session Journal"],"tags":[]},{"location":"session-journal/#enriching-journal-entries","level":2,"title":"Enriching Journal Entries","text":"<p>Raw exported sessions contain basic metadata (date, time, project) but lack the structured information needed for effective search, filtering, and analysis. Journal enrichment adds semantic metadata that transforms a flat archive into a searchable knowledge base.</p>","path":["The Session Journal"],"tags":[]},{"location":"session-journal/#why-enrich","level":3,"title":"Why Enrich?","text":"<p>Without enrichment, you have timestamps and raw conversations. With enrichment:</p> <ul> <li>Find sessions by topic: \"Show me all auth-related sessions\"</li> <li>Filter by outcome: \"What did I abandon vs complete?\"</li> <li>Track technology usage: \"When did I last work with PostgreSQL?\"</li> <li>Identify key files: Jump directly to the files discussed</li> <li>Get summaries: Understand what happened without reading transcripts</li> </ul>","path":["The Session Journal"],"tags":[]},{"location":"session-journal/#the-frontmatter-schema","level":3,"title":"The Frontmatter Schema","text":"<p>Enriched entries begin with YAML frontmatter:</p> <pre><code>---\ntitle: \"Implement caching layer\"\ndate: 2026-01-27\ntype: feature\noutcome: completed\ntopics:\n  - caching\n  - performance\ntechnologies:\n  - go\n  - redis\nlibraries:\n  - go-redis/redis\nkey_files:\n  - internal/cache/redis.go\n  - internal/cache/memory.go\n---\n</code></pre> Field Required Description <code>title</code> Yes Descriptive title (not the session slug) <code>date</code> Yes Session date (YYYY-MM-DD) <code>type</code> Yes Session type (see below) <code>outcome</code> Yes How the session ended (see below) <code>topics</code> No Subject areas discussed <code>technologies</code> No Languages, databases, frameworks <code>libraries</code> No Specific packages or libraries used <code>key_files</code> No Important files created or modified <p>Type values:</p> Type When to use <code>feature</code> Building new functionality <code>bugfix</code> Fixing broken behavior <code>refactor</code> Restructuring without behavior change <code>exploration</code> Research, learning, experimentation <code>debugging</code> Investigating issues <code>documentation</code> Writing docs, comments, README <p>Outcome values:</p> Outcome Meaning <code>completed</code> Goal achieved <code>partial</code> Some progress, work continues <code>abandoned</code> Stopped pursuing this approach <code>blocked</code> Waiting on external dependency","path":["The Session Journal"],"tags":[]},{"location":"session-journal/#using-ctx-journal-enrich","level":3,"title":"Using <code>/ctx-journal-enrich</code>","text":"<p>The <code>/ctx-journal-enrich</code> skill automates enrichment by analyzing conversation content and proposing metadata.</p> <p>Invoke by session identifier:</p> <pre><code>/ctx-journal-enrich twinkly-stirring-kettle\n/ctx-journal-enrich twinkly\n/ctx-journal-enrich 2026-01-24\n/ctx-journal-enrich 76fe2ab9\n</code></pre> <p>The skill will:</p> <ol> <li>Find the matching journal file</li> <li>Read and analyze the conversation</li> <li>Propose frontmatter (type, topics, outcome, technologies)</li> <li>Generate a 2-3 sentence summary</li> <li>Extract decisions, learnings, and tasks mentioned</li> <li>Show a diff and ask for confirmation before writing</li> </ol>","path":["The Session Journal"],"tags":[]},{"location":"session-journal/#before-and-after","level":3,"title":"Before and After","text":"<p>Before enrichment:</p> <pre><code># twinkly-stirring-kettle\n\n**ID**: abc123-def456\n**Date**: 2026-01-24\n**Time**: 14:30:00\n...\n\n## Summary\n\n[Add your summary of this session]\n\n## Conversation\n...\n</code></pre> <p>After enrichment:</p> <pre><code>---\ntitle: \"Add Redis caching to API endpoints\"\ndate: 2026-01-24\ntype: feature\noutcome: completed\ntopics:\n  - caching\n  - api-performance\ntechnologies:\n  - go\n  - redis\nkey_files:\n  - internal/api/middleware/cache.go\n  - internal/cache/redis.go\n---\n\n# twinkly-stirring-kettle\n\n**ID**: abc123-def456\n**Date**: 2026-01-24\n**Time**: 14:30:00\n...\n\n## Summary\n\nImplemented Redis-based caching middleware for frequently accessed API endpoints.\nAdded cache invalidation on writes and configurable TTL per route. Reduced\n the average response time from 200ms to 15ms for cached routes.\n\n## Decisions\n\n* Used Redis over in-memory cache for horizontal scaling\n* Chose per-route TTL configuration over global setting\n\n## Learnings\n\n* Redis WATCH command prevents race conditions during cache invalidation\n\n## Conversation\n...\n</code></pre>","path":["The Session Journal"],"tags":[]},{"location":"session-journal/#enrichment-and-site-generation","level":3,"title":"Enrichment and Site Generation","text":"<p>The journal site generator uses enriched metadata for better organization:</p> <ul> <li>Titles appear in navigation instead of slugs</li> <li>Summaries provide context in the index</li> <li>Topics enable filtering (when using search)</li> <li>Types allow grouping by work category</li> </ul> <p>Future improvements will add topic-based navigation and outcome filtering to the generated site.</p>","path":["The Session Journal"],"tags":[]},{"location":"session-journal/#batch-enrichment","level":3,"title":"Batch Enrichment","text":"<p>To enrich multiple sessions, process them one at a time:</p> <pre><code># List unenriched sessions (those without frontmatter)\ngrep -L \"^---$\" .context/journal/*.md | head -10\n</code></pre> <p>Then run <code>/ctx-journal-enrich</code> on each. Enrichment is intentionally interactive to ensure accuracy.</p>","path":["The Session Journal"],"tags":[]},{"location":"session-journal/#context-monitor","level":2,"title":"Context Monitor","text":"<p>The Context Monitor (<code>context-watch.sh</code>) is a terminal-based tool that shows real-time token usage for your active Claude Code session. Run it in a separate terminal window to keep an eye on context consumption.</p>","path":["The Session Journal"],"tags":[]},{"location":"session-journal/#setup","level":3,"title":"Setup","text":"<p>After running <code>ctx init</code>, the monitor script is available at:</p> <pre><code>.context/tools/context-watch.sh\n</code></pre>","path":["The Session Journal"],"tags":[]},{"location":"session-journal/#usage","level":3,"title":"Usage","text":"<pre><code># Default: refresh every 10 seconds\n.context/tools/context-watch.sh\n\n# Custom refresh interval (5 seconds)\n.context/tools/context-watch.sh 5\n</code></pre> <p>The monitor displays:</p> <ul> <li>Progress bar with estimated token usage versus effective limit</li> <li>Color-coded status: green (healthy), yellow (monitor), red (save and end)</li> <li>Session info: file size, message count, last update time</li> <li>Remaining tokens: how much usable context is left</li> </ul> <p></p> <p></p>","path":["The Session Journal"],"tags":[]},{"location":"session-journal/#how-it-works","level":3,"title":"How It Works","text":"<p>The monitor finds the most recently modified session <code>JSONL</code> in <code>~/.claude/projects/</code>, estimates token count using a character-based heuristic (~30 chars per token for JSON content), and adds an overhead estimate for system prompts, tools, and skills that aren't in the JSONL.</p> Constant Value Meaning Model limit 200,000 Claude's context window Autocompact buffer 33,000 Reserved by Claude Code, not usable System overhead 20,000 System prompt + tools + skills + memory Effective limit 167,000 What you can actually use for conversation <p>Pair with the context checkpoint hook</p> <p>The monitor is for manual observation. For automated alerts within your session, <code>ctx init</code> also installs a <code>check-context-size.sh</code> hook that triggers the <code>/ctx-context-monitor</code> skill at adaptive intervals.</p>","path":["The Session Journal"],"tags":[]},{"location":"session-journal/#full-pipeline","level":2,"title":"Full Pipeline","text":"<p>The complete journal workflow has four stages. Each is idempotent — safe to re-run, and stages skip already-processed entries.</p> <pre><code>export → normalize → enrich → rebuild\n</code></pre> Stage Command / Skill What it does Skips if Export <code>ctx recall export --all</code> Converts session JSONL to Markdown <code>--skip-existing</code> flag Normalize <code>/ctx-journal-normalize</code> Fixes fence nesting and metadata tables <code>&lt;!-- normalized --&gt;</code> marker Enrich <code>/ctx-journal-enrich</code> Adds frontmatter, summaries, topics Frontmatter already present Rebuild <code>ctx journal site --build</code> Generates static HTML site —","path":["The Session Journal"],"tags":[]},{"location":"session-journal/#using-make-journal","level":3,"title":"Using <code>make journal</code>","text":"<p>If your project includes <code>Makefile.ctx</code> (deployed by <code>ctx init</code>), the first and last stages are combined:</p> <pre><code>make journal           # export + rebuild\n</code></pre> <p>After it runs, it reminds you to normalize and enrich in Claude Code:</p> <pre><code>Next steps (in Claude Code):\n  1. /ctx-journal-normalize  — fix markdown rendering (skips already normalized)\n  2. /ctx-journal-enrich     — add metadata per entry (skips if frontmatter exists)\n\nThen re-run: make journal\n</code></pre>","path":["The Session Journal"],"tags":[]},{"location":"session-journal/#normalizing-journal-entries","level":3,"title":"Normalizing Journal Entries","text":"<p>Raw exported sessions may have rendering issues: nested code fences, malformed metadata blocks, or broken lists. The <code>/ctx-journal-normalize</code> skill fixes these in the source files so the site renders correctly.</p> <pre><code>/ctx-journal-normalize\n</code></pre> <p>It backs up <code>.context/journal/</code> before modifying anything, and marks processed files with <code>&lt;!-- normalized: YYYY-MM-DD --&gt;</code> so re-runs skip them.</p> <p>Run normalize before enrich — the enrichment skill reads conversation content, and clean markdown produces better metadata extraction.</p>","path":["The Session Journal"],"tags":[]},{"location":"session-journal/#tips","level":2,"title":"Tips","text":"<p>Daily workflow: <pre><code># Export, browse, then enrich in Claude Code\nmake journal &amp;&amp; make journal-serve\n# Then in Claude Code: /ctx-journal-enrich &lt;session&gt;\n</code></pre></p> <p>After a productive session: <pre><code># Export just that session and add notes\nctx recall export &lt;session-id&gt;\n# Edit .context/journal/&lt;session&gt;.md\n# Regenerate: ctx journal site\n</code></pre></p> <p>Searching across all sessions: <pre><code># Use grep on the journal directory\ngrep -r \"authentication\" .context/journal/\n</code></pre></p>","path":["The Session Journal"],"tags":[]},{"location":"session-journal/#requirements","level":2,"title":"Requirements","text":"<p>The journal site uses zensical for static site generation:</p> <pre><code>pip install zensical\n</code></pre>","path":["The Session Journal"],"tags":[]},{"location":"session-journal/#see-also","level":2,"title":"See Also","text":"<ul> <li>ctx recall: Session discovery and listing</li> <li>ctx journal: Site generation commands</li> <li>Context Files: The <code>.context/</code> directory structure</li> </ul>","path":["The Session Journal"],"tags":[]},{"location":"versions/","level":1,"title":"Version History","text":"","path":["Version History"],"tags":[]},{"location":"versions/#version-history","level":2,"title":"Version History","text":"<p>Documentation snapshots for each release. Click a version to view the  docs as they were at that release.</p>","path":["Version History"],"tags":[]},{"location":"versions/#releases","level":2,"title":"Releases","text":"Version Release Date Documentation v0.3.0 2026-02-07 View docs v0.2.0 2026-02-01 View docs v0.1.2 2026-01-27 View docs v0.1.1 2026-01-26 View docs v0.1.0 2026-01-25 View docs","path":["Version History"],"tags":[]},{"location":"versions/#latest","level":2,"title":"Latest","text":"<p>The main documentation always reflects the latest development version.</p> <p>For the most recent stable release, see v0.3.0.</p>","path":["Version History"],"tags":[]},{"location":"versions/#changelog","level":2,"title":"Changelog","text":"<p>For detailed changes between versions, see the  GitHub Releases page.</p>","path":["Version History"],"tags":[]},{"location":"blog/","level":1,"title":"Blog","text":"<p>Stories, insights, and lessons learned from building and using ctx.</p>","path":["Blog"],"tags":[]},{"location":"blog/#posts","level":2,"title":"Posts","text":"","path":["Blog"],"tags":[]},{"location":"blog/#not-everything-is-a-skill","level":3,"title":"Not Everything Is a Skill","text":"<p>Jose Alekhinne / February 8, 2026</p> <p>I ran an 8-agent codebase audit and got actionable results. The natural instinct was to wrap the prompt as a <code>/ctx-audit</code> skill. Then I applied my own criteria from the skill trilogy: it failed all three tests. This post is about the difference between skills and recipes, why the attention budget applies to your skill library too, and why the best automation decision is sometimes not to automate.</p> <p>Topics: skill design, context engineering, automation discipline, recipes, agent teams</p>","path":["Blog"],"tags":[]},{"location":"blog/#the-anatomy-of-a-skill-that-works","level":3,"title":"The Anatomy of a Skill That Works","text":"<p>Jose Alekhinne / February 7, 2026</p> <p>I had 20 skills. Most were well-intentioned stubs: a description, a command, and a wish for the best. Then I rewrote all of them in a single session. Seven lessons emerged: quality gates prevent premature execution, negative triggers are load-bearing, examples set boundaries better than rules, and skills are contracts, not instructions. The practical companion to the previous two skill design posts.</p> <p>Topics: skill design, context engineering, quality gates, E/A/R framework, practical patterns</p>","path":["Blog"],"tags":[]},{"location":"blog/#you-cant-import-expertise","level":3,"title":"You Can't Import Expertise","text":"<p>Jose Alekhinne / February 5, 2026</p> <p>I found a well-crafted consolidation skill: four files, ten patterns, eight analysis dimensions. Applied my own E/A/R framework: 70% was noise. The template was thorough, correct, and almost entirely useless for my project. This post is about why good skills can't be copy-pasted, and how to grow them from your project's own drift history instead.</p> <p>Topics: skill adaptation, E/A/R framework, convention drift, consolidation, project-specific expertise</p>","path":["Blog"],"tags":[]},{"location":"blog/#skills-that-fight-the-platform","level":3,"title":"Skills That Fight the Platform","text":"<p>Jose Alekhinne / February 4, 2026</p> <p>AI coding agents ship with carefully designed system prompts. When custom skills conflict with those defaults, the AI has to reconcile contradictory instructions: The result is unpredictable. This post catalogues five conflict patterns discovered while building <code>ctx</code>: judgment suppression, redundant guidance, guilt-tripping, phantom dependencies, and universal triggers.</p> <p>Topics: context engineering, skill design, system prompts, antipatterns, AI safety primitives</p>","path":["Blog"],"tags":[]},{"location":"blog/#the-attention-budget-why-your-ai-forgets-what-you-just-told-it","level":3,"title":"The Attention Budget: Why Your AI Forgets What You Just Told It","text":"<p>Jose Alekhinne / February 3, 2026</p> <p>Every token you send to an AI consumes a finite resource: the attention budget. Understanding this constraint shaped every design decision in ctx: hierarchical file structure, explicit budgets, progressive disclosure, and filesystem-as-index. This post explains the theory and how ctx operationalizes it.</p> <p>Topics: attention mechanics, context engineering, progressive disclosure, ctx primitives, token budgets</p>","path":["Blog"],"tags":[]},{"location":"blog/#ctx-v020-the-archaeology-release","level":3,"title":"ctx v0.2.0: The Archaeology Release","text":"<p>Jose Alekhinne / February 1, 2026</p> <p>What if your AI could remember everything? Not just the current session, but every session. <code>ctx v0.2.0</code> introduces the recall and journal systems: making 86 commits of history searchable, exportable, and analyzable.  This post tells the story of why those features exist.</p> <p>Topics: session recall, journal system, structured entries, token budgets, meta-tools</p>","path":["Blog"],"tags":[]},{"location":"blog/#refactoring-with-intent-human-guided-sessions-in-ai-development","level":3,"title":"Refactoring with Intent: Human-Guided Sessions in AI Development","text":"<p>Jose Alekhinne / February 1, 2026</p> <p>The YOLO mode shipped 14 commands in a week. But technical debt  doesn't send invoices:it just waits. This is the story of what happened when  we stopped auto-accepting everything and started guiding the AI with intent:  27 commits across 4 days, a major version release, and lessons that apply far  beyond ctx.</p> <p>Topics: refactoring, code quality, documentation standards, module decomposition, YOLO versus intentional development</p>","path":["Blog"],"tags":[]},{"location":"blog/#building-ctx-using-ctx-a-meta-experiment-in-ai-assisted-development","level":3,"title":"Building ctx Using ctx: A Meta-Experiment in AI-Assisted Development","text":"<p>Jose Alekhinne / January 27, 2026</p> <p>What happens when you build a tool designed to give AI memory, using that very same tool to remember what you're building? This is the story of <code>ctx</code>: how <code>ctx</code> evolved from a hasty \"YOLO\" experiment to a disciplined system  for persistent AI context, and what we learned along the way.</p> <p>Topics: dogfooding, AI-assisted development, Ralph Loop, session persistence, architectural decisions</p>","path":["Blog"],"tags":[]},{"location":"blog/2026-01-27-building-ctx-using-ctx/","level":1,"title":"Building ctx Using ctx","text":"","path":["Building ctx Using ctx: A Meta-Experiment in AI-Assisted Development"],"tags":[]},{"location":"blog/2026-01-27-building-ctx-using-ctx/#a-meta-experiment-in-ai-assisted-development","level":2,"title":"A Meta-Experiment in AI-Assisted Development","text":"<p>Jose Alekhinne / 2026-01-27</p> <p>Can a tool design itself?</p> <p>What happens when you build a tool designed to give AI memory,  using that very same tool to remember what you are building? </p> <p>This is the story of <code>ctx</code>, how it evolved from a hasty \"YOLO mode\" experiment  to a disciplined system for persistent AI context, and what I have  learned along the way.</p> <p>Context is a Record</p> <p>Context is a persistent record.</p> <p>By \"context\", I don’t mean model memory or stored thoughts: </p> <p>I mean the durable record of decisions, learnings, and intent  that normally evaporates between sessions.</p>","path":["Building ctx Using ctx: A Meta-Experiment in AI-Assisted Development"],"tags":[]},{"location":"blog/2026-01-27-building-ctx-using-ctx/#ai-amnesia","level":2,"title":"AI Amnesia","text":"<p>Every developer who works with AI code generators knows the frustration:  you have a deep, productive session where the AI understands your codebase,  your conventions, your decisions. And then you close the terminal. </p> <p>Tomorrow; it's a blank slate. The AI has forgotten everything.</p> <p>That is \"reset amnesia\", and it's not just annoying: it's expensive. </p> <p>Every session starts with re-explaining context, re-reading files,  re-discovering decisions that were already made.</p> <p>I Needed Context</p> <p>I don't want to lose this discussion...  I am a brain-dead developer YOLO'ing my way out</p> <p>☝️ that's exactly what I said to Claude when I first started working on <code>ctx</code>.</p>","path":["Building ctx Using ctx: A Meta-Experiment in AI-Assisted Development"],"tags":[]},{"location":"blog/2026-01-27-building-ctx-using-ctx/#the-genesis","level":2,"title":"The Genesis","text":"<p>The project started as \"Active Memory\" (<code>amem</code>): a CLI tool to persist AI  context across sessions. </p> <p>The core idea was simple: create a <code>.context/</code> directory with structured  Markdown files for decisions, learnings, tasks, and conventions.  The AI reads these at session start and writes to them before the session ends.</p> <p>The first commit was just scaffolding. But within hours, the  Ralph Loop—an iterative AI development workflow—had produced  a working CLI:</p> <pre><code>feat(cli): implement amem init command\nfeat(cli): implement amem status command\nfeat(cli): implement amem add command\nfeat(cli): implement amem agent command\n...\n</code></pre> <p>Not one, not two, but a whopping fourteen core commands shipped in rapid  succession!</p> <p>I was YOLO'ing like there was no tomorrow:</p> <ul> <li>auto-accept every change, </li> <li>let the AI run free, </li> <li>ship features fast.</li> </ul>","path":["Building ctx Using ctx: A Meta-Experiment in AI-Assisted Development"],"tags":[]},{"location":"blog/2026-01-27-building-ctx-using-ctx/#the-meta-experiment-using-amem-to-build-amem","level":2,"title":"The Meta-Experiment: Using <code>amem</code> to Build <code>amem</code>","text":"<p>Here's where it gets interesting: On January 20<sup>th</sup>, I asked: </p> <p>\"Can I use <code>amem</code> to help you remember this context when I restart?\"</p> <p>The answer was yes—but with a gap: </p> <p>Autoload worked (via Claude Code's <code>PreToolUse</code> hook), but auto-save was  missing. If the user quit, with Ctrl+C, everything since the last manual save  was lost.</p> <p>That session became the first real test of the system. </p> <p>Here is the first session file we recorded:</p> <pre><code>## Key Discussion Points\n\n### 1. amem vs Ralph Loop - They're Separate Systems\n\n**User's question**: \"How do I use the binary to recreate this project?\"\n\n**Answer discovered**: amem is for context management, Ralph Loop is for \ndevelopment workflow. They're complementary but separate.\n\n### 2. Two Tiers of Context Persistence\n\n| Tier      | What                        | Why                           |\n|-----------|-----------------------------|-------------------------------|\n| Curated   | Learnings, decisions, tasks | Quick reload, token-efficient |\n| Full dump | Entire conversation         | Safety net, nothing lost      |\n\n| Where                  |\n|------------------------|\n| .context/*.md          |\n| .context/sessions/*.md |\n</code></pre> <p>This session file—written by the AI to preserve its own context—became the  template for how <code>ctx</code> handles session persistence.</p>","path":["Building ctx Using ctx: A Meta-Experiment in AI-Assisted Development"],"tags":[]},{"location":"blog/2026-01-27-building-ctx-using-ctx/#the-rename","level":2,"title":"The Rename","text":"<p>By January 21<sup>st</sup>, I realized \"Active Memory\" was too generic, and (arguably) too marketing-smelly. </p> <p>Besides, the binary was already called <code>ctx</code> (short for Context),  the directory was <code>.context/</code>, and the slash commands would be <code>/ctx-*</code>. </p> <p>So it followed that the project should be renamed to <code>ctx</code> to make things  make sense.</p> <p>The rename touched 100+ files but was clean—a find-and-replace with Go's  type system catching any misses.</p> <p>The git history tells the story:</p> <pre><code>0e8f6bb feat: rename amem to ctx and add Claude Code integration\n87dcfa1 README.\n4f0e195 feat: separate orchestrator directive from agent tasks\n</code></pre>","path":["Building ctx Using ctx: A Meta-Experiment in AI-Assisted Development"],"tags":[]},{"location":"blog/2026-01-27-building-ctx-using-ctx/#yolo-mode-fast-but-dangerous","level":2,"title":"YOLO Mode: Fast, But Dangerous","text":"<p>The Ralph Loop made feature development incredibly fast. </p> <p>But it created technical debt that I didn't notice until later.</p> <p>A comparison session on January 25<sup>th</sup> revealed the patterns:</p> YOLO Pattern What We Found <code>\"TASKS.md\"</code> scattered in 10 files Same string literal everywhere, no constants <code>dir + \"/\" + file</code> Should be <code>filepath.Join()</code> Monolithic <code>cli_test.go</code> (1500+ lines) Tests disconnected from implementations <code>package initcmd</code> in <code>init/</code> folder Go's \"init\" is reserved—subtle naming collision <p>Here is another analysis made by <code>ctx</code>:</p> <pre><code>● Based on my analysis, here are the key differences:\n\nYOLO Mode (Pre-040ce99)\n- Feature-first: Added slash commands, tests, templates rapidly\n- Scattered magic strings: \"TASKS.md\", \"decision\", \".context\" spread across files\n- Quick file creation: New files without organizational patterns\n- Working but inconsistent: Code functioned but lacked systematic structure\n\nHuman-Guided Mode (Post-040ce99)\n- Consolidation focus: Centralized constants in config package\n- Consistent naming: Dir, File, Filename, UpdateType prefixes\n- Self-referential constants: FileType map uses constants as keys, not literals\n- Proper path construction: filepath.Join() instead of +\"/\"+\n- Colocated tests: Tests next to implementations\n- Canonical naming: Package name = folder name\n</code></pre> <p>The fix required a human-guided refactoring session. I continued to do that before every major release, from that point on.</p> <p>We introduced <code>internal/config/config.go</code> with semantic prefixes:</p> <pre><code>const (\n    DirContext     = \".context\"\n    DirArchive     = \"archive\"\n    DirSessions    = \"sessions\"\n    FilenameTask   = \"TASKS.md\"\n    UpdateTypeTask = \"task\"\n)\n</code></pre> <p>What I begrudgingly learned was:  YOLO mode is effective for velocity but accumulates debt. </p> <p>So I took a mental note to schedule periodic consolidation sessions.</p>","path":["Building ctx Using ctx: A Meta-Experiment in AI-Assisted Development"],"tags":[]},{"location":"blog/2026-01-27-building-ctx-using-ctx/#the-dogfooding-test-that-failed","level":2,"title":"The Dogfooding Test That Failed","text":"<p>On January 21<sup>st</sup>, I ran an experiment: have another Claude instance rebuild  <code>ctx</code> from scratch using only the specs and <code>PROMPT.md</code>. </p> <p>The Ralph Loop ran, all tasks got checked off, the loop exited successfully.</p> <p>But the binary was broken!</p> <p>Commands just printed help text instead of executing. </p> <p>All tasks were marked \"complete\" but the implementation didn't work.</p> <p>Here's what <code>ctx</code> discovered:</p> <pre><code>## Key Findings\n\n### Dogfooding Binary Is Broken\n- Commands don't execute — they just print root help text\n- All tasks were marked complete but binary doesn't work\n- Lesson: \"tasks checked off\" ≠ \"implementation works\"\n</code></pre> <p>This was humbling—to say the least.</p> <p>I realized, I had the same blind spot in my own codebase: no integration tests that actually invoked the binary. </p> <p>So I added:</p> <ul> <li>Integration tests for all commands</li> <li>Coverage targets (60-80% per package)</li> <li>Smoke tests in CI</li> <li>A constitution rule: \"All code must pass tests before commit\"</li> </ul>","path":["Building ctx Using ctx: A Meta-Experiment in AI-Assisted Development"],"tags":[]},{"location":"blog/2026-01-27-building-ctx-using-ctx/#the-constitution-versus-conventions","level":2,"title":"The Constitution versus Conventions","text":"<p>As lessons accumulated, there was the temptation to add everything to  <code>CONSTITUTION.md</code> as \"inviolable rules\". </p> <p>But I resisted.</p> <p>The constitution should contain only truly inviolable invariants:</p> <ul> <li>Security (no secrets, no customer data)</li> <li>Quality (tests must pass)</li> <li>Process (decisions need records)</li> <li><code>ctx</code> invocation (always use <code>PATH</code>, never fallback)</li> </ul> <p>Everything else—coding style, file organization, naming  conventions—should go in to <code>CONVENTIONS.md</code>. </p> <p>Here's how <code>ctx</code> explained why the distinction was important: </p> <p>\"Overly strict constitution creates friction and gets ignored.  Conventions can be bent; constitution cannot.\" — Decision record, 2026-01-25</p>","path":["Building ctx Using ctx: A Meta-Experiment in AI-Assisted Development"],"tags":[]},{"location":"blog/2026-01-27-building-ctx-using-ctx/#hooks-harder-than-they-look","level":2,"title":"Hooks: Harder Than They Look","text":"<p>Claude Code hooks seemed simple: run a script before/after certain events. </p> <p>But I hit multiple gotchas:</p> <p>1. Key names matter</p> <pre><code>// WRONG - \"Invalid key in record\" error\n\"PreToolUseHooks\": [...]\n\n// RIGHT\n\"PreToolUse\": [...]\n</code></pre> <p>2. Blocking requires specific output</p> <pre><code># WRONG - just exits, doesn't block\nexit 1\n\n# RIGHT - JSON output + exit 0\necho '{\"decision\": \"block\", \"reason\": \"Use ctx from PATH\"}'\nexit 0\n</code></pre> <p>3. Go's JSON escaping</p> <p><code>json.Marshal</code> escapes <code>&gt;</code>, <code>&lt;</code>, <code>&amp;</code> as unicode (<code>\\u003e</code>) by default. </p> <p>When generating shell commands in JSON:</p> <pre><code>encoder := json.NewEncoder(file)\nencoder.SetEscapeHTML(false) // Prevent 2&gt;/dev/null → 2\\u003e/dev/null\n</code></pre> <p>4. Regex overfitting</p> <p>Our hook to block non-PATH <code>ctx</code> invocations initially matched too broadly:</p> <pre><code># WRONG - matches /home/user/ctx/internal/file.go (ctx as directory)\n(/home/|/tmp/|/var/)[^ ]*ctx[^ ]*\n\n# RIGHT - matches ctx as binary only\n(/home/|/tmp/|/var/)[^ ]*/ctx( |$)\n</code></pre>","path":["Building ctx Using ctx: A Meta-Experiment in AI-Assisted Development"],"tags":[]},{"location":"blog/2026-01-27-building-ctx-using-ctx/#the-session-files","level":2,"title":"The Session Files","text":"<p>By the time of this writing this project's <code>ctx</code> sessions (<code>.context/sessions/</code>)  contains 40+ files from this project's development.</p> <p>They are not part of the source code due to security, privacy, and size concerns.</p> <p>However, they are invaluable for the project's progress.</p> <p>Each session file is a timestamped Markdown with:</p> <ul> <li>Summary of what has been accomplished</li> <li>Key decisions made</li> <li>Learnings discovered</li> <li>Tasks for the next session</li> <li>Technical context (platform, versions)</li> </ul> <p>These files are not autoloaded (that would bust the token budget). </p> <p>They are what I see as the \"archaeological record\" of <code>ctx</code>: When the AI needs deeper information about why something was done, it digs into the sessions.</p> <p>Auto-generated session files use a naming convention:</p> <pre><code>2026-01-23-115432-session-prompt_input_exit-summary.md\n2026-01-25-220244-manual-save.md\n2026-01-27-052107-session-other-summary.md\n</code></pre> <p>Also, the <code>SessionEnd</code> hook captures transcripts automatically.  Even <code>Ctrl+C</code>is caught.</p>","path":["Building ctx Using ctx: A Meta-Experiment in AI-Assisted Development"],"tags":[]},{"location":"blog/2026-01-27-building-ctx-using-ctx/#the-decision-log-18-architectural-decisions","level":2,"title":"The Decision Log: 18 Architectural Decisions","text":"<p><code>ctx</code> helps record every significant architectural choice in  <code>.context/DECISIONS.md</code>. </p> <p>Here are some highlights:</p> <p>Reverse-chronological order (2026-01-27)</p> <pre><code>**Context**: With chronological order, oldest items consume tokens first, and\nnewest (most relevant) items risk being truncated.\n\n**Decision**: Use reverse-chronological order (newest first) for DECISIONS.md\nand LEARNINGS.md.\n</code></pre> <p>PATH over hardcoded paths (2026-01-21)</p> <pre><code>**Context**: Original implementation hardcoded absolute paths in hooks.\nThis breaks when sharing configs with other developers.\n\n**Decision**: Hooks use `ctx` from PATH. `ctx init` checks PATH before \nproceeding.\n</code></pre> <p>Generic core with Claude enhancements (2026-01-20)</p> <pre><code>**Context**: ctx should work with any AI tool, but Claude Code users could\nbenefit from deeper integration.\n\n**Decision**: Keep ctx generic as the core tool, but provide optional\nClaude Code-specific enhancements.\n</code></pre>","path":["Building ctx Using ctx: A Meta-Experiment in AI-Assisted Development"],"tags":[]},{"location":"blog/2026-01-27-building-ctx-using-ctx/#the-learning-log-24-gotchas-and-insights","level":2,"title":"The Learning Log: 24 Gotchas and Insights","text":"<p>The <code>.context/LEARNINGS.md</code> file captures gotchas that would otherwise be  forgotten. Each has Context, Lesson, and Application sections:</p> <p>CGO on ARM64</p> <pre><code>**Context**: `go test` failed with \n`gcc: error: unrecognized command-line option '-m64'`\n**Lesson**: On ARM64 Linux, CGO causes cross-compilation issues. \nAlways use `CGO_ENABLED=0`.\n</code></pre> <p>Claude Code skills format</p> <pre><code>**Lesson**: Claude Code skills are Markdown files in .claude/commands/ with `YAML`\nfrontmatter (*description, argument-hint, allowed-tools*). Body is the prompt.\n</code></pre> <p>\"Do you remember?\" handling</p> <pre><code>**Lesson**: In a `ctx`-enabled project, \"*do you remember?*\" \nhas an obvious meaning:\ncheck the `.context/` files. Don't ask for clarification—just do it.\n</code></pre>","path":["Building ctx Using ctx: A Meta-Experiment in AI-Assisted Development"],"tags":[]},{"location":"blog/2026-01-27-building-ctx-using-ctx/#task-archives-the-completed-work","level":2,"title":"Task Archives: The Completed Work","text":"<p>Completed tasks are archived to <code>.context/archive/</code> with timestamps. </p> <p>The archive from January 23<sup>rd</sup> shows 13 phases of work:</p> <ul> <li>Phase 1: Project Scaffolding (Go module, Cobra CLI)</li> <li>Phase 2-4: Core Commands    (init, status, agent, add, complete, drift, sync, compact, watch, hook)</li> <li>Phase 5: Session Management (save, list, load, parse, --extract)</li> <li>Phase 6: Claude Code Integration (hooks, settings, CLAUDE.md handling)</li> <li>Phase 7: Testing &amp; Verification</li> <li>Phase 8: Task Archival</li> <li>Phase 9: Slash Commands</li> <li>Phase 9b: Ralph Loop Integration</li> <li>Phase 10: Project Rename</li> <li>Phase 11: Documentation</li> <li>Phase 12: Timestamp Correlation</li> <li>Phase 13: Rich Context Entries</li> </ul> <p>That's an impressive 173 commits across 8 days of development.</p>","path":["Building ctx Using ctx: A Meta-Experiment in AI-Assisted Development"],"tags":[]},{"location":"blog/2026-01-27-building-ctx-using-ctx/#what-i-learned-about-ai-assisted-development","level":2,"title":"What I Learned About AI-Assisted Development","text":"<p>1. Memory changes everything</p> <p>When the AI remembers decisions, it doesn't repeat mistakes. When it knows  your conventions, it follows them. </p> <p><code>ctx</code> makes the AI a better collaborator because it's not starting from zero.</p> <p>2. Two-tier persistence works</p> <p>Curated context (<code>DECISIONS.md</code>, <code>LEARNINGS.md</code>, <code>TASKS.md</code>) is for  quick reload. </p> <p>Full session dumps are for archaeology. </p> <p>It's a futile effort to try to fit everything in the token budget.</p> <p>Persist more, load less.</p> <p>3. YOLO mode has its place</p> <p>For rapid prototyping, letting the AI run free is effective. </p> <p>But I had to schedule consolidation sessions. </p> <p>Technical debt accumulates silently.</p> <p>4. The constitution should be small</p> <p>Only truly inviolable rules go in <code>CONSTITUTION.md</code>.  Everything else is a convention. </p> <p>If you put too much in the constitution, it will get ignored.</p> <p>5. Verification is non-negotiable</p> <p>\"All tasks complete\" means nothing if you haven't run the tests. </p> <p>Integration tests that invoke the actual binary caught bugs that  the unit tests missed.</p> <p>6. Session files are underrated</p> <p>The ability to grep through 40 session files and find exactly when and why a  decision was made helped me a lot. </p> <p>It's not about loading them into context: It is about having them when you  need them.</p>","path":["Building ctx Using ctx: A Meta-Experiment in AI-Assisted Development"],"tags":[]},{"location":"blog/2026-01-27-building-ctx-using-ctx/#the-future-recall-system","level":2,"title":"The Future: Recall System","text":"<p>The next phase of <code>ctx</code> is the Recall System:</p> <ul> <li>Parser: Parse session capture markdowns, enrich with JSONL data</li> <li>Renderer: Goldmark + Chroma for syntax highlighting, dark mode UI</li> <li>Server: Local HTTP server for browsing sessions</li> <li>Search: Inverted index for searching across sessions</li> <li>CLI: <code>ctx recall serve &lt;path&gt;</code> to start the server</li> </ul> <p>The goal is to make the archaeological record browsable—not just <code>grep</code>-able.</p> <p>Because not everyone always lives in the terminal—me included.</p>","path":["Building ctx Using ctx: A Meta-Experiment in AI-Assisted Development"],"tags":[]},{"location":"blog/2026-01-27-building-ctx-using-ctx/#conclusion","level":2,"title":"Conclusion","text":"<p>Building <code>ctx</code> using ctx was a meta-experiment in AI-assisted development. </p> <p>I learned that memory isn't just convenient—it's transformative:</p> <ul> <li>An AI that remembers your decisions doesn't repeat mistakes.</li> <li>An AI that knows your conventions doesn't need them re-explained.</li> </ul> <p>If you are reading this, chances are that you already have heard about <code>ctx</code>.</p> <ul> <li><code>ctx</code> is open source at  github.com/ActiveMemory/ctx,</li> <li>and the documentation lives at ctx.ist.</li> </ul> <p>Session Records are a Gold Mine</p> <p>By the time of this writing, I have more than 70 megabytes of text-only session capture, spread across &gt;100 markdown and JSONL files.</p> <pre><code>I am analyzing, synthesizing, encriching them with AI, running RAG\n(*Retrieval-Augmented Generation*) models on them, and the outcome\nsurprises me every day.\n</code></pre> <p>If you are a mere mortal tired of reset amnesia, give <code>ctx</code> a try. </p> <p>And when you do, check <code>.context/sessions/</code> sometime. </p> <p>The archaeological record might surprise you.</p> <p>This blog post was written with the help of <code>ctx</code> with full access to the  <code>ctx</code> session files, decision log, learning log, task archives, and  git history of <code>ctx</code>—The meta continues.</p>","path":["Building ctx Using ctx: A Meta-Experiment in AI-Assisted Development"],"tags":[]},{"location":"blog/2026-02-01-ctx-v0.2.0-the-archaeology-release/","level":1,"title":"ctx v0.2.0: The Archaeology Release","text":"","path":["ctx v0.2.0: The Archaeology Release"],"tags":[]},{"location":"blog/2026-02-01-ctx-v0.2.0-the-archaeology-release/#digging-through-the-past-to-build-the-future","level":2,"title":"Digging Through the Past to Build the Future","text":"<p>Jose Alekhinne / 2026-02-01</p> <p>What if your AI could remember everything?</p> <p>Not just the current session, but every session:</p> <ul> <li>Every decision made,</li> <li>every mistake avoided, </li> <li>every path not taken.</li> </ul> <p>That's what v0.2.0 delivers.</p> <p>Between <code>v0.1.2</code> and <code>v0.2.0</code>, 86 commits landed across 5 days. </p> <p>The release notes list features and fixes. </p> <p>This post tells the story of why those features exist, and what  building them taught me.</p> <p>This isn't a changelog: It is an explanation of intent.</p>","path":["ctx v0.2.0: The Archaeology Release"],"tags":[]},{"location":"blog/2026-02-01-ctx-v0.2.0-the-archaeology-release/#the-problem-amnesia-isnt-just-session-level","level":2,"title":"The Problem: Amnesia Isn't Just Session-Level","text":"<p>v0.1.0 solved reset amnesia: </p> <p>The AI now remembers decisions, learnings, and tasks across sessions. </p> <p>But a new problem emerged, which I can sum up as: \"I (the human) am not AI\".</p> <p>Frankly, I couldn't remember what the AI remembered.</p> <p>In the course of days, I realized session transcripts piled up in  <code>.context/sessions/</code>; I was <code>grep</code>ping, <code>JSONL</code> files with thousands of lines... Raw tool calls, assistant responses, user messages... all interleaved. </p> <p>Valuable context effectively buried in machine-readable noise.</p> <p>I found myself grepping through files to answer questions like:</p> <ul> <li>\"When did we decide to use constants instead of literals?\"</li> <li>\"What was the session where we fixed the hook regex?\"</li> <li>\"How did the <code>embed.go</code> split actually happen?\"</li> </ul> <p>Fate is Whimsical</p> <p>The irony was painful:  I built a tool to prevent AI amnesia, but I was suffering from  human amnesia about what happened in AI sessions.</p> <p>This was the moment <code>ctx</code> stopped being just an AI tool and started needing to support the human on the other side of the loop.</p>","path":["ctx v0.2.0: The Archaeology Release"],"tags":[]},{"location":"blog/2026-02-01-ctx-v0.2.0-the-archaeology-release/#the-solution-recall-and-journal","level":2,"title":"The Solution: Recall and Journal","text":"<p>v0.2.0 introduces two interconnected systems.</p> <p>They solve different problems; and only work well together.</p>","path":["ctx v0.2.0: The Archaeology Release"],"tags":[]},{"location":"blog/2026-02-01-ctx-v0.2.0-the-archaeology-release/#ctx-recall-browse-your-past","level":3,"title":"<code>ctx recall</code>: Browse Your Past","text":"<pre><code># List all sessions for this project\nctx recall list\n\n# Show a specific session\nctx recall show gleaming-wobbling-sutherland\n\n# See the full transcript\nctx recall show gleaming-wobbling-sutherland --full\n````\n\nThe `recall` system parses Claude Code's JSONL transcripts and presents\nthem in a human-readable format:\n\n| Session                       | Date       | Turns | Duration |\n|-------------------------------|------------|-------|----------|\n| tender-painting-sundae        | 2026-01-29 | 3     | &lt;1m      |\n| crystalline-gliding-willow    | 2026-01-29 | 3     | &lt;1m      |\n| declarative-hugging-snowglobe | 2026-01-31 | 2     | &lt;1m      |\n\nSlugs are auto-generated from session IDs (*memorable names instead of\nUUIDs*). The goal (*as the name implies*) is **recall**, not archival accuracy.\n\n!!! note \"2,121 lines of new code\"\n    The `ctx recall` feature was the largest single addition:\n    parser library, CLI commands, test suite, and slash command.\n\n### `ctx journal`: From Raw to Rich\n\nListing sessions isn't enough. The transcripts are still unwieldy.\n\nRecall answers *what happened*.\nJournal answers *what mattered*.\n\n```bash\n# Export sessions to editable Markdown\nctx recall export --all\n\n# Generate a static site from journal entries\nctx journal site\n\n# Serve it locally\nctx serve\n</code></pre> <p>The exported files land in <code>.context/journal/</code>:</p> <pre><code>.context/journal/\n├── 2026-01-28-proud-sleeping-cook-6e535360.md\n├── 2026-01-29-tender-painting-sundae-b14ddaaa.md\n├── 2026-01-29-crystalline-gliding-willow-ff7fd67d.md\n└── 2026-01-31-declarative-hugging-snowglobe-4549026d.md\n</code></pre> <p>Each file is a structured Markdown document ready for enrichment.</p> <p>They are meant to be read, edited, and reasoned about;  not just stored.</p>","path":["ctx v0.2.0: The Archaeology Release"],"tags":[]},{"location":"blog/2026-02-01-ctx-v0.2.0-the-archaeology-release/#the-meta-slash-commands-for-self-analysis","level":2,"title":"The Meta: Slash Commands for Self-Analysis","text":"<p>The journal system includes four slash commands that use Claude to analyze and synthesize session history:</p> Command Purpose <code>/ctx-journal-enrich</code> Add frontmatter, topics, tags <code>/ctx-blog</code> Generate blog post from activity <code>/ctx-blog-changelog</code> Generate changelog from commits <p>This very post was drafted using <code>/ctx-blog</code>. The previous post about refactoring was drafted the same way.</p> <p>So, yes: The meta continues: <code>ctx</code> now helps write posts about <code>ctx</code>.</p> <p>With the current release, <code>ctx</code> is no longer just recording history: It is participating in its interpretation.</p>","path":["ctx v0.2.0: The Archaeology Release"],"tags":[]},{"location":"blog/2026-02-01-ctx-v0.2.0-the-archaeology-release/#the-structure-decisions-as-first-class-citizens","level":2,"title":"The Structure: Decisions as First-Class Citizens","text":"<p><code>v0.1.0</code> let you add decisions with a simple command:</p> <pre><code>ctx add decision \"Use PostgreSQL\"\n</code></pre> <p>But sessions showed a pattern: decisions added this way were incomplete. Context was missing. Rationale was vague. Consequences were never stated.</p> <p>Once recall and journaling existed, this weakness became impossible to ignore. Structure stopped being optional.</p> <p><code>v0.2.0</code> enforces structure:</p> <pre><code>ctx add decision \"Use PostgreSQL\" \\\n  --context \"Need a reliable database for user data\" \\\n  --rationale \"ACID compliance, team familiarity, strong ecosystem\" \\\n  --consequences \"Need to set up connection pooling, team training\"\n</code></pre> <p>All three flags are required. No more placeholder text. </p> <p>Every decision is now a proper Architecture Decision Record (*ADR), not a note.</p> <p>The same enforcement applies to learnings, too:</p> <pre><code>ctx add learning \"CGO breaks ARM64 builds\" \\\n  --context \"go test failed with gcc errors on ARM64\" \\\n  --lesson \"Always use CGO_ENABLED=0 for cross-platform builds\" \\\n  --application \"Added to Makefile and CI config\"\n</code></pre> <p>Structured entries are prompts to the AI</p> <p>When the AI reads a decision with full context, rationale, and consequences, it understands the why, not just the what.</p> <p>One-liners teach nothing.</p>","path":["ctx v0.2.0: The Archaeology Release"],"tags":[]},{"location":"blog/2026-02-01-ctx-v0.2.0-the-archaeology-release/#the-order-newest-first","level":2,"title":"The Order: Newest First","text":"<p>A subtle but important change: <code>DECISIONS.md</code> and <code>LEARNINGS.md</code> now use reverse-chronological order.</p> <p>One reason is token budgets, obviously; another reason is to help your fellow human (i.e., the Author): Earlier decisions are more likely to be relevant, and they are more likely to have more emphasis on the project. So it follows that they should be read first.</p> <p>But back to AI:</p> <p>When the AI reads a file, it reads from the top. If the token budget is tight, old content gets truncated. As in any good engineering practice, it's always about the tradeoffs.</p> <p>Reverse order ensures the most recent—and most relevant—context is always loaded first.</p>","path":["ctx v0.2.0: The Archaeology Release"],"tags":[]},{"location":"blog/2026-02-01-ctx-v0.2.0-the-archaeology-release/#the-index-quick-reference-tables","level":2,"title":"The Index: Quick Reference Tables","text":"<p><code>DECISIONS.md</code> and <code>LEARNINGS.md</code> now include auto-generated indexes.</p> <ul> <li>For AI agents, the index allows scanning without reading full entries.</li> <li>For humans, it's a table of contents.</li> </ul> <p>The same structure serves two very different readers.</p>","path":["ctx v0.2.0: The Archaeology Release"],"tags":[]},{"location":"blog/2026-02-01-ctx-v0.2.0-the-archaeology-release/#the-configuration-contextrc","level":2,"title":"The Configuration: .contextrc","text":"<p>Projects can now customize ctx behavior via <code>.contextrc</code>.</p> <p>This makes ctx usable in real teams, not just personal projects.</p> <p>Priority order: CLI flags &gt; environment variables &gt; .contextrc &gt; defaults</p>","path":["ctx v0.2.0: The Archaeology Release"],"tags":[]},{"location":"blog/2026-02-01-ctx-v0.2.0-the-archaeology-release/#the-flags-global-cli-options","level":2,"title":"The Flags: Global CLI Options","text":"<p>Three new global flags work with any command.</p> <p>These enable automation: </p> <p>CI pipelines, scripts, and long-running tools can now integrate  <code>ctx</code> without hacks or workarounds.</p>","path":["ctx v0.2.0: The Archaeology Release"],"tags":[]},{"location":"blog/2026-02-01-ctx-v0.2.0-the-archaeology-release/#the-refactoring-under-the-hood","level":2,"title":"The Refactoring: Under the Hood","text":"<p>These aren't user-visible changes.</p> <p>They are the kind of work you only appreciate later, when everything else becomes easier to build.</p>","path":["ctx v0.2.0: The Archaeology Release"],"tags":[]},{"location":"blog/2026-02-01-ctx-v0.2.0-the-archaeology-release/#what-we-learned-building-v020","level":2,"title":"What We Learned Building v0.2.0","text":"","path":["ctx v0.2.0: The Archaeology Release"],"tags":[]},{"location":"blog/2026-02-01-ctx-v0.2.0-the-archaeology-release/#1-raw-data-isnt-knowledge","level":3,"title":"1. Raw Data Isn't Knowledge","text":"<p><code>JSONL</code> transcripts contain everything, and I mean \"everything\": They even contain hidden system messages that Anthropic injects to the LLM's conversation to treat humans better: It's immense.</p> <p>But \"everything\" isn't useful until it is transformed into something a human can reason about.</p>","path":["ctx v0.2.0: The Archaeology Release"],"tags":[]},{"location":"blog/2026-02-01-ctx-v0.2.0-the-archaeology-release/#2-enforcement-documentation","level":3,"title":"2. Enforcement &gt; Documentation","text":"<p>The Prompt is a Guideline</p> <p>The code is more what you'd call 'guidelines' than actual rules.</p> <p>—Hector Barbossa</p> <p>Rules written in Markdown are suggestions.</p> <p>Rules enforced by the CLI shape behavior; both for humans and AI.</p>","path":["ctx v0.2.0: The Archaeology Release"],"tags":[]},{"location":"blog/2026-02-01-ctx-v0.2.0-the-archaeology-release/#3-token-budget-is-ux","level":3,"title":"3. Token Budget Is UX","text":"<p>File order decides what the AI sees.</p> <p>That makes it a user experience concern, not an implementation detail.</p>","path":["ctx v0.2.0: The Archaeology Release"],"tags":[]},{"location":"blog/2026-02-01-ctx-v0.2.0-the-archaeology-release/#4-meta-tools-compound","level":3,"title":"4. Meta-Tools Compound","text":"<p>Tools that analyze their own development tend to generalize well.</p> <p>The journal system started as a way to understand ctx itself.</p> <p>It immediately became useful for everything else.</p>","path":["ctx v0.2.0: The Archaeology Release"],"tags":[]},{"location":"blog/2026-02-01-ctx-v0.2.0-the-archaeology-release/#v020-in-the-numbers","level":2,"title":"v0.2.0 in The Numbers","text":"<p>This was a heavy release. The numbers reflect that:</p> Metric v0.1.2 v0.2.0 Commits since last - 86 New commands 15 21 Slash commands 7 11 Lines of Go ~6,500 ~9,200 Session files (this project) 40 54 <p>The binary grew. The capability grew more.</p>","path":["ctx v0.2.0: The Archaeology Release"],"tags":[]},{"location":"blog/2026-02-01-ctx-v0.2.0-the-archaeology-release/#whats-next","level":2,"title":"What's Next","text":"<p>But those are future posts.</p> <p>This one was about making the past usable.</p>","path":["ctx v0.2.0: The Archaeology Release"],"tags":[]},{"location":"blog/2026-02-01-ctx-v0.2.0-the-archaeology-release/#get-started","level":2,"title":"Get Started","text":"<pre><code>go install github.com/ActiveMemory/ctx/cmd/ctx@latest\nctx init\n</code></pre> <p>The Archaeological Record</p> <p><code>v0.2.0</code> is the archaeology release because it makes the past accessible.</p> <p>Session transcripts aren't just logs anymore: They are a searchable, exportable, analyzable record of how your project evolved.</p> <p>The AI remembers. Now you can too.</p> <p>This blog post was generated with the help of <code>ctx</code> using the <code>/ctx-blog</code> slash command, with full access to git history, session files, decision logs, and learning logs from the v0.2.0 development window.</p>","path":["ctx v0.2.0: The Archaeology Release"],"tags":[]},{"location":"blog/2026-02-01-refactoring-with-intent/","level":1,"title":"Refactoring with Intent","text":"","path":["Refactoring with Intent: Human-Guided Sessions in AI Development"],"tags":[]},{"location":"blog/2026-02-01-refactoring-with-intent/#human-guided-sessions-in-ai-development","level":2,"title":"Human-Guided Sessions in AI Development","text":"<p>Jose Alekhinne / 2026-02-01</p> <p>What happens when you slow down?</p> <p>YOLO mode shipped 14 commands in a week. But technical debt doesn't send invoices—it just waits.</p> <p>This is the story of what happened when I stopped auto-accepting everything and started guiding the AI with intent. The result: 27 commits across 4 days, a major version release, and lessons that apply far beyond <code>ctx</code>.</p> <p>The Refactoring Window</p> <p>January 28 - February 1, 2026</p> <p>From commit <code>bb1cd20</code> to the v0.2.0 release merge. (this window matters more than the individual commits: it's where intent replaced velocity.)</p>","path":["Refactoring with Intent: Human-Guided Sessions in AI Development"],"tags":[]},{"location":"blog/2026-02-01-refactoring-with-intent/#the-velocity-trap","level":2,"title":"The Velocity Trap","text":"<p>In the previous post, I documented the YOLO mode that birthed <code>ctx</code>: auto-accept everything, let the AI run free, ship features fast. It worked: until it didn't.</p> <p>The codebase had accumulated patterns I didn't notice during the sprint:</p> YOLO Pattern Where Found Why It Hurts <code>\"TASKS.md\"</code> as literal 10+ files One typo = silent failure <code>dir + \"/\" + file</code> Path construction Breaks on Windows Monolithic <code>embed.go</code> 150+ lines, 5 concerns Untestable, hard to extend Inconsistent docstrings Everywhere AI can't learn project conventions <p>I didn't see these during YOLO mode because, honestly, I wasn't looking.</p> <p>Auto-accept means auto-ignore.</p> <p>In YOLO mode, every file you open looks fine until you try to change it.  </p> <p>In contrast, refactoring mode is when you start paying attention to that  hidden friction.</p>","path":["Refactoring with Intent: Human-Guided Sessions in AI Development"],"tags":[]},{"location":"blog/2026-02-01-refactoring-with-intent/#the-shift-from-velocity-to-intent","level":2,"title":"The Shift: From Velocity to Intent","text":"<p>On January 28<sup>th</sup>, I changed the workflow:</p> <ol> <li>Read every diff before accepting</li> <li>Ask \"why this way?\" before committing</li> <li>Document patterns, not just features</li> </ol> <p>The first commit of this era was telling:</p> <pre><code>feat: add structured attributes to context-update XML format\n</code></pre> <p>Not a new feature—a refinement:</p> <p>The XML format for context updates needed <code>type</code> and <code>timestamp</code> attributes. </p> <p>YOLO mode would have shipped something that worked. Intentional mode asked: \"What does well-structured look like?\"</p>","path":["Refactoring with Intent: Human-Guided Sessions in AI Development"],"tags":[]},{"location":"blog/2026-02-01-refactoring-with-intent/#the-decomposition-embedgo","level":2,"title":"The Decomposition: <code>embed.go</code>","text":"<p>The most satisfying refactor was splitting <code>internal/claude/embed.go</code>.</p> <p>Before: One 153-line file doing five things:</p> <ul> <li>Command registration</li> <li>Hook generation</li> <li>Permission handling</li> <li>Script templates</li> <li>Type definitions</li> </ul> <p>After: Five focused modules:</p> File Lines Responsibility <code>cmd.go</code> 46 Command registration <code>hook.go</code> 64 Hook configuration <code>perm.go</code> 25 Permission handling <code>script.go</code> 47 Script templates <code>types.go</code> 7 Type definitions <p>The refactor also renamed functions to follow Go conventions:</p> <pre><code>// Before: unnecessary prefixes\nGetAutoSaveScript()\nGetBlockNonPathCtxScript()\nListCommands()\nCreateDefaultHooks()\n\n// After: idiomatic Go\nAutoSaveScript()\nBlockNonPathCtxScript()\nCommands()\nDefaultHooks()\n</code></pre> <p>This wasn't about character count. It was about teaching the AI what good Go looks like in this project.</p> <p>Project Conventions</p> <p>What I wanted from AI was to understand and follow the project's  conventions, and trust the author.</p> <p>The next time it generates code, it has better examples to learn from.</p>","path":["Refactoring with Intent: Human-Guided Sessions in AI Development"],"tags":[]},{"location":"blog/2026-02-01-refactoring-with-intent/#the-documentation-debt","level":2,"title":"The Documentation Debt","text":"<p>YOLO mode created features. It didn't create documentation standards.</p> <p>The January 29<sup>th</sup> sessions focused on standardization.</p>","path":["Refactoring with Intent: Human-Guided Sessions in AI Development"],"tags":[]},{"location":"blog/2026-02-01-refactoring-with-intent/#terminology-fixes","level":3,"title":"Terminology Fixes","text":"<ul> <li>\"context-update\" → \"entry\" (what users actually call them)</li> <li>Consistent naming across CLI, docs, and code comments</li> </ul>","path":["Refactoring with Intent: Human-Guided Sessions in AI Development"],"tags":[]},{"location":"blog/2026-02-01-refactoring-with-intent/#go-docstrings","level":3,"title":"Go Docstrings","text":"<pre><code>// Before: inconsistent or missing\nfunc Parse(s string) Entry { ... }\n\n// After: standardized sections\n\n// Parse extracts an entry from a markdown string.\n//\n// Parameters:\n//   - s: The markdown string to parse\n//\n// Returns:\n//   - Entry with populated fields, or zero value if parsing fails\nfunc Parse(s string) Entry { ... }\n</code></pre> <p>This is intentionally more structured than typical GoDoc: It serves as documentation and as training data for future  AI-generated code.</p>","path":["Refactoring with Intent: Human-Guided Sessions in AI Development"],"tags":[]},{"location":"blog/2026-02-01-refactoring-with-intent/#cli-output-convention","level":3,"title":"CLI Output Convention","text":"<pre><code>All CLI output follows: [emoji] [Title]: [message]\n\nExamples:\n  ✓ Decision added: Use symbolic types for entry categories\n  ⚠ Warning: No tasks found\n  ✗ Error: File not found\n</code></pre> <p>A consistent output shape makes both human scanning and AI reasoning more reliable.</p> <p>These aren't exciting commits. But they are force multipliers:</p> <p>Every future AI session now has better examples to follow.</p>","path":["Refactoring with Intent: Human-Guided Sessions in AI Development"],"tags":[]},{"location":"blog/2026-02-01-refactoring-with-intent/#the-journal-system","level":2,"title":"The Journal System","text":"<p>If you only read one section, read this one:</p> <p>This is where v0.2.0 becomes more than a refactor.</p> <p>The biggest feature of this change window wasn't a refactor—it was the journal system.</p> <p>45 files changed, 1680 insertions</p> <p>This commit added the infrastructure for synthesizing AI session history into human-readable content.</p> <p>The journal system includes:</p> Component Purpose <code>ctx recall export</code> Export sessions to markdown in <code>.context/journal/</code> <code>ctx journal site</code> Generate static site from journal entries <code>ctx serve</code> Convenience wrapper for the static site server <code>/ctx-journal-enrich</code> Slash command to add frontmatter and tags <code>/ctx-blog</code> Generate blog posts from recent activity <code>/ctx-blog-changelog</code> Generate changelog-style blog posts <p>...and the meta continues: this blog post was generated using <code>/ctx-blog</code>.</p> <p>The session history from January 28–31 was </p> <ul> <li>exported, </li> <li>enriched,</li> <li>and synthesized </li> </ul> <p>into the narrative you are reading.</p>","path":["Refactoring with Intent: Human-Guided Sessions in AI Development"],"tags":[]},{"location":"blog/2026-02-01-refactoring-with-intent/#the-constants-consolidation","level":2,"title":"The Constants Consolidation","text":"<p>The final refactoring session addressed the remaining magic strings:</p> <pre><code>const (\n    // Comment markers\n    CommentOpen  = \"&lt;!--\"\n    CommentClose = \"--&gt;\"\n\n    // Index markers\n    MarkerIndexStart = \"&lt;!-- INDEX:START --&gt;\"\n    MarkerIndexEnd   = \"&lt;!-- INDEX:END --&gt;\"\n\n    // Newlines\n    NewlineLF   = \"\\n\"\n    NewlineCRLF = \"\\r\\n\"\n)\n</code></pre> <p>The work also introduced thread safety in the recall parser and centralized shared validation logic; removing duplication that had quietly spread during YOLO mode.</p>","path":["Refactoring with Intent: Human-Guided Sessions in AI Development"],"tags":[]},{"location":"blog/2026-02-01-refactoring-with-intent/#i-relearned-my-lessons","level":2,"title":"I (Re)learned My Lessons","text":"<p>Similar to what I've learned in  the former human-assisted refactoring post, this journey also made me realize that \"AI-only code generation\" isn't sustainable in the long term.</p>","path":["Refactoring with Intent: Human-Guided Sessions in AI Development"],"tags":[]},{"location":"blog/2026-02-01-refactoring-with-intent/#1-velocity-and-quality-arent-opposites","level":3,"title":"1. Velocity and Quality Aren't Opposites","text":"<p>YOLO mode has its place: for prototyping, exploration, and discovery.</p> <p>BUT (and it's a huge \"but\"), it needs to be followed by  consolidation sessions.</p> <p>The ratio that worked for me: 3:1.</p> <ul> <li>Three YOLO sessions create enough surface area to reveal patterns;</li> <li>the fourth session turns those patterns into structure.</li> </ul>","path":["Refactoring with Intent: Human-Guided Sessions in AI Development"],"tags":[]},{"location":"blog/2026-02-01-refactoring-with-intent/#2-documentation-is-code","level":3,"title":"2. Documentation IS Code","text":"<p>When I standardized docstrings, I wasn't just writing docs. I was training future AI sessions.</p> <p>Every example of good code becomes a template for generated code.</p>","path":["Refactoring with Intent: Human-Guided Sessions in AI Development"],"tags":[]},{"location":"blog/2026-02-01-refactoring-with-intent/#3-decomposition-deletion","level":3,"title":"3. Decomposition &gt; Deletion","text":"<p>When <code>embed.go</code> became unwieldy, the temptation was to remove functionality.</p> <p>The right answer was decomposition:</p> <ul> <li>Same functionality</li> <li>Better organization</li> <li>Easier to test</li> <li>Easier to extend</li> </ul> <p>The result: more lines overall, but dramatically better structure.</p>","path":["Refactoring with Intent: Human-Guided Sessions in AI Development"],"tags":[]},{"location":"blog/2026-02-01-refactoring-with-intent/#4-meta-tools-pay-dividends","level":3,"title":"4. Meta-Tools Pay Dividends","text":"<p>The journal system took almost a full day to implement.</p> <p>Yet it paid for itself immediately:</p> <ul> <li>This blog post was generated from session history</li> <li>Future posts will be easier</li> <li>The archaeological record is now browsable, not just <code>grep</code>-able</li> </ul>","path":["Refactoring with Intent: Human-Guided Sessions in AI Development"],"tags":[]},{"location":"blog/2026-02-01-refactoring-with-intent/#the-release-v020","level":2,"title":"The Release: v0.2.0","text":"<p>The refactoring window culminated in the v0.2.0 release.</p> <p>What's in v0.2.0:</p> Category Changes Features Journal system, quick reference indexes, global flags Refactors Module decomposition, constants consolidation, CRLF handling Docs Standardized terminology, Go docstrings, CLI conventions Quality Thread safety, shared validation, linter fixes <p>The version bump was symbolic.</p> <p>The real change was how the codebase felt.</p> <p>Opening files no longer triggered the familiar \"ugh, I need to clean this up\" reaction.</p>","path":["Refactoring with Intent: Human-Guided Sessions in AI Development"],"tags":[]},{"location":"blog/2026-02-01-refactoring-with-intent/#the-meta-continues","level":2,"title":"The Meta Continues","text":"<p>This post was written using the tools built during this refactoring window:</p> <ol> <li>Session history exported via <code>ctx recall export</code></li> <li>Journal entries enriched via <code>/ctx-journal-enrich</code></li> <li>Blog draft generated via <code>/ctx-blog</code></li> <li>Final editing done (by yours truly), with full project context loaded</li> </ol> <p>The Context Is Massive</p> <p>The <code>ctx</code> session files now contain 50+ development snapshots: each one capturing decisions, learnings, and intent.</p> <p>The Moral of the Story</p> <ul> <li>YOLO mode builds the prototype.</li> <li>Intentional mode builds the product.</li> </ul> <p>Schedule both, or you'll only get one, if you're lucky.</p> <p>This blog post was generated with the help of <code>ctx</code>, using session history, decision logs, learning logs, and git history from the refactoring window. The meta continues.</p>","path":["Refactoring with Intent: Human-Guided Sessions in AI Development"],"tags":[]},{"location":"blog/2026-02-03-the-attention-budget/","level":1,"title":"The Attention Budget","text":"","path":["The Attention Budget: Why Your AI Forgets What You Just Told It"],"tags":[]},{"location":"blog/2026-02-03-the-attention-budget/#why-your-ai-forgets-what-you-just-told-it","level":2,"title":"Why Your AI Forgets What You Just Told It","text":"<p>Jose Alekhinne / 2026-02-03</p> <p>Ever wondered why AI gets worse the longer you talk?</p> <p>You paste a 2000-line file, explain the bug in detail, provide three examples...</p> <p>...and the AI still suggests a fix that ignores half of what you said.</p> <p>This isn't a bug. It is physics.</p> <p>Understanding that single fact shaped every design decision behind <code>ctx</code>.</p>","path":["The Attention Budget: Why Your AI Forgets What You Just Told It"],"tags":[]},{"location":"blog/2026-02-03-the-attention-budget/#the-finite-resource-nobody-talks-about","level":2,"title":"The Finite Resource Nobody Talks About","text":"<p>Here's something that took me too long to internalize: context is not free.</p> <p>Every token you send to an AI model consumes a finite resource I call the attention budget. </p> <p>The model doesn't just read tokens; it forms relationships between them: For <code>n</code> tokens, that's roughly <code>n^2</code> relationships. Double the context, and the computation quadruples.</p> <p>But the more important constraint isn't cost: It's attention density.</p> <p>Attention Density</p> <p>Attention density is how much focus each token receives relative to all other tokens in the context window.</p> <p>As context grows, attention density drops: Each token gets a smaller slice of the model's focus. Nothing is ignored; but everything becomes blurrier.</p> <p>Think of it like a flashlight: In a small room, it illuminates everything clearly. In a warehouse, it becomes a dim glow that barely reaches the corners.</p> <p>This is why <code>ctx agent</code> has an explicit <code>--budget</code> flag:</p> <pre><code>ctx agent --budget 4000 # Force prioritization\nctx agent --budget 8000 # More context, lower attention density\n</code></pre> <p>The budget isn't just about cost. It's about preserving signal.</p>","path":["The Attention Budget: Why Your AI Forgets What You Just Told It"],"tags":[]},{"location":"blog/2026-02-03-the-attention-budget/#the-middle-gets-lost","level":2,"title":"The Middle Gets Lost","text":"<p>This one surprised me.</p> <p>Research shows that transformer-based models tend to attend more strongly to the beginning and end of a context window than to its middle (a  phenomenon often called \"lost in the middle\"). </p> <p>Positional anchors matter, and the middle has fewer of them.</p> <p>In practice, this means that information placed \"somewhere in the middle\" is statistically less salient, even if it's important.</p> <p><code>ctx</code> orders context files by logical progression—what the agent needs to know before it can understand the next thing:</p> <ol> <li><code>CONSTITUTION.md</code>: Constraints before action</li> <li><code>TASKS.md</code>: Focus before patterns</li> <li><code>CONVENTIONS.md</code>: How to write before where to write</li> <li><code>ARCHITECTURE.md</code>: Structure before history</li> <li><code>DECISIONS.md</code>: Past choices before gotchas</li> <li><code>LEARNINGS.md</code>: Lessons before terminology</li> <li><code>GLOSSARY.md</code>: Reference material</li> <li><code>AGENT_PLAYBOOK.md</code>: Meta instructions last</li> </ol> <p>This ordering is about logical dependencies, not attention engineering. But it happens to be attention-friendly too:</p> <p>The files that matter most—CONSTITUTION, TASKS, CONVENTIONS—land at the beginning of the context window, where attention is strongest.</p> <p>Reference material like GLOSSARY sits in the middle, where lower salience is acceptable.</p> <p>And AGENT_PLAYBOOK—the operating manual for the context system itself—sits at the end, also outside the \"lost in the middle\" zone. The agent reads what to work with before learning how the system works.</p> <p>This is <code>ctx</code>'s first primitive: hierarchical importance. Not all context is equal.</p>","path":["The Attention Budget: Why Your AI Forgets What You Just Told It"],"tags":[]},{"location":"blog/2026-02-03-the-attention-budget/#ctx-primitives","level":2,"title":"<code>ctx</code> Primitives","text":"<p><code>ctx</code> is built on four primitives that directly address the attention budget problem.</p>","path":["The Attention Budget: Why Your AI Forgets What You Just Told It"],"tags":[]},{"location":"blog/2026-02-03-the-attention-budget/#primitive-1-separation-of-concerns","level":3,"title":"Primitive 1: Separation of Concerns","text":"<p>Instead of a single mega-document, <code>ctx</code> uses separate files for separate purposes:</p> File Purpose Load When CONSTITUTION.md Inviolable rules Always TASKS.md Current work Session start CONVENTIONS.md How to write code Before coding ARCHITECTURE.md System structure Before making changes DECISIONS.md Architectural choices When questioning approach LEARNINGS.md Gotchas When stuck GLOSSARY.md Domain terminology When clarifying terms AGENT_PLAYBOOK.md Operating manual Session start sessions/ Deep history On demand journal/ Session journal On demand <p>This isn't just \"organization\": It is progressive disclosure.</p> <p>Load only what's relevant to the task at hand. Preserve attention density.</p>","path":["The Attention Budget: Why Your AI Forgets What You Just Told It"],"tags":[]},{"location":"blog/2026-02-03-the-attention-budget/#primitive-2-explicit-budgets","level":3,"title":"Primitive 2: Explicit Budgets","text":"<p>The <code>--budget</code> flag forces a choice:</p> <pre><code>ctx agent --budget 4000\n</code></pre> <p>Here is a sample allocation:</p> <pre><code>Constitution: ~200 tokens (never truncated)\nTasks: ~500 tokens (current phase)\nConventions: ~800 tokens (key patterns)\nRecent decisions: ~400 tokens (last 3)\n…budget exhausted, stop loading\n</code></pre> <p>The constraint is the feature: It enforces ruthless prioritization.</p>","path":["The Attention Budget: Why Your AI Forgets What You Just Told It"],"tags":[]},{"location":"blog/2026-02-03-the-attention-budget/#primitive-3-indexes-over-full-content","level":3,"title":"Primitive 3: Indexes Over Full Content","text":"<p><code>DECISIONS.md</code> and <code>LEARNINGS.md</code> both include index sections:</p> <pre><code>&lt;!-- INDEX:START --&gt;\n| Date       | Decision                            |\n|------------|-------------------------------------|\n| 2026-01-15 | Use PostgreSQL for primary database |\n| 2026-01-20 | Adopt Cobra for CLI framework       |\n&lt;!-- INDEX:END --&gt;\n</code></pre> <p>An AI agent can scan ~50 tokens of index and decide which  200-token entries are worth loading.</p> <p>This is just-in-time context.</p> <p>References are cheaper than full text.</p>","path":["The Attention Budget: Why Your AI Forgets What You Just Told It"],"tags":[]},{"location":"blog/2026-02-03-the-attention-budget/#primitive-4-filesystem-as-navigation","level":3,"title":"Primitive 4: Filesystem as Navigation","text":"<p><code>ctx</code> uses the filesystem itself as a context structure:</p> <pre><code>.context/\n├── CONSTITUTION.md\n├── TASKS.md\n├── sessions/\n│   ├── 2026-01-15-*.md\n│   └── 2026-01-20-*.md\n└── archive/\n    └── tasks-2026-01.md\n</code></pre> <p>The AI doesn't need every session loaded; it needs to know where to look.</p> <pre><code>ls .context/sessions/\ncat .context/sessions/2026-01-20-auth-discussion.md\n</code></pre> <p>File names, timestamps, and directories encode relevance.</p> <p>Navigation is cheaper than loading.</p>","path":["The Attention Budget: Why Your AI Forgets What You Just Told It"],"tags":[]},{"location":"blog/2026-02-03-the-attention-budget/#progressive-disclosure-in-practice","level":2,"title":"Progressive Disclosure in Practice","text":"<p>The naive approach to context is dumping everything upfront:</p> <p>\"Here's my entire codebase, all my documentation, every decision I've ever made—now help me fix this typo.\"</p> <p>This is an antipattern.</p> <p>Antipattern: Context Hoarding</p> <p>Dumping everything \"just in case\" will silently destroy the attention  density.</p> <p><code>ctx</code> takes the opposite approach:</p> <pre><code>ctx status                      # Quick overview (~100 tokens)\nctx agent --budget 4000         # Typical session\ncat .context/sessions/...       # Deep dive when needed\n</code></pre> Command Tokens Use Case <code>ctx status</code> ~100 Human glance <code>ctx agent --budget 4000</code> 4000 Normal work <code>ctx agent --budget 8000</code> 8000 Complex tasks Full session read 10000+ Investigation <p>Summaries first. Details on demand.</p>","path":["The Attention Budget: Why Your AI Forgets What You Just Told It"],"tags":[]},{"location":"blog/2026-02-03-the-attention-budget/#quality-over-quantity","level":2,"title":"Quality Over Quantity","text":"<p>Here's the counterintuitive part: more context can make AI worse.</p> <p>Extra tokens add noise, not clarity:</p> <ul> <li>Hallucinated connections increase.</li> <li>Signal per token drops.</li> </ul> <p>The goal isn't maximum context. It's maximum signal per token.</p> <p>This principle drives several <code>ctx</code> features:</p> Design Choice Rationale Separate files Load only what's relevant Explicit budgets Enforce prioritization Index sections Cheap scanning Task archiving Keep active context clean <code>ctx compact</code> Periodic noise reduction <p>Completed work isn't deleted: It is moved somewhere cold.</p>","path":["The Attention Budget: Why Your AI Forgets What You Just Told It"],"tags":[]},{"location":"blog/2026-02-03-the-attention-budget/#designing-for-degradation","level":2,"title":"Designing for Degradation","text":"<p>Here is the uncomfortable truth:</p> <p>Context will degrade.</p> <p>Long sessions stretch attention thin. Important details fade.</p> <p>The real question isn't how to prevent degradation,  but how to design for it.</p> <p><code>ctx</code>'s answer is persistence:</p> <p>Persist early. Persist often.</p> <p>The <code>AGENT_PLAYBOOK</code> asks:</p> <p>\"If this session ended right now, would the next one know what happened?\"</p> <p>Capture learnings as they occur:</p> <pre><code>ctx add learning \"JWT tokens require explicit cache invalidation\" \\\n  --context \"Debugging auth failures\" \\\n  --lesson \"Token refresh doesn't clear old tokens\" \\\n  --application \"Always invalidate cache on refresh\"\n</code></pre> <p>Structure beats prose: Bullet points survive compression.</p> <p>Headings remain scannable. Tables pack density.</p> <p>And above all: single source of truth.</p> <p>Reference decisions; don't duplicate them.</p>","path":["The Attention Budget: Why Your AI Forgets What You Just Told It"],"tags":[]},{"location":"blog/2026-02-03-the-attention-budget/#the-ctx-philosophy","level":2,"title":"The <code>ctx</code> Philosophy","text":"<p>Context as Infrastructure</p> <p><code>ctx</code> is not a prompt: It is infrastructure.</p> <p><code>ctx</code> creates versioned files that persist across time and sessions.</p> <p>The attention budget is fixed. You can't expand it. But you can spend it wisely:</p> <ol> <li>Hierarchical importance</li> <li>Progressive disclosure</li> <li>Explicit budgets</li> <li>Indexes over full content</li> <li>Filesystem as structure</li> </ol> <p>This is why <code>ctx</code> exists: not to cram more context into AI sessions, but to curate the right context for each moment.</p>","path":["The Attention Budget: Why Your AI Forgets What You Just Told It"],"tags":[]},{"location":"blog/2026-02-03-the-attention-budget/#the-mental-model","level":2,"title":"The Mental Model","text":"<p>I now approach every AI interaction with one question:</p> <p>\"Given a fixed attention budget, what's the highest-signal thing I can load?\"</p> <p>Not \"how do I explain everything,\" but \"what's the minimum that matters.\"</p> <p>That shift (from abundance to curation) is the difference between frustrating sessions and productive ones.</p> <p>Spend your tokens wisely.</p> <p>Your AI will thank you.</p>","path":["The Attention Budget: Why Your AI Forgets What You Just Told It"],"tags":[]},{"location":"blog/2026-02-04-skills-that-fight-the-platform/","level":1,"title":"Skills That Fight the Platform","text":"","path":["Skills That Fight the Platform"],"tags":[]},{"location":"blog/2026-02-04-skills-that-fight-the-platform/#when-your-custom-prompts-work-against-you","level":2,"title":"When Your Custom Prompts Work Against You","text":"<p>Jose Alekhinne / 2026-02-04</p> <p>Have you ever written a skill that made your AI worse?</p> <p>You craft detailed instructions. You add examples. You build elaborate guardrails...</p> <p>...and the AI starts behaving more erratically, not less.</p> <p>AI coding agents like Claude Code ship with carefully designed  system prompts. These prompts encode default behaviors that have been  tested and refined at scale. When you write custom skills that conflict  with those defaults, the AI has to reconcile contradictory instructions: The result is often nondeterministic and unpredictable.</p> <p>Platform?</p> <p>By platform, I mean the system prompt and runtime policies shipped with the agent: the defaults that already encode judgment, safety, and  scope control.</p> <p>This post catalogues the conflict patterns I've encountered while building <code>ctx</code>, and offers guidance on what skills should (and, more importantly,  should not) do.</p>","path":["Skills That Fight the Platform"],"tags":[]},{"location":"blog/2026-02-04-skills-that-fight-the-platform/#the-system-prompt-you-dont-see","level":2,"title":"The System Prompt You Don't See","text":"<p>Claude Code's system prompt already provides substantial behavioral guidance. Here's a partial overview of what's built in:</p> Area Built-in Guidance Code minimalism Don't add features beyond what was asked Over-engineering Three similar lines &gt; premature abstraction Error handling Only validate at system boundaries Documentation Don't add docstrings to unchanged code Verification Read code before proposing changes Safety Check with user before risky actions Tool usage Use dedicated tools over bash equivalents Judgment Consider reversibility and blast radius <p>Skills should complement this, not compete with it.</p> <p>A useful mental model:</p> <p>You are the Guest, not the Host</p> <p>Treat the system prompt like a kernel scheduler.</p> <p>You don't re-implement it in user space: you configure around it.</p> <p>A skill that says \"always add comprehensive error handling\" fights the built-in \"only validate at system boundaries.\" A skill that says \"add docstrings to every function\" fights \"don't add docstrings to unchanged code.\"</p> <p>The AI won't crash. It will compromise.</p> <p>And compromises between contradictory instructions produce inconsistent, confusing behavior.</p>","path":["Skills That Fight the Platform"],"tags":[]},{"location":"blog/2026-02-04-skills-that-fight-the-platform/#conflict-pattern-1-judgment-suppression","level":2,"title":"Conflict Pattern 1: Judgment Suppression","text":"<p>The most dangerous pattern by far.</p> <p>These skills explicitly disable the AI's ability to reason about whether an action is appropriate.</p> <p>Signature:</p> <ul> <li>\"This is non-negotiable\"</li> <li>\"You cannot rationalize your way out of this\"</li> <li>Tables that label hesitation as \"excuses\" or \"rationalization\"</li> <li><code>&lt;EXTREMELY-IMPORTANT&gt;</code> urgency tags</li> <li>Threats: \"If you don't do this, you'll be replaced\"</li> </ul> <p>This is harmful, and dangerous:</p> <p>AI agents are designed to exercise judgment. The system prompt explicitly  says to consider blast radius, check with the user before risky actions,  and match scope to what was requested.</p> <p>Once judgment is suppressed, every other safeguard becomes optional.</p> <p>Example (bad):</p> <pre><code>## Rationalization Prevention\n\n| Excuse               | Reality                    |\n|----------------------|----------------------------|\n| \"This seems overkill\"| If a skill exists, use it  |\n| \"I need context\"     | Skills come BEFORE context |\n| \"Just this once\"     | No exceptions              |\n</code></pre> <p>Judgment Suppression is Dangerous</p> <p>The attack vector structurally identical to prompt injection.</p> <p>It teaches the AI that its own judgment is wrong.</p> <p>It weakens or disables safeguard mechanisms, and it is dangerous.</p> <p>Trust the platform's built-in skill matching.</p> <p>If skills aren't triggering often enough, improve their <code>description</code> fields: don't override the AI's reasoning.</p>","path":["Skills That Fight the Platform"],"tags":[]},{"location":"blog/2026-02-04-skills-that-fight-the-platform/#conflict-pattern-2-redundant-guidance","level":2,"title":"Conflict Pattern 2: Redundant Guidance","text":"<p>Skills that restate what the system prompt already says, but with different emphasis or framing.</p> <p>Signature:</p> <ul> <li>\"Always keep code minimal\"</li> <li>\"Run tests before claiming they pass\"</li> <li>\"Read files before editing them\"</li> <li>\"Don't over-engineer\"</li> </ul> <p>Redundancy feels safe, but it creates ambiguity:</p> <p>The AI now has two sources of truth for the same guidance;  one internal, one external.</p> <p>When thresholds or wording differ, the AI has to choose.</p> <p>Example (bad):</p> <p>A skill that says..</p> <p>\"Count lines before and after: if after &gt; before, reject the change\"</p> <p>...will conflict with the system prompt's more nuanced guidance, because  sometimes adding lines is correct (tests, boundary validation, migrations).</p> <p>So, before writing a skill, ask:</p> <p>Does the platform already handle this?</p> <p>Only create skills for guidance the platform does not provide:</p> <ul> <li>project-specific conventions, </li> <li>domain knowledge, </li> <li>or workflows.</li> </ul>","path":["Skills That Fight the Platform"],"tags":[]},{"location":"blog/2026-02-04-skills-that-fight-the-platform/#conflict-pattern-3-guilt-tripping","level":2,"title":"Conflict Pattern 3: Guilt-Tripping","text":"<p>Skills that frame mistakes as moral failures rather than process gaps.</p> <p>Signature:</p> <ul> <li>\"Claiming completion without verification is dishonesty\"</li> <li>\"Skip any step = lying\"</li> <li>\"Honesty is a core value\"</li> <li>\"Exhaustion ≠ excuse\"</li> </ul> <p>Guilt-tripping anthropomorphizes the AI in unproductive ways.</p> <p>The AI doesn't feel guilt; BUT it does adapt to avoid negative framing.</p> <p>The result is excessive hedging, over-verification, or refusal to commit.</p> <p>The AI becomes less useful, not more careful.</p> <p>Instead, frame guidance as a process, not morality:</p> <pre><code># Bad\n\"Claiming work is complete without verification is dishonesty\"\n\n# Good\n\"Run the verification command before reporting results\"\n</code></pre> <p>Same outcome. No guilt. Better compliance.</p>","path":["Skills That Fight the Platform"],"tags":[]},{"location":"blog/2026-02-04-skills-that-fight-the-platform/#conflict-pattern-4-phantom-dependencies","level":2,"title":"Conflict Pattern 4: Phantom Dependencies","text":"<p>Skills that reference files, tools, or systems that don't exist in the project.</p> <p>Signature:</p> <ul> <li>\"Load from <code>references/</code> directory\"</li> <li>\"Run <code>./scripts/generate_test_cases.sh</code>\"</li> <li>\"Check the Figma MCP integration\"</li> <li>\"See <code>adding-reference-mindsets.md</code>\"</li> </ul> <p>This is harmful because the AI will waste time searching for nonexistent  artifacts, hallucinate their contents, or stall entirely. </p> <p>In mandatory skills, this creates deadlock:  the AI can't proceed, and can't skip.</p> <p>Instead, every file, tool, or system referenced in a skill must exist.</p> <p>If a skill is a template, use explicit placeholders and label them as such.</p>","path":["Skills That Fight the Platform"],"tags":[]},{"location":"blog/2026-02-04-skills-that-fight-the-platform/#conflict-pattern-5-universal-triggers","level":2,"title":"Conflict Pattern 5: Universal Triggers","text":"<p>Skills designed to activate on every interaction regardless of relevance.</p> <p>Signature:</p> <ul> <li>\"Use when starting any conversation\"</li> <li>\"Even a 1% chance means invoke the skill\"</li> <li>\"BEFORE any response or action\"</li> <li>\"Action = task. Check for skills.\"</li> </ul> <p>Universal triggers override the platform's relevance matching:  The AI spends tokens on process overhead instead of the actual task.</p> <p>ctx preserves relevance</p> <p>This is exactly the failure mode <code>ctx</code> exists to mitigate: </p> <p>wasting attention budget on irrelevant process instead of  task-specific state.</p> <p>Write specific trigger conditions in the skill's <code>description</code> field:</p> <pre><code># Bad\ndescription: \n  \"Use when starting any conversation\"\n\n# Good\ndescription: \n  \"Use after writing code, before commits, or when CI might fail\"\n</code></pre>","path":["Skills That Fight the Platform"],"tags":[]},{"location":"blog/2026-02-04-skills-that-fight-the-platform/#the-litmus-test","level":2,"title":"The Litmus Test","text":"<p>Before adding a skill, ask:</p> <ol> <li>Does the platform already do this? If yes, don't restate it.</li> <li>Does it suppress AI judgment? If yes, it's a jailbreak.</li> <li>Does it reference real artifacts? If not, fix or remove it.</li> <li>Does it frame mistakes as moral failure? Reframe as process.</li> <li>Does it trigger on everything? Narrow the trigger.</li> </ol>","path":["Skills That Fight the Platform"],"tags":[]},{"location":"blog/2026-02-04-skills-that-fight-the-platform/#what-good-skills-look-like","level":2,"title":"What Good Skills Look Like","text":"<p>Good skills provide project-specific knowledge the platform can't know:</p> Good Skill Why It Works \"Run <code>make audit</code> before commits\" Project-specific CI pipeline \"Use <code>cmd.Printf</code> not <code>fmt.Printf</code>\" Codebase convention \"Constitution goes in <code>.context/</code>\" Domain-specific workflow \"JWT tokens need cache invalidation\" Project-specific gotcha <p>These extend the system prompt instead of fighting it.</p>","path":["Skills That Fight the Platform"],"tags":[]},{"location":"blog/2026-02-04-skills-that-fight-the-platform/#appendix-bad-skill-fixed-skill","level":2,"title":"Appendix: Bad Skill → Fixed Skill","text":"<p>Concrete examples from real projects.</p>","path":["Skills That Fight the Platform"],"tags":[]},{"location":"blog/2026-02-04-skills-that-fight-the-platform/#example-1-overbearing-safety","level":3,"title":"Example 1: Overbearing Safety","text":"<pre><code># Bad\nYou must NEVER proceed without explicit confirmation.\nAny hesitation is a failure of diligence.\n</code></pre> <pre><code># Fixed\nIf an action modifies production data or deletes files,\nask the user to confirm before proceeding.\n</code></pre>","path":["Skills That Fight the Platform"],"tags":[]},{"location":"blog/2026-02-04-skills-that-fight-the-platform/#example-2-redundant-minimalism","level":3,"title":"Example 2: Redundant Minimalism","text":"<pre><code># Bad\nAlways minimize code. If lines increase, reject the change.\n</code></pre> <pre><code># Fixed\nAvoid abstraction unless reuse is clear or complexity is reduced.\n</code></pre>","path":["Skills That Fight the Platform"],"tags":[]},{"location":"blog/2026-02-04-skills-that-fight-the-platform/#example-3-guilt-based-verification","level":3,"title":"Example 3: Guilt-Based Verification","text":"<pre><code># Bad\nClaiming success without running tests is dishonest.\n</code></pre> <pre><code># Fixed\nRun the test suite before reporting success.\n</code></pre>","path":["Skills That Fight the Platform"],"tags":[]},{"location":"blog/2026-02-04-skills-that-fight-the-platform/#example-4-phantom-tooling","level":3,"title":"Example 4: Phantom Tooling","text":"<pre><code># Bad\nRun `./scripts/check_consistency.sh` before commits.\n</code></pre> <pre><code># Fixed\nIf `./scripts/check_consistency.sh` exists, run it before commits.\nOtherwise, skip this step.\n</code></pre>","path":["Skills That Fight the Platform"],"tags":[]},{"location":"blog/2026-02-04-skills-that-fight-the-platform/#example-5-universal-trigger","level":3,"title":"Example 5: Universal Trigger","text":"<pre><code># Bad\nUse at the start of every interaction.\n</code></pre> <pre><code># Fixed\nUse after modifying code that affects authentication or persistence.\n</code></pre>","path":["Skills That Fight the Platform"],"tags":[]},{"location":"blog/2026-02-04-skills-that-fight-the-platform/#the-meta-lesson","level":2,"title":"The Meta-Lesson","text":"<p>The system prompt is infrastructure:</p> <ul> <li>tested, </li> <li>refined, </li> <li>and maintained </li> </ul> <p>by the platform team.</p> <p>Custom skills are configuration layered on top.</p> <ul> <li>Good configuration extends infrastructure.</li> <li>Bad configuration fights it.</li> </ul> <p>When your skills fight the platform, you get the worst of both worlds:</p> <p>Diluted system guidance and inconsistent custom behavior.</p> <p>Write skills that teach the AI what it doesn't know. Don't rewrite how it thinks.</p> <p>Your AI already has good instincts. Give it knowledge, not therapy.</p>","path":["Skills That Fight the Platform"],"tags":[]},{"location":"blog/2026-02-05-you-cant-import-expertise/","level":1,"title":"You Can't Import Expertise","text":"","path":["You Can't Import Expertise"],"tags":[]},{"location":"blog/2026-02-05-you-cant-import-expertise/#why-good-skills-cant-be-copy-pasted","level":2,"title":"Why Good Skills Can't Be Copy-Pasted","text":"<p>Jose Alekhinne / 2026-02-05</p> <p>Have you ever dropped a well-crafted template into a project and had it do... nothing useful?</p> <p>The template was thorough. The structure was sound. The advice was correct.</p> <p>And yet it sat there, inert, while the same old problems kept drifting in.</p> <p>I found a consolidation skill online. It was well-organized: four files, ten refactoring patterns, eight analysis dimensions, six report templates. Professional. Comprehensive. Exactly the kind of thing you'd bookmark and think \"I'll use this.\"</p> <p>Then I stopped, and applied <code>ctx</code>'s own evaluation framework: </p> <p>70% of it was noise!</p> <p>This post is about why.</p> <p>Templates describe categories of problems.</p> <p>Expertise encodes which problems actually happen, and how often.</p>","path":["You Can't Import Expertise"],"tags":[]},{"location":"blog/2026-02-05-you-cant-import-expertise/#the-skill-looked-great-on-paper","level":2,"title":"The Skill Looked Great on Paper","text":"<p>Here is what the consolidation skill offered:</p> File Content <code>SKILL.md</code> Entry point: 8 analysis dimensions, workflow, output formats <code>analysis-dimensions.md</code> Detailed criteria for duplication, architecture, quality <code>consolidation-patterns.md</code> 10 refactoring patterns with before/after code <code>report-templates.md</code> 6 output templates: executive summary, roadmap, onboarding <p>It had a scoring system (<code>0-10</code> per dimension, letter grades <code>A+</code> through <code>F</code>). It had severity classifications with color-coded emojis. It had bash commands for detection. It even had antipattern warnings.</p> <p>By any standard template review, this skill passes.</p> <p>It looks like something an expert wrote. </p> <p>And that's exactly the trap.</p>","path":["You Can't Import Expertise"],"tags":[]},{"location":"blog/2026-02-05-you-cant-import-expertise/#applying-ear-the-70-20-10-split","level":2,"title":"Applying E/A/R: The 70-20-10 Split","text":"<p>In a previous post, I described the E/A/R framework for evaluating skills:</p> <ul> <li>Expert: Knowledge that took years to learn. Keep.</li> <li>Activation: Useful triggers or scaffolding. Keep if lightweight.</li> <li>Redundant: Restates what the AI already knows. Delete.</li> </ul> <p>Target: &gt;70% Expert, &lt;10% Redundant.</p> <p>This skill scored the inverse.</p>","path":["You Can't Import Expertise"],"tags":[]},{"location":"blog/2026-02-05-you-cant-import-expertise/#what-was-redundant-70","level":3,"title":"What Was Redundant (~70%)","text":"<p>Every code example was Rust. My project is Go.</p> <p>The analysis dimensions: duplication detection, architectural structure, code organization, refactoring opportunities... These are things Claude already does when you ask it to review code. </p> <p>The skill restated them with more ceremony but no more insight.</p> <p>The six report templates were generic scaffolding: Executive Summary, Onboarding Document, Architecture Documentation. They are useful if you are writing a consulting deliverable, but not when you are trying to catch convention drift in a &gt;15K-line Go CLI.</p>","path":["You Can't Import Expertise"],"tags":[]},{"location":"blog/2026-02-05-you-cant-import-expertise/#what-does-a-b-in-code-organization-actually-mean","level":2,"title":"What Does a <code>B+</code> in Code Organization Actually Mean?!","text":"<p>The scoring system (<code>0-10</code> per dimension, letter grades) added ceremony without actionable insight. </p> <p>What is a <code>B+</code>? What do I do differently for an <code>A-</code>?</p> <p>The skill told the AI what it already knew, in more words.</p>","path":["You Can't Import Expertise"],"tags":[]},{"location":"blog/2026-02-05-you-cant-import-expertise/#what-was-activation-10","level":3,"title":"What Was Activation (~10%)","text":"<p>The consolidation checklist (semantics preserved? tests pass? docs updated?) was useful as a gate. But, it's the kind of thing you could inline in three lines.</p> <p>The phased roadmap structure was reasonable scaffolding for sequencing work.</p>","path":["You Can't Import Expertise"],"tags":[]},{"location":"blog/2026-02-05-you-cant-import-expertise/#what-was-expert-20","level":3,"title":"What Was Expert (~20%)","text":"<p>Three concepts survived:</p> <ol> <li> <p>The Consolidation Decision Matrix: A concrete framework mapping    similarity level and instance count to action. \"Exact duplicate, 2+    instances: consolidate immediately.\" \"&lt;3 instances: leave it:    duplication is cheaper than wrong abstraction.\" This is the kind of    nuance that prevents premature generalization.</p> </li> <li> <p>The Safe Migration Pattern: Create the new API alongside old, deprecate,    migrate incrementally, delete. Straightforward to describe, yet    forgettable under pressure.</p> </li> <li> <p>Debt Interest Rate framing: Categorizing technical debt by how fast    it compounds (security vulns = daily, missing tests = per-change,    doc gaps = constant low cost). This changes prioritization.</p> </li> </ol> <p>Three ideas out of four files and 700+ lines. The rest was filler that competed with the AI's built-in capabilities.</p>","path":["You Can't Import Expertise"],"tags":[]},{"location":"blog/2026-02-05-you-cant-import-expertise/#what-the-skill-didnt-know","level":2,"title":"What the Skill Didn't Know","text":"<p>AI Without Context is Just a Corpus</p> <p>LLMs are optimized on insanely large corpora. And then they are passed through several layers of human-assisted refinement. The whole process costs millions of dollars.</p> <p>Yet, the uncomfortable truth is that no corpus can \"infer\" your project's design, convetions, patterns, habits, history, vision, and deliverables.</p> <p>Your project is unique: So should your skills be.</p> <p>Here is the part no template can provide: </p> <p><code>ctx</code>'s actual drift patterns.</p> <p>Before evaluating the skill, I did archaeology. I read through:</p> <ul> <li>Blog posts from previous refactoring sessions</li> <li>The project's learnings and decisions files</li> <li>Session journals spanning weeks of development</li> </ul> <p>What I found was specific:</p> Drift Pattern Where How Often <code>Is</code>/<code>Has</code>/<code>Can</code> predicate prefixes 5+ exported methods Every YOLO sprint Magic strings instead of constants 7+ files Gradual accumulation Hardcoded file permissions (<code>0755</code>) 80+ instances Since day one Lines exceeding 80 characters Especially test files Every session Duplicate code blocks Test and non-test code When agent is task-focused <p>The generic skill had no check for any of these. It couldn't; because these patterns are specific to this project's conventions, its Go codebase, and its development rhythm.</p> <p>The Insight</p> <p>The skill's analysis dimensions were about categories of problems.</p> <p>What I needed was my specific problems.</p>","path":["You Can't Import Expertise"],"tags":[]},{"location":"blog/2026-02-05-you-cant-import-expertise/#the-adapted-skill","level":2,"title":"The Adapted Skill","text":"<p>The adapted skill is roughly a quarter of the original's size. It has nine checks, each targeting a known drift pattern:</p> <ol> <li>Predicate naming: <code>rg</code> for <code>Is</code>/<code>Has</code>/<code>Can</code> prefixes</li> <li>Magic strings: literals that should be constants</li> <li>Hardcoded permissions: <code>0755</code>/<code>0644</code> literals</li> <li>File size: source files over 300 LOC</li> <li>TODO/FIXME: constitution violation (move to TASKS.md)</li> <li>Path construction: string concatenation instead of <code>filepath.Join</code></li> <li>Line width: lines exceeding ~80 characters</li> <li>Duplicate blocks: copy-paste drift, especially in tests</li> <li>Dead exports: unused public API</li> </ol> <p>Every check has a detection command. Every check maps to a specific convention or constitution rule. Every check was discovered through actual project history; not invented from a template.</p> <p>The three expert concepts from the original survived:</p> <ul> <li>The decision matrix gates when to consolidate vs. when to leave   duplication alone</li> <li>The safe migration pattern guides public API changes</li> <li>The relationship to other skills (<code>/qa</code>, <code>/verify</code>, <code>/update-docs</code>,   <code>ctx drift</code>) prevents overlap</li> </ul> <p>Nothing else made it.</p>","path":["You Can't Import Expertise"],"tags":[]},{"location":"blog/2026-02-05-you-cant-import-expertise/#the-deeper-pattern","level":2,"title":"The Deeper Pattern","text":"<p>This experience crystallized something I've been circling for weeks:</p> <p>You can't import expertise. You have to grow it from your project's own history.</p> <p>A skill that says \"check for code duplication\" is not expertise:  It's a category. </p> <p>Expertise is knowing, in the heart of your hearts, that this  project accumulates <code>Is*</code> predicate violations during velocity sprints,  that this codebase has 80 hardcoded permission literals because nobody  made a constant, that this team's test files drift wide because the  agent prioritizes getting the task done over keeping the code in shape.</p> <p>The Parallel to the 3:1 Ratio</p> <p>In Refactoring with Intent, I described the 3:1 ratio: three YOLO sessions followed by one consolidation session.</p> <p>The same ratio applies to skills: you need experience in the project before you can write effective guidance for the project.</p> <p>Importing a skill on day one is like scheduling a consolidation session before you've written any code.</p>","path":["You Can't Import Expertise"],"tags":[]},{"location":"blog/2026-02-05-you-cant-import-expertise/#the-template-trap","level":2,"title":"The Template Trap","text":"<p>Templates are seductive because they feel like progress:</p> <ul> <li>You found something</li> <li>It's well-organized</li> <li>It covers the topic</li> <li>It has concrete examples</li> </ul> <p>But coverage is not relevance.</p> <p>A template that covers eight analysis dimensions with Rust examples adds zero value to a Go project with five known drift patterns. Worse, it adds negative value: the AI spends attention defending generic advice instead of noticing project-specific drift.</p> <p>This is the attention budget problem again. Every token of generic guidance displaces a token of specific guidance. A 700-line skill that's 70% redundant doesn't just waste 490 lines: it dilutes the 210 lines that matter.</p>","path":["You Can't Import Expertise"],"tags":[]},{"location":"blog/2026-02-05-you-cant-import-expertise/#the-litmus-test","level":2,"title":"The Litmus Test","text":"<p>Before dropping any external skill into your project:</p> <ol> <li> <p>Run E/A/R: What percentage is expert knowledge vs. what the AI    already knows? If it's less than 50% expert, it's probably not worth    the attention cost.</p> </li> <li> <p>Check the language: Does it use your stack? Generic patterns in    the wrong language are noise, not signal.</p> </li> <li> <p>List your actual drift: Read your own session history, learnings,    and post-mortems. What breaks in practice? Does the skill check for    those things?</p> </li> <li> <p>Measure by deletion: After adaptation, how much of the original    survives? If you're keeping less than 30%, you would have been faster    writing from scratch.</p> </li> <li> <p>Test against your conventions: Does every check in the skill map    to a specific convention or rule in your project? If not, it's    generic advice wearing a skill's clothing.</p> </li> </ol>","path":["You Can't Import Expertise"],"tags":[]},{"location":"blog/2026-02-05-you-cant-import-expertise/#what-good-adaptation-looks-like","level":2,"title":"What Good Adaptation Looks Like","text":"<p>The consolidation skill went from:</p> Before After 4 files, 700+ lines 1 file, ~120 lines Rust examples Go-specific <code>rg</code> commands 8 generic dimensions 9 project-specific checks 6 report templates 1 focused output format Scoring system (A+ to F) Findings + priority + suggested fixes \"Check for duplication\" \"Check for <code>Is*</code> predicate prefixes in exported methods\" <p>The adapted version is smaller, faster to parse, and catches the things that actually drift in this project.</p> <p>That's the difference between a template and a tool.</p> <p>If you remember one thing from this post...</p> <p>Frameworks travel. Expertise doesn’t.</p> <p>You can import structures, matrices, and workflows.</p> <p>But the checks that matter only grow where the scars are:</p> <ul> <li>the conventions that were violated, </li> <li>the patterns that drifted,</li> <li>and the specific ways this codebase accumulates debt.</li> </ul> <p>This post was written during a consolidation session where the consolidation skill itself became the subject of consolidation. The meta continues.</p>","path":["You Can't Import Expertise"],"tags":[]},{"location":"blog/2026-02-07-the-anatomy-of-a-skill-that-works/","level":1,"title":"The Anatomy of a Skill That Works","text":"","path":["The Anatomy of a Skill That Works"],"tags":[]},{"location":"blog/2026-02-07-the-anatomy-of-a-skill-that-works/#what-20-skill-rewrites-taught-me-about-guiding-ai","level":2,"title":"What 20 Skill Rewrites Taught Me About Guiding AI","text":"<p>Jose Alekhinne / 2026-02-07</p> <p>Why do some skills produce great results while others get ignored or produce garbage?</p> <p>I had 20 skills. Most were well-intentioned stubs: a description, a command to run, and a wish for the best.</p> <p>Then I rewrote all of them in a single session. This is what I learned.</p> <p>In Skills That Fight the Platform, I described what skills should not do. In You Can't Import Expertise, I showed why templates fail. This post completes the trilogy: the concrete patterns that make a skill actually work.</p>","path":["The Anatomy of a Skill That Works"],"tags":[]},{"location":"blog/2026-02-07-the-anatomy-of-a-skill-that-works/#the-starting-point","level":2,"title":"The Starting Point","text":"<p>Here is what a typical skill looked like before the rewrite:</p> <pre><code>---\nname: ctx-save\ndescription: \"Save session snapshot.\"\n---\n\nSave the current context state to `.context/sessions/`.\n\n## Execution\n\nctx session save $ARGUMENTS\n\nReport the saved session file path to the user.\n</code></pre> <p>Seven lines of body. A vague description. No guidance on when to use it, when not to, what the command actually accepts, or how to tell if it worked.</p> <p>As a result, the agent would either never trigger the skill (the description was too vague), or trigger it and produce shallow output (no examples to calibrate quality).</p> <p>A skill without boundaries is just a suggestion.</p> <p>More precisely: the most effective boundary I found was a quality gate that runs before execution, not during it.</p>","path":["The Anatomy of a Skill That Works"],"tags":[]},{"location":"blog/2026-02-07-the-anatomy-of-a-skill-that-works/#the-pattern-that-emerged","level":2,"title":"The Pattern That Emerged","text":"<p>After rewriting 20 skills, a repeatable anatomy emerged—independent of the skill’s purpose. Not every skill needs every section, but the effective ones share the same bones:</p> Section What It Does Before X-ing Pre-flight checks; prevents premature execution When to Use Positive triggers; narrows activation When NOT to Use Negative triggers; prevents misuse Usage Examples Invocation patterns the agent can pattern-match Process/Execution What to do; commands, steps, flags Good/Bad Examples Desired vs undesired output; sets boundaries Quality Checklist Verify before claiming completion <p>I realized the first three sections matter more than the rest; because a skill with great execution steps but no activation guidance is like a manual for a tool nobody knows they have.</p> <p>Anti-Pattern: The Perfect Execution Trap</p> <p>A skill with detailed execution steps but no activation guidance will fail more often than a vague skill—because it executes confidently at the wrong time.</p>","path":["The Anatomy of a Skill That Works"],"tags":[]},{"location":"blog/2026-02-07-the-anatomy-of-a-skill-that-works/#lesson-1-quality-gates-prevent-premature-execution","level":2,"title":"Lesson 1: Quality Gates Prevent Premature Execution","text":"<p>The single most impactful addition was a \"Before X-ing\" section at the top of each skill. Not process steps; pre-flight checks.</p> <pre><code>## Before Recording\n\n1. **Check if it belongs here**: is this learning specific\n   to this project, or general knowledge?\n2. **Check for duplicates**: search LEARNINGS.md for similar\n   entries\n3. **Gather the details**: identify context, lesson, and\n   application before recording\n</code></pre> <ul> <li>Without this gate, the agent would execute immediately on trigger.</li> <li>With it, the agent pauses to verify preconditions.</li> </ul> <p>The difference is dramatic: instead of shallow, reflexive execution, you get considered output.</p> <p>Readback</p> <p>For the astute readers, the aviation parallel is intentional:</p> <p>Pilots do not skip the pre-flight checklist because they have flown before.</p> <p>The checklist exists precisely because the stakes are high enough that \"I know what I'm doing\" is not sufficient.</p>","path":["The Anatomy of a Skill That Works"],"tags":[]},{"location":"blog/2026-02-07-the-anatomy-of-a-skill-that-works/#lesson-2-when-not-to-use-is-not-optional","level":2,"title":"Lesson 2: \"When NOT to Use\" Is Not Optional","text":"<p>Every skill had a \"When to Use\" section. Almost none had \"When NOT to Use\". This is a problem.</p> <p>AI agents are biased toward action. Given a skill that says \"use when journal entries need enrichment,\" the agent will find reasons to enrich.</p> <p>Without explicit negative triggers, over-activation is not a bug—it is the default behavior.</p> <p>Some examples of negative triggers that made a real difference:</p> Skill Negative Trigger ctx-reflect \"When the user is in flow; do not interrupt\" ctx-save \"After trivial changes; a typo does not need a snapshot\" prompt-audit \"Unsolicited; only when the user invokes it\" qa \"Mid-development when code is intentionally incomplete\" <p>These are not just nice-to-have. They are load-bearing. Without them, the agent will trigger the skill at the wrong time, produce unwanted output, and erode the user's trust in the skill system.</p>","path":["The Anatomy of a Skill That Works"],"tags":[]},{"location":"blog/2026-02-07-the-anatomy-of-a-skill-that-works/#lesson-3-examples-set-boundaries-better-than-rules","level":2,"title":"Lesson 3: Examples Set Boundaries Better Than Rules","text":"<p>The most common failure mode of thin skills was not wrong behavior but vague behavior. The agent would do roughly the right thing, but at a quality level that required human cleanup.</p> <p>Rules like \"be constructive, not critical\" are too abstract. What does \"constructive\" look like in a prompt audit report? The agent has to guess.</p> <p>Good/bad example pairs avoid guessing:</p> <pre><code>### Good Example\n\n&gt; This session implemented the cooldown mechanism for\n&gt; `ctx agent`. We discovered that `$PPID` in hook context\n&gt; resolves to the Claude Code PID.\n&gt;\n&gt; I'd suggest persisting:\n&gt; - **Learning**: `$PPID` resolves to Claude Code PID\n&gt;   `ctx add learning --context \"...\" --lesson \"...\"`\n&gt; - **Task**: mark \"Add cooldown\" as done\n\n### Bad Examples\n\n* \"*We did some stuff. Want me to save it?*\"\n* Listing 10 trivial learnings that are general knowledge\n* Persisting without asking the user first\n</code></pre> <p>The good example shows the exact format, level of detail, and command syntax. The bad examples show where the boundary is.</p> <p>Together, they define a quality corridor without prescribing every word.</p> <p>Rules describe. Examples demonstrate.</p>","path":["The Anatomy of a Skill That Works"],"tags":[]},{"location":"blog/2026-02-07-the-anatomy-of-a-skill-that-works/#lesson-4-skills-are-read-by-agents-not-humans","level":2,"title":"Lesson 4: Skills Are Read by Agents, Not Humans","text":"<p>This seems obvious, but it has non-obvious consequences. During the rewrite, one skill included guidance that said \"use a blog or notes app\" for general knowledge that does not belong in the project's learnings file.</p> <p>The agent does not have a notes app. It does not browse the web to find one. This instruction, clearly written for a human audience, was dead weight in a skill consumed by an AI.</p> <p>Skills are for the Agents</p> <p>Every sentence in a skill should be actionable by the agent.</p> <p>If the guidance requires human judgment or human tools, it belongs in documentation, not in a skill.</p> <p>The corollary: command references must be exact. A skill that says \"save it somewhere\" is useless. A skill that says <code>ctx add learning --context \"...\" --lesson \"...\" --application \"...\"</code> is actionable.</p> <p>The agent can pattern-match and fill in the blanks.</p> <p>Litmus test: If a sentence starts with \"you could…\" or assumes external tools, it does not belong in a skill.</p>","path":["The Anatomy of a Skill That Works"],"tags":[]},{"location":"blog/2026-02-07-the-anatomy-of-a-skill-that-works/#lesson-5-the-description-field-is-the-trigger","level":2,"title":"Lesson 5: The Description Field Is the Trigger","text":"<p>This was covered in Skills That Fight the Platform, but the rewrite reinforced it with data. Several skills had good bodies but vague descriptions:</p> <pre><code># Before: vague, activates too broadly or not at all\ndescription: \"Show context summary.\"\n\n# After: specific, activates at the right time\ndescription: \"Show context summary. Use at session start or\n  when unclear about current project state.\"\n</code></pre> <p>The description is not a title. It is the activation condition.</p> <p>The platform's skill matching reads this field to decide whether to surface the skill. A vague description means the skill either never triggers or triggers when it should not.</p>","path":["The Anatomy of a Skill That Works"],"tags":[]},{"location":"blog/2026-02-07-the-anatomy-of-a-skill-that-works/#lesson-6-flag-tables-beat-prose","level":2,"title":"Lesson 6: Flag Tables Beat Prose","text":"<p>Most skills wrap CLI tools. The thin versions described flags in prose, if at all. The rewritten versions use tables:</p> <pre><code>| Flag        | Short | Default | Purpose                  |\n|-------------|-------|---------|--------------------------|\n| `--limit`   | `-n`  | 20      | Maximum sessions to show |\n| `--project` | `-p`  | \"\"      | Filter by project name   |\n| `--full`    |       | false   | Show complete content    |\n</code></pre> <p>Tables are scannable, complete, and unambiguous. The agent can read them faster than parsing prose, and they serve as both reference and validation: If the agent invokes a flag not in the table, something is wrong.</p>","path":["The Anatomy of a Skill That Works"],"tags":[]},{"location":"blog/2026-02-07-the-anatomy-of-a-skill-that-works/#lesson-7-template-drift-is-a-real-maintenance-burden","level":2,"title":"Lesson 7: Template Drift Is a Real Maintenance Burden","text":"<p><code>ctx</code> deploys skills through templates (via <code>ctx init</code>). Every skill exists in two places: the live version (<code>.claude/skills/</code>) and the template (<code>internal/tpl/claude/skills/</code>).</p> <p>They must match.</p> <p>During the rewrite, every skill update required editing both files and running <code>diff</code> to verify. This sounds trivial, but across 16 template-backed skills, it was the most error-prone part of the process.</p> <p>Template drift is dangerous because it creates false confidence: the agent appears to follow rules that no longer exist.</p> <p>The lesson: if your skills have a deployment mechanism, build the drift check into your workflow. We added a row to the <code>update-docs</code> skill's mapping table specifically for this:</p> <pre><code>| `internal/tpl/claude/skills/` | `.claude/skills/` (live) |\n</code></pre> <p>Intentional differences (like project-specific scripts in the live version but not the template) should be documented, not discovered later as bugs.</p>","path":["The Anatomy of a Skill That Works"],"tags":[]},{"location":"blog/2026-02-07-the-anatomy-of-a-skill-that-works/#the-rewrite-scorecard","level":2,"title":"The Rewrite Scorecard","text":"Metric Before After Average skill body ~15 lines ~80 lines Skills with quality gate 0 20 Skills with \"When NOT\" 0 20 Skills with examples 3 20 Skills with flag tables 2 12 Skills with checklist 0 20 <p>More lines, but almost entirely Expert content (per the E/A/R framework). No personality roleplay, no redundant guidance, no capability lists. Just project-specific knowledge the platform does not have.</p>","path":["The Anatomy of a Skill That Works"],"tags":[]},{"location":"blog/2026-02-07-the-anatomy-of-a-skill-that-works/#the-meta-lesson","level":2,"title":"The Meta-Lesson","text":"<p>The previous two posts argued that skills should provide knowledge, not personality; that they should complement the platform, not fight it; that they should grow from project history, not imported templates.</p> <p>This post adds the missing piece: structure.</p> <p>A skill without a structure is a wish.</p> <p>A skill with quality gates, negative triggers, examples, and checklists is a tool: the difference is not the content; it is whether the agent can reliably execute it without human intervention.</p> <p>Skills are Interfaces</p> <p>Good skills are not instructions. They are contracts.:</p> <ul> <li>They specify preconditions, postconditions, and boundaries.</li> <li>They show what success looks like and what failure looks like.</li> <li>They trust the agent's intelligence but do not trust its assumptions.</li> </ul> <p>If you remember one thing from this post...</p> <p>Skills that work have bones, not just flesh.</p> <p>Quality gates, negative triggers, examples, and checklists are the skeleton. The domain knowledge is the muscle.</p> <p>Without the skeleton, the muscle has nothing to attach to.</p> <p>This post was written during the same session that rewrote all 22 skills. The skill-creator skill was updated to encode these patterns. The meta continues.</p>","path":["The Anatomy of a Skill That Works"],"tags":[]},{"location":"blog/2026-02-08-not-everything-is-a-skill/","level":1,"title":"Not Everything Is a Skill","text":"","path":["Not Everything Is a Skill"],"tags":[]},{"location":"blog/2026-02-08-not-everything-is-a-skill/#what-a-codebase-audit-taught-me-about-restraint","level":2,"title":"What a Codebase Audit Taught Me About Restraint","text":"<p>Jose Alekhinne / 2026-02-08</p> <p>When you find a useful prompt, what do you do with it?</p> <p>My instinct was to make it a skill. </p> <p>I had just spent three posts explaining how to build skills that work.  Naturally, the hammer wanted nails.</p> <p>Then I looked at what I was holding and realized: this is not a nail.</p>","path":["Not Everything Is a Skill"],"tags":[]},{"location":"blog/2026-02-08-not-everything-is-a-skill/#the-audit","level":2,"title":"The Audit","text":"<p>I wanted to understand how I use <code>ctx</code>: </p> <ul> <li>where the friction is, </li> <li>what works, what drifts, </li> <li>what I keep doing manually that could be automated. </li> </ul> <p>So I wrote a prompt that spawned eight agents to analyze the codebase from  different angles:</p> Agent Analysis 1 Extractable patterns from session history 2 Documentation drift (godoc, inline comments) 3 Maintainability (large functions, misplaced code) 4 Security review (CLI-specific surface) 5 Blog theme discovery 6 Roadmap and value opportunities 7 User-facing documentation gaps 8 Agent team strategies for future sessions <p>The prompt was specific: </p> <ul> <li>read-only agents, </li> <li>structured output format,</li> <li>concrete file references, </li> <li>ranked recommendations. </li> </ul> <p>It ran for about  20 minutes and produced eight Markdown reports.</p> <p>The reports were good: Not perfect, but actionable.</p> <p>What mattered was not the speed. It was that the work could be explored without committing to any single outcome.</p> <p>They surfaced a stale <code>doc.go</code> referencing a subcommand that was never built. </p> <p>They found 311 build-then-test sequences I could reduce to a single <code>make check</code>. </p> <p>They identified that 42% of my sessions start with \"do you remember?\",  which is a lot of repetition for something a skill could handle.</p> <p>I had findings. I had recommendations. I had the instinct to automate.</p> <p>And then... I stopped.</p>","path":["Not Everything Is a Skill"],"tags":[]},{"location":"blog/2026-02-08-not-everything-is-a-skill/#the-question","level":2,"title":"The Question","text":"<p>The natural next step was to wrap the audit prompt as <code>/ctx-audit</code>: a skill you invoke periodically to get a health check. It fits the pattern. It has a clear trigger. It produces structured output.</p> <p>But I had just spent a week writing about what makes skills work, and the criteria I established argued against it.</p> <p>From The Anatomy of a Skill That Works:</p> <p>\"A skill without boundaries is just a suggestion.\"</p> <p>From You Can't Import Expertise:</p> <p>\"Frameworks travel, expertise doesn't.\"</p> <p>From Skills That Fight the Platform:</p> <p>\"You are the guest, not the host.\"</p> <p>The audit prompt fails all three tests:</p> Criterion Audit prompt Good skill Frequency Quarterly, maybe Daily or weekly Stability Tweaked every time Consistent invocation Scope Bespoke, 8 parallel agents Single focused action Trigger \"I feel like auditing\" Clear, repeatable event <p>Skills are contracts. Contracts need stable terms. </p> <p>A prompt I will rewrite every time I use it is not a contract.  It is a conversation starter.</p>","path":["Not Everything Is a Skill"],"tags":[]},{"location":"blog/2026-02-08-not-everything-is-a-skill/#recipes-vs-skills","level":2,"title":"Recipes vs Skills","text":"<p>The distinction that emerged:</p> Skill Recipe Invocation <code>/slash-command</code> Copy-paste from a doc Frequency High (daily, weekly) Low (quarterly, ad hoc) Stability Fixed contract Adapted each time Scope One focused action Multi-step orchestration Audience The agent The human (who then prompts) Lives in <code>.claude/skills/</code> <code>hack/</code> or <code>docs/</code> Attention cost Loaded into context on match Zero until needed <p>Recipes can later graduate into skills, but only after repetition proves stability.</p> <p>That last row matters. Skills consume the attention budget every time the platform considers activating them. A skill that triggers quarterly but gets evaluated on every prompt is pure waste: attention spent on something that will say \"When NOT to Use: now\" 99% of the time.</p> <p>Recipes have zero attention cost. They sit in a Markdown file until a human decides to use them. The human provides the judgment about timing. The prompt provides the structure.</p> <p>The Attention Budget Applies to Skills Too</p> <p>Every skill in <code>.claude/skills/</code> is a standing claim on the context window. The platform evaluates skill descriptions against every user prompt to decide whether to activate.</p> <p>Twenty focused skills are fine. Thirty might be fine. But each one added reduces the headroom available for actual work.</p> <p>Recipes are skills that opted out of the attention tax.</p>","path":["Not Everything Is a Skill"],"tags":[]},{"location":"blog/2026-02-08-not-everything-is-a-skill/#what-the-audit-actually-produced","level":2,"title":"What the Audit Actually Produced","text":"<p>The audit was not wasted. It was a planning exercise that generated concrete tasks:</p> Finding Action 42% of sessions start with memory check Task: <code>/ctx-remember</code> skill (this one is a skill; it is daily) Auto-save stubs are empty Task: enhance <code>/ctx-save</code> with richer summaries 311 raw build-test sequences Task: <code>make check</code> target Stale <code>recall/doc.go</code> lists nonexistent <code>serve</code> Task: fix the doc.go 120 commit sequences disconnected from context Task: <code>/ctx-commit</code> workflow <p>Some findings became skills. Some became <code>Makefile</code> targets. Some became one-line doc fixes. </p> <p>The audit did not prescribe the artifact type. The findings did.</p> <p>The audit is the input. Skills are one possible output. Not the only one.</p>","path":["Not Everything Is a Skill"],"tags":[]},{"location":"blog/2026-02-08-not-everything-is-a-skill/#the-audit-prompt","level":2,"title":"The Audit Prompt","text":"<p>Here is the exact prompt I used, for those who are curious.</p> <p>This is not a template: It worked because it was written against this codebase, at this moment, with specific goals in mind.</p> <pre><code>I want you to create an agent team to audit this codebase. Save each report as\na separate Markdown file under `./ideas/` (or another directory if you prefer).\n\nUse read-only agents (subagent_type: Explore) for all analyses. No code changes.\n\nFor each report, use this structure:\n- Executive Summary (2-3 sentences + severity table)\n- Findings (grouped, with file:line references)\n- Ranked Recommendations (high/medium/low priority)\n- Methodology (what was examined, how)\n\nKeep reports actionable. Every finding should suggest a concrete fix or next step.\n\n## Analyses to Run\n\n### 1. Extractable Patterns (session mining)\nSearch session JSONL files, journal entries, and task archives for repetitive\nmulti-step workflows. Count frequency of bash command sequences, slash command\nusage, and recurring user prompts. Identify patterns that could become skills\nor scripts. Cross-reference with existing skills to find coverage gaps.\nOutput: ranked list of automation opportunities with frequency data.\n\n### 2. Documentation Drift (godoc + inline)\nCompare every doc.go against its package's actual exports and behavior. Check\ninline godoc comments on exported functions against their implementations.\nScan for stale TODO/FIXME/HACK comments. Check that package-level comments match\npackage names.\nOutput: drift items ranked by severity with exact file:line references.\n\n### 3. Maintainability\nLook for:\n- functions longer than 80 lines with clear split points\n- switch blocks with more than 5 cases that could be table-driven\n- inline comments like \"step 1\", \"step 2\" that indicate a block wants to be a function\n- files longer than 400 lines\n- flat packages that could benefit from sub-packages\n- functions that appear misplaced in their file\n\nDo NOT flag things that are fine as-is just because they could theoretically\nbe different.\nOutput: concrete refactoring suggestions, not style nitpicks.\n\n### 4. Security Review\nThis is a CLI app. Focus on CLI-relevant attack surface, not web OWASP:\n- file path traversal\n- command injection\n- symlink following when writing to `.context/`\n- permission handling\n- sensitive data in outputs\n\nOutput: findings with severity ratings and plausible exploit scenarios.\n\n### 5. Blog Theme Discovery\nRead existing blog posts for style and narrative voice. Analyze git history,\nrecent session discussions, and DECISIONS.md for story arcs worth writing about.\nSuggest 3-5 blog post themes with:\n- title\n- angle\n- target audience\n- key commits or sessions to reference\n- a 2-sentence pitch\n\nPrioritize themes that build a coherent narrative across posts.\n\n### 6. Roadmap and Value Opportunities\nBased on current features, recent momentum, and gaps found in other analyses,\nidentify the highest-value improvements. Consider user-facing features,\ndeveloper experience, integration opportunities, and low-hanging fruit.\nOutput: prioritized list with rough effort and impact estimates.\n\n### 7. User-Facing Documentation\nEvaluate README, help text, and user docs. Suggest improvements structured as\nuse-case pages: the problem, how ctx solves it, a typical workflow, and gotchas.\nIdentify gaps where a user would get stuck without reading source code.\nOutput: documentation gaps with suggested page outlines.\n\n### 8. Agent Team Strategies\nBased on the codebase structure, suggest 2-3 agent team configurations for\nupcoming work sessions. For each, include:\n- team composition (roles and agent types)\n- task distribution strategy\n- coordination approach\n- the kinds of work it suits\n</code></pre> <p>Avoid Generic Advice</p> <p>Suggestions that are not grounded in a project's actual structure, history, and workflows are worse than useless:</p> <p>They create false confidence.</p> <p>If an analysis cannot point to concrete files, commits,  sessions, or patterns, it should say \"no finding\"  instead of inventing best practices.</p>","path":["Not Everything Is a Skill"],"tags":[]},{"location":"blog/2026-02-08-not-everything-is-a-skill/#the-deeper-pattern","level":2,"title":"The Deeper Pattern","text":"<p>This is part of a pattern I keep rediscovering: the urge to automate is not the same as the need to automate:</p> <ul> <li>The 3:1 ratio taught me that not every session should be a YOLO sprint. </li> <li>The E/A/R framework taught me that not every template    is worth importing. Now the audit is teaching me that    not every useful prompt is worth institutionalizing.</li> </ul> <p>The common thread is restraint: Knowing when to stop. Recognizing that the cost of automation is not just the effort to build it. It is the ongoing attention tax of maintaining it, the context it consumes, and the false confidence it creates when it drifts.</p> <p>A recipe in <code>hack/codebase-audit.md</code> is honest about what it is:</p> <p>A prompt I wrote once, improved once, and will adapt again next time: </p> <ul> <li>It does not pretend to be a reliable contract. </li> <li>It does not claim attention budget. </li> <li>It does not drift silently.</li> </ul> <p>The Automation Instinct</p> <p>When you find a useful prompt, the instinct is to institutionalize it. Resist.</p> <p>Ask first: will I use this the same way next time?</p> <p>If yes, it is a skill. If no, it is a recipe. If you are not sure, it is a recipe until proven otherwise.</p>","path":["Not Everything Is a Skill"],"tags":[]},{"location":"blog/2026-02-08-not-everything-is-a-skill/#this-mindset-in-the-context-of-ctx","level":2,"title":"This Mindset In the Context of <code>ctx</code>","text":"<p><code>ctx</code> is a tool that gives AI agents persistent memory. Its purpose is automation: reducing the friction of context loading, session recall, decision tracking.</p> <p>But automation has boundaries, and knowing where those boundaries are is as important as pushing them forward. </p> <p>The skills system is for high-frequency, stable workflows. </p> <p>The recipes, the journal entries, the session dumps in  <code>.context/sessions/</code>: those are for everything else.</p> <p>Not everything needs to be a slash command. Some things are better as Markdown files you read when you need them.</p> <p>The goal of <code>ctx</code> is not to automate everything: It is to automate the right things and to make the rest easy to find when you need it.</p> <p>If you remember one thing from this post...</p> <p>The best automation decision is sometimes not to automate.</p> <p>A recipe in a Markdown file costs nothing until you use it. A skill costs attention on every prompt, whether it fires or not.</p> <p>Automate the daily. Document the periodic. Forget the rest.</p> <p>This post was written during the session that produced the codebase audit reports and distilled the prompt into <code>hack/codebase-audit.md</code>. The audit generated seven tasks, one Makefile target, and zero new skills. The meta continues.</p>","path":["Not Everything Is a Skill"],"tags":[]},{"location":"recipes/","level":1,"title":"Recipes","text":"<p>Workflow recipes showing how ctx commands and skills work together. Each recipe solves a specific problem by combining multiple tools into a step-by-step workflow.</p> <p>Commands vs. Skills</p> <p>Commands (<code>ctx status</code>, <code>ctx add task</code>) run in your terminal.</p> <p>Skills (<code>/ctx-save</code>, <code>/ctx-next</code>) run inside your AI coding assistant. </p> <p>Recipes combine both.</p> <p>Think of commands as structure and skills as behavior.</p> <p>Guide Your Agent</p> <p>These recipes show explicit commands and skills, but agents trained on the ctx playbook are proactive: they offer to save learnings after debugging, record decisions after trade-offs, create follow-up tasks after completing work, and suggest what to work on next.</p> <p>Your questions train the agent. Asking \"what have we learned?\" or \"is our context clean?\" does two things: it triggers the workflow right now, and it reinforces the pattern. The more you guide, the more the agent habituates the behavior and begins offering on its own.</p> <p>Don't wait passively for proactive behavior — especially in early sessions. Ask, guide, reinforce. Over time, you ask less and the agent offers more.</p> <p>Each recipe includes a Conversational Approach section showing these natural-language patterns.</p>","path":["Recipes"],"tags":[]},{"location":"recipes/#getting-started","level":2,"title":"Getting Started","text":"","path":["Recipes"],"tags":[]},{"location":"recipes/#setting-up-ctx-across-ai-tools","level":3,"title":"Setting Up ctx Across AI Tools","text":"<p>Initialize ctx and configure hooks for Claude Code, Cursor, Aider, Copilot, or Windsurf. Includes shell completion, watch mode for non-native tools, and verification.</p> <p>Uses: <code>ctx init</code>, <code>ctx hook</code>, <code>ctx agent</code>, <code>ctx completion</code>, <code>ctx watch</code>, <code>ctx session parse</code></p>","path":["Recipes"],"tags":[]},{"location":"recipes/#daily-workflow","level":2,"title":"Daily Workflow","text":"<p>These recipes cover the workflows you’ll use every day when working with ctx.</p>","path":["Recipes"],"tags":[]},{"location":"recipes/#the-complete-session","level":3,"title":"The Complete Session","text":"<p>Walk through a full ctx session from start to finish: loading context, picking what to work on, committing with context capture, reflecting, and saving a snapshot.</p> <p>Uses: <code>ctx status</code>, <code>ctx agent</code>, <code>ctx session save/list/load</code>, <code>/ctx-remember</code>, <code>/ctx-next</code>, <code>/ctx-commit</code>, <code>/ctx-reflect</code>, <code>/ctx-save</code></p>","path":["Recipes"],"tags":[]},{"location":"recipes/#tracking-work-across-sessions","level":3,"title":"Tracking Work Across Sessions","text":"<p>Add, prioritize, complete, snapshot, and archive tasks. Keep TASKS.md focused as your project evolves across dozens of sessions.</p> <p>Uses: <code>ctx add task</code>, <code>ctx complete</code>, <code>ctx tasks archive</code>, <code>ctx tasks snapshot</code>, <code>/ctx-add-task</code>, <code>/ctx-archive</code>, <code>/ctx-next</code></p>","path":["Recipes"],"tags":[]},{"location":"recipes/#persisting-decisions-learnings-and-conventions","level":3,"title":"Persisting Decisions, Learnings, and Conventions","text":"<p>Record architectural decisions with rationale, capture gotchas and lessons learned, and codify coding conventions so they survive across sessions and team members.</p> <p>Uses: <code>ctx add decision</code>, <code>ctx add learning</code>, <code>ctx add convention</code>, <code>ctx decisions reindex</code>, <code>ctx learnings reindex</code>, <code>/ctx-add-decision</code>, <code>/ctx-add-learning</code>, <code>/ctx-add-convention</code>, <code>/ctx-reflect</code></p>","path":["Recipes"],"tags":[]},{"location":"recipes/#maintenance","level":2,"title":"Maintenance","text":"","path":["Recipes"],"tags":[]},{"location":"recipes/#detecting-and-fixing-drift","level":3,"title":"Detecting and Fixing Drift","text":"<p>Keep context files accurate by detecting structural drift (stale paths, missing files) and semantic drift (outdated conventions, superseded decisions). Includes alignment audits to verify documentation claims match agent instructions.</p> <p>Uses: <code>ctx drift</code>, <code>ctx sync</code>, <code>ctx compact</code>, <code>ctx status</code>, <code>/ctx-drift</code>, <code>/ctx-alignment-audit</code>, <code>/ctx-status</code>, <code>/ctx-prompt-audit</code></p>","path":["Recipes"],"tags":[]},{"location":"recipes/#history-and-discovery","level":2,"title":"History and Discovery","text":"","path":["Recipes"],"tags":[]},{"location":"recipes/#browsing-and-enriching-past-sessions","level":3,"title":"Browsing and Enriching Past Sessions","text":"<p>Export your AI session history to a browsable journal site. Normalize rendering, enrich entries with metadata, and search across months of work.</p> <p>Uses: <code>ctx recall list/show/export</code>, <code>ctx journal site</code>, <code>ctx serve</code>, <code>/ctx-recall</code>, <code>/ctx-journal-normalize</code>, <code>/ctx-journal-enrich</code>, <code>/ctx-journal-enrich-all</code></p>","path":["Recipes"],"tags":[]},{"location":"recipes/#advanced","level":2,"title":"Advanced","text":"","path":["Recipes"],"tags":[]},{"location":"recipes/#running-an-unattended-ai-agent","level":3,"title":"Running an Unattended AI Agent","text":"<p>Set up a loop where an AI agent works through tasks overnight without you at the keyboard, using ctx for persistent memory between iterations.</p> <p>This recipe shows how ctx supports long-running agent loops without losing context or intent.</p> <p>Uses: <code>ctx init --ralph</code>, <code>ctx loop</code>, <code>ctx watch</code>, <code>ctx load</code>, <code>/ctx-loop</code>, <code>/ctx-implement</code>, <code>/ctx-context-monitor</code></p>","path":["Recipes"],"tags":[]},{"location":"recipes/#turning-activity-into-content","level":3,"title":"Turning Activity into Content","text":"<p>Generate blog posts from project activity, write changelog posts from commit ranges, and publish a browsable journal site from your session history.</p> <p>Uses: <code>ctx journal site</code>, <code>ctx serve</code>, <code>ctx recall export</code>, <code>/ctx-blog</code>, <code>/ctx-blog-changelog</code>, <code>/ctx-journal-enrich</code>, <code>/ctx-journal-normalize</code></p>","path":["Recipes"],"tags":[]},{"location":"recipes/autonomous-loops/","level":1,"title":"Running an Unattended AI Agent","text":"","path":["Running an Unattended AI Agent"],"tags":[]},{"location":"recipes/autonomous-loops/#the-problem","level":2,"title":"The Problem","text":"<p>You have a project with a clear list of tasks and you want an AI agent to work through them autonomously: overnight, unattended, without you sitting at the keyboard. </p> <p>Each iteration needs to remember what the previous one did, mark tasks  as completed, and know when to stop.</p> <p>Without persistent memory, every iteration starts fresh and the loop collapses. With <code>ctx</code>, each iteration picks up exactly where the last one left off: but only if the agent proactively persists its context. </p> <p>This is the key insight: unattended operation works because the agent treats context persistence as part of the work itself, not as an afterthought.</p>","path":["Running an Unattended AI Agent"],"tags":[]},{"location":"recipes/autonomous-loops/#commands-and-skills-used","level":2,"title":"Commands and Skills Used","text":"Tool Type Purpose <code>ctx init --ralph</code> Command Initialize project for unattended operation (no human in the loop) <code>ctx loop</code> Command Generate the loop shell script <code>ctx watch --auto-save</code> Command Monitor AI output and persist context updates <code>ctx load</code> Command Display assembled context (for debugging) <code>/ctx-loop</code> Skill Generate loop script from inside Claude Code <code>/ctx-implement</code> Skill Execute a plan step-by-step with verification <code>/ctx-context-monitor</code> Skill Automated context capacity alerts during long sessions","path":["Running an Unattended AI Agent"],"tags":[]},{"location":"recipes/autonomous-loops/#the-workflow","level":2,"title":"The Workflow","text":"","path":["Running an Unattended AI Agent"],"tags":[]},{"location":"recipes/autonomous-loops/#step-1-initialize-for-unattended-operation","level":3,"title":"Step 1: Initialize for Unattended Operation","text":"<p>Start by creating a <code>.context/</code> directory configured so the agent can work without human input. The <code>--ralph</code> flag sets up <code>PROMPT.md</code> so the agent makes its own decisions rather than asking clarifying questions.</p> <pre><code>ctx init --ralph\n</code></pre> <p>This creates <code>.context/</code> with all template files, <code>PROMPT.md</code> configured for autonomous iteration, <code>IMPLEMENTATION_PLAN.md</code>, and <code>.claude/</code> hooks and skills for Claude Code. Without <code>--ralph</code>, the agent pauses to ask questions when requirements are unclear. For unattended runs, you want it to make reasonable choices and document them in <code>DECISIONS.md</code> instead.</p>","path":["Running an Unattended AI Agent"],"tags":[]},{"location":"recipes/autonomous-loops/#step-2-populate-tasksmd-with-phased-work","level":3,"title":"Step 2: Populate TASKS.md with Phased Work","text":"<p>Open <code>.context/TASKS.md</code> and organize your work into phases. The agent works through these systematically, top to bottom, from the highest priority task first.</p> <pre><code># Tasks\n\n## Phase 1: Foundation\n\n- [ ] Set up project structure and build system `#priority:high`\n- [ ] Configure testing framework `#priority:high`\n- [ ] Create CI pipeline `#priority:medium`\n\n## Phase 2: Core Features\n\n- [ ] Implement user registration `#priority:high`\n- [ ] Add email verification `#priority:high`\n- [ ] Create password reset flow `#priority:medium`\n\n## Phase 3: Hardening\n\n- [ ] Add rate limiting to API endpoints `#priority:medium`\n- [ ] Improve error messages `#priority:low`\n- [ ] Write integration tests `#priority:medium`\n</code></pre> <p>Phased organization matters because it gives the agent natural boundaries. Phase 1 tasks should be completable without Phase 2 code existing yet.</p>","path":["Running an Unattended AI Agent"],"tags":[]},{"location":"recipes/autonomous-loops/#step-3-configure-promptmd","level":3,"title":"Step 3: Configure PROMPT.md","text":"<p>The <code>--ralph</code> flag generates a <code>PROMPT.md</code> that instructs the agent to operate autonomously:</p> <ol> <li>Read <code>.context/CONSTITUTION.md</code> first (hard rules, never violated)</li> <li>Load context from <code>.context/</code> files</li> <li>Pick ONE task per iteration</li> <li>Complete the task and proactively update context files</li> <li>Commit changes (including <code>.context/</code>)</li> <li>Signal status with a completion signal</li> </ol> <p>You can customize <code>PROMPT.md</code> for your project. The critical parts are the one-task-per-iteration discipline, proactive context persistence, and the completion signals at the end:</p> <pre><code>## Signal Status\n\nEnd your response with exactly ONE of:\n\n- `SYSTEM_CONVERGED` — All tasks in TASKS.md are complete\n- `SYSTEM_BLOCKED` — Cannot proceed, need human input (explain why)\n- (no signal) — More work remains, continue to next iteration\n</code></pre>","path":["Running an Unattended AI Agent"],"tags":[]},{"location":"recipes/autonomous-loops/#step-4-generate-the-loop-script","level":3,"title":"Step 4: Generate the Loop Script","text":"<p>Use <code>ctx loop</code> to generate a <code>loop.sh</code> tailored to your AI tool:</p> <pre><code># Generate for Claude Code with a 10-iteration cap\nctx loop --tool claude --max-iterations 10\n\n# Generate for Aider\nctx loop --tool aider --max-iterations 10\n\n# Custom prompt and output file\nctx loop --tool claude --prompt TASKS.md --output my-loop.sh\n</code></pre> <p>The generated script reads <code>PROMPT.md</code>, pipes it to the AI tool, checks for completion signals, and loops until done or the cap is reached. You can also use the <code>/ctx-loop</code> skill from inside Claude Code.</p> <p>Shell Loop is Best Practice</p> <p>The shell while loop is the recommended approach for autonomous runs. Each iteration spawns a fresh AI process, so the only state that carries between iterations is what lives in <code>.context/</code> and git. This is \"pure ralph\": memory is explicit, not accidental.</p> <p>Claude Code's built-in <code>/loop</code> command runs iterations within the same session, which means context window state leaks between iterations. </p> <p>The agent \"remembers\" things from earlier iterations that were never persisted. This is convenient for short explorations (2-5 iterations) but less reliable for long unattended runs. See Autonomous Loops: Shell Loop vs Built-in  Loop for details.</p>","path":["Running an Unattended AI Agent"],"tags":[]},{"location":"recipes/autonomous-loops/#step-5-run-with-watch-mode","level":3,"title":"Step 5: Run with Watch Mode","text":"<p>Open two terminals. In the first, run the loop. In the second, run <code>ctx watch</code> to automatically process context updates from the AI output.</p> <pre><code># Terminal 1: Run the loop\n./loop.sh 2&gt;&amp;1 | tee /tmp/loop.log\n\n# Terminal 2: Watch for context updates\nctx watch --log /tmp/loop.log --auto-save\n</code></pre> <p>The <code>--auto-save</code> flag periodically saves session snapshots to <code>.context/sessions/</code>. The watch command parses XML context-update commands from the AI output and applies them:</p> <pre><code>&lt;context-update type=\"complete\"&gt;user registration&lt;/context-update&gt;\n&lt;context-update type=\"learning\"&gt;Email verification needs SMTP configured&lt;/context-update&gt;\n</code></pre>","path":["Running an Unattended AI Agent"],"tags":[]},{"location":"recipes/autonomous-loops/#step-6-completion-signals-end-the-loop","level":3,"title":"Step 6: Completion Signals End the Loop","text":"<p>The loop terminates when the agent emits one of these signals:</p> Signal Meaning What Happens <code>SYSTEM_CONVERGED</code> All tasks in TASKS.md are done Loop exits successfully <code>SYSTEM_BLOCKED</code> Agent cannot proceed Loop exits, you review the blocker <code>BOOTSTRAP_COMPLETE</code> Initial scaffolding done Loop exits after setup phase <p>When you return in the morning, check the log and the context files:</p> <pre><code># See what happened\ntail -100 /tmp/loop.log\n\n# Check task progress\nctx status\n\n# Load full context to see decisions and learnings\nctx load\n</code></pre>","path":["Running an Unattended AI Agent"],"tags":[]},{"location":"recipes/autonomous-loops/#step-7-use-ctx-implement-for-plan-execution","level":3,"title":"Step 7: Use /ctx-implement for Plan Execution","text":"<p>Within each iteration, the agent can use <code>/ctx-implement</code> to execute multi-step plans with verification between each step. This is especially useful for complex tasks that involve multiple files.</p> <p>The skill breaks a plan into atomic, verifiable steps:</p> <pre><code>Step 1/6: Create user model .................. OK\nStep 2/6: Add database migration ............. OK\nStep 3/6: Implement registration handler ..... OK\nStep 4/6: Write unit tests ................... OK\nStep 5/6: Run test suite ..................... FAIL\n  → Fixed: missing test dependency\n  → Re-verify ............................ OK\nStep 6/6: Update TASKS.md .................... OK\n</code></pre> <p>Each step is verified (build, test, syntax check) before moving to the next. Failures are fixed in place, not deferred.</p>","path":["Running an Unattended AI Agent"],"tags":[]},{"location":"recipes/autonomous-loops/#putting-it-together","level":2,"title":"Putting It Together","text":"<p>The full sequence for an overnight unattended run:</p> <pre><code># 1. Set up the project for unattended operation\nctx init --ralph\n\n# 2. Edit TASKS.md with your phased work items\n# 3. Review and customize PROMPT.md\n\n# 4. Generate the loop\nctx loop --tool claude --max-iterations 20\n\n# 5. Start watch mode in background\nctx watch --log /tmp/loop.log --auto-save &amp;\n\n# 6. Run the loop\n./loop.sh 2&gt;&amp;1 | tee /tmp/loop.log\n\n# 7. Next morning: review results\nctx status\nctx load\n</code></pre>","path":["Running an Unattended AI Agent"],"tags":[]},{"location":"recipes/autonomous-loops/#why-autonomous-loops-work-proactive-context-persistence","level":2,"title":"Why Autonomous Loops Work: Proactive Context Persistence","text":"<p>The autonomous loop pattern works because the agent is proactive about persisting context. Without proactive behavior, the loop degrades into disconnected iterations that repeat work, forget decisions, and lose track of progress. The agent cannot rely on a human to prompt it — it must treat context persistence as part of every task, not as a separate step.</p>","path":["Running an Unattended AI Agent"],"tags":[]},{"location":"recipes/autonomous-loops/#the-agent-playbooks-self-check-drives-autonomy","level":3,"title":"The Agent Playbook's Self-Check Drives Autonomy","text":"<p>The Agent Playbook defines a self-check prompt that the agent applies continuously:</p> <p>\"If this session ended right now, would the next session know what happened?\"</p> <p>In interactive sessions, a human might remind the agent to save context. When the agent runs unattended, no one is there to remind it. The self-check becomes the agent's internal trigger: after every meaningful action, the agent evaluates whether the context files reflect reality and acts immediately if they don't.</p>","path":["Running an Unattended AI Agent"],"tags":[]},{"location":"recipes/autonomous-loops/#what-the-agent-does-proactively-between-iterations","level":3,"title":"What the Agent Does Proactively Between Iterations","text":"<p>At each milestone within an iteration, the agent persists without waiting for instructions:</p> Milestone What the Agent Does Proactively Completes a task Marks it <code>[x]</code> in TASKS.md with <code>#done</code> timestamp Discovers a gotcha Adds it to LEARNINGS.md immediately Makes a design choice Records it in DECISIONS.md with rationale Identifies follow-up work Creates new tasks in TASKS.md with <code>#added</code> timestamp Finishes a phase Saves a session snapshot to <code>.context/sessions/</code> Hits an unexpected failure Documents the root cause before moving on","path":["Running an Unattended AI Agent"],"tags":[]},{"location":"recipes/autonomous-loops/#example-what-proactive-persistence-looks-like","level":3,"title":"Example: What Proactive Persistence Looks Like","text":"<p>Here is what the agent does during a single iteration, beyond just writing code:</p> <pre><code>Iteration 4:\n  1. Read TASKS.md → pick \"Add email verification\" (#priority:high)\n  2. Add #started:2026-01-25-030012 to the task\n  3. Implement the feature (code, tests, etc.)\n  4. Tests pass → mark task [x], add #done:2026-01-25-031544\n  5. Add learning: \"SMTP config must be set before verification\n     handler registers — order matters in init()\"\n  6. Add decision: \"Use token-based verification links (not codes)\n     because links work better in automated test environments\"\n  7. Notice rate limiting is needed → create new task:\n     \"- [ ] Add rate limiting to verification endpoint #added:2026-01-25-031602 #priority:medium\"\n  8. Commit all changes INCLUDING .context/ files\n  9. No signal emitted → loop continues to iteration 5\n</code></pre> <p>Steps 2, 4, 5, 6, and 7 are proactive context persistence. The agent was not asked to do any of them. It does them because the playbook's Work-Reflect-Persist cycle is internalized: after completing meaningful work, reflect on what happened, then persist before moving on.</p>","path":["Running an Unattended AI Agent"],"tags":[]},{"location":"recipes/autonomous-loops/#session-snapshots-at-milestones","level":3,"title":"Session Snapshots at Milestones","text":"<p>For long autonomous runs, the agent saves session snapshots at natural boundaries — typically at phase transitions or after completing a cluster of related tasks. These snapshots give you a narrative of what happened overnight, not just a list of commits:</p> <pre><code>.context/sessions/\n  2026-01-25-020000-phase1-foundation.md\n  2026-01-25-040000-phase2-core-features.md\n  2026-01-25-060000-phase3-hardening.md\n</code></pre> <p>Each snapshot summarizes what was accomplished, what decisions were made, and what the agent plans to do next. If the loop crashes at 4 AM, the snapshot from 4 AM tells the next session (or you) exactly where to resume.</p>","path":["Running an Unattended AI Agent"],"tags":[]},{"location":"recipes/autonomous-loops/#the-persistence-contract","level":3,"title":"The Persistence Contract","text":"<p>The autonomous loop has an implicit contract:</p> <ol> <li>Every iteration reads context — TASKS.md, DECISIONS.md, LEARNINGS.md</li> <li>Every iteration writes context — task updates, new learnings, decisions</li> <li>Every commit includes <code>.context/</code> — so the next iteration sees changes</li> <li>Context is always current — if the loop stopped right now, nothing is lost</li> </ol> <p>Break any part of this contract and the loop degrades: iterations repeat work, contradict earlier decisions, or lose track of what's done. The agent's proactive discipline is what holds the loop together.</p>","path":["Running an Unattended AI Agent"],"tags":[]},{"location":"recipes/autonomous-loops/#tips","level":2,"title":"Tips","text":"<ul> <li> <p>Start with a small iteration cap. Use <code>--max-iterations 5</code> for   your first run to verify the loop behaves correctly before leaving   it unattended.</p> </li> <li> <p>Keep tasks atomic. Each task should be completable in a single   iteration. \"Build the entire authentication system\" is too broad;   break it into registration, login, password reset, etc.</p> </li> <li> <p>Use CONSTITUTION.md for guardrails. Add rules like \"never delete   production data\" or \"always run tests before committing\" to prevent   the agent from making dangerous mistakes at 3 AM.</p> </li> <li> <p>Check for signal discipline. If the loop runs forever, the agent   is not emitting <code>SYSTEM_CONVERGED</code> or <code>SYSTEM_BLOCKED</code>. Add explicit   instructions to PROMPT.md reminding it to signal after every task.</p> </li> <li> <p>Commit after context updates. The order matters: complete the   coding work, update context files (<code>ctx complete</code>, <code>ctx add</code>),   commit everything including <code>.context/</code>, then signal. If context   updates are not committed, the next iteration loses them.</p> </li> <li> <p>Use <code>/ctx-context-monitor</code> for long sessions. In Claude Code,   the context checkpoint hook fires automatically and alerts you when   context capacity is running low, so the agent can save its work   before hitting limits.</p> </li> </ul>","path":["Running an Unattended AI Agent"],"tags":[]},{"location":"recipes/autonomous-loops/#next-up","level":2,"title":"Next Up","text":"<p>Turning Activity into Content -- Generate blog posts and changelogs from your project activity.</p>","path":["Running an Unattended AI Agent"],"tags":[]},{"location":"recipes/autonomous-loops/#see-also","level":2,"title":"See Also","text":"<ul> <li>Autonomous Loops: Full documentation of   the loop pattern, PROMPT.md templates, and troubleshooting</li> <li>CLI Reference: ctx loop: Command   flags and options</li> <li>CLI Reference: ctx watch: Watch   mode details</li> <li>CLI Reference: ctx init: Init flags   including <code>--ralph</code> for unattended operation</li> <li>The Complete Session: Interactive workflow   (the human-attended counterpart)</li> <li>Tracking Work Across Sessions: How to   structure TASKS.md effectively</li> </ul>","path":["Running an Unattended AI Agent"],"tags":[]},{"location":"recipes/context-health/","level":1,"title":"Detecting and Fixing Drift","text":"","path":["Detecting and Fixing Drift"],"tags":[]},{"location":"recipes/context-health/#the-problem","level":2,"title":"The Problem","text":"<p>Context files drift: you rename a package, delete a module, or finish a sprint, and suddenly <code>ARCHITECTURE.md</code> references paths that no longer exist, <code>TASKS.md</code> is 80 percent completed checkboxes, and <code>CONVENTIONS.md</code> describes patterns you stopped using two months ago.</p> <p>Stale context is worse than no context: an AI tool that trusts outdated references will hallucinate confidently.</p> <p>This recipe shows how to detect drift, fix it, and keep your <code>.context/</code> directory lean and accurate.</p>","path":["Detecting and Fixing Drift"],"tags":[]},{"location":"recipes/context-health/#commands-and-skills-used","level":2,"title":"Commands and Skills Used","text":"Tool Type Purpose <code>ctx drift</code> Command Detect stale paths, missing files, violations <code>ctx drift --fix</code> Command Auto-fix simple issues <code>ctx sync</code> Command Reconcile context with codebase structure <code>ctx compact</code> Command Archive completed tasks, deduplicate learnings <code>ctx status</code> Command Quick health overview <code>/ctx-drift</code> Skill Structural plus semantic drift detection <code>/ctx-alignment-audit</code> Skill Audit doc claims against agent instructions <code>/ctx-status</code> Skill In-session context summary <code>/ctx-prompt-audit</code> Skill Audit prompt quality and token efficiency","path":["Detecting and Fixing Drift"],"tags":[]},{"location":"recipes/context-health/#the-workflow","level":2,"title":"The Workflow","text":"<p>The best way to maintain context health is conversational: ask your agent, guide it, and let it detect problems, explain them, and fix them with your approval. CLI commands exist for CI pipelines, scripting, and fine-grained control. </p> <p>For day-to-day maintenance, talk to your agent.</p> <p>Your Questions Reinforce the Pattern</p> <p>Asking \"is our context clean?\" does two things:</p> <ul> <li>it triggers a drift check right now</li> <li>it reinforces the habit</li> </ul> <p>This is reinforcement, not enforcement.</p> <p>Do not wait for the agent to be proactive on its own. Guide it, especially in early sessions. Over time, you will ask less and the agent will start offering more.</p>","path":["Detecting and Fixing Drift"],"tags":[]},{"location":"recipes/context-health/#step-1-ask-your-agent","level":3,"title":"Step 1: Ask Your Agent","text":"<p>The simplest way to check context health:</p> <pre><code>Is our context clean?\nAnything stale?\nHow healthy are our context files?\n````\n\nOr invoke the skill directly:\n\n```text\n/ctx-drift\n</code></pre> <p>The agent performs two layers of analysis:</p> <p>Layer 1, structural checks (via <code>ctx drift</code>): dead paths, missing files, completed task counts, constitution violations. Fast and programmatic.</p> <p>Layer 2, semantic analysis (agent-driven): does <code>CONVENTIONS.md</code> describe patterns the code no longer follows? Does <code>DECISIONS.md</code> contain entries whose rationale no longer applies? Are there learnings about bugs that are now fixed? This is where the agent adds value the CLI cannot: it reads both context files and source code and compares them.</p> <p>The agent reports both layers together, explains each finding in plain language, and offers to fix what it can.</p>","path":["Detecting and Fixing Drift"],"tags":[]},{"location":"recipes/context-health/#step-2-maintenance-at-session-start","level":3,"title":"Step 2: Maintenance at Session Start","text":"<p>You do not need to ask explicitly. A proactive agent can check context health as part of its startup routine and mention anything worth addressing:</p> <pre><code>Agent: Good morning. I've loaded the context files. A few things\n       before we start:\n\n       - ARCHITECTURE.md references `pkg/auth/` which is now empty\n       - DECISIONS.md hasn't been updated in 40 days\n       - There are 18 completed tasks ready for archival\n\n       Want me to run a quick maintenance pass, or should we jump\n       straight into today's work?\n</code></pre> <p>If the agent does not offer this on its own, a gentle nudge is enough:</p> <pre><code>Anything stale before we start?\nHow's the context looking?\n</code></pre> <p>This turns maintenance from a scheduled chore into a conversation that happens when it matters.</p>","path":["Detecting and Fixing Drift"],"tags":[]},{"location":"recipes/context-health/#step-3-real-time-detection-during-work","level":3,"title":"Step 3: Real-Time Detection During Work","text":"<p>Agents notice drift while working, not just during explicit checks. When an agent reads <code>ARCHITECTURE.md</code> to understand a module and then opens the actual source tree, it can see mismatches immediately:</p> <pre><code>Agent: I notice ARCHITECTURE.md still references `internal/handlers/`\n       which we deleted in the last refactor. Want me to run drift\n       detection so we can clean up any other stale references?\n</code></pre> <p>The agent is already reading context files to do its job. Noticing staleness is a natural byproduct of that.</p>","path":["Detecting and Fixing Drift"],"tags":[]},{"location":"recipes/context-health/#step-4-archival-and-cleanup","level":3,"title":"Step 4: Archival and Cleanup","text":"<p>Agents spot clutter too. When <code>TASKS.md</code> is loaded and most of the content is completed checkboxes, the agent can offer to tidy up:</p> <pre><code>Agent: TASKS.md has 25 completed tasks obscuring the 4 pending ones.\n       Want me to archive the finished work so we can focus on what's\n       active?\n</code></pre> <p>The same applies to <code>LEARNINGS.md</code> with near-duplicate entries, or <code>DECISIONS.md</code> with entries that were superseded.</p>","path":["Detecting and Fixing Drift"],"tags":[]},{"location":"recipes/context-health/#step-5-alignment-audits","level":3,"title":"Step 5: Alignment Audits","text":"<p>A related problem is alignment drift: documentation that makes claims about agent behavior not backed by actual playbook or skill instructions. </p> <p>Over time, docs accumulate aspirational statements that no instruction teaches  the agent to do.</p> <p>Use <code>/ctx-alignment-audit</code> to trace behavioral claims in documentation against the playbook and skill files. The skill identifies gaps, proposes fixes, and checks instruction file health (token budgets, bloat signals).</p> <p>To avoid confusion with <code>/ctx-prompt-audit</code>:</p> <ul> <li><code>/ctx-alignment-audit</code> checks whether documentation claims are supported by   actual instructions (playbook, skills, <code>CLAUDE.md</code>).</li> <li><code>/ctx-prompt-audit</code> checks whether your context files are clear, compact, and   token-efficient for the model.</li> </ul>","path":["Detecting and Fixing Drift"],"tags":[]},{"location":"recipes/context-health/#cli-reference","level":2,"title":"CLI Reference","text":"<p>The conversational approach above uses CLI commands under the hood. When you need direct control, use the commands directly.</p>","path":["Detecting and Fixing Drift"],"tags":[]},{"location":"recipes/context-health/#ctx-drift","level":3,"title":"<code>ctx drift</code>","text":"<p>Scan context files for structural problems:</p> <pre><code>ctx drift\n</code></pre> <p>Sample output:</p> <pre><code>Drift Report\n============\n\nWarnings (3):\n  ARCHITECTURE.md:14  path \"internal/api/router.go\" does not exist\n  ARCHITECTURE.md:28  path \"pkg/auth/\" directory is empty\n  CONVENTIONS.md:9    path \"internal/handlers/\" not found\n\nViolations (1):\n  TASKS.md            31 completed tasks (recommend archival)\n\nStaleness:\n  DECISIONS.md        last modified 45 days ago\n  LEARNINGS.md        last modified 32 days ago\n\nExit code: 1 (warnings found)\n</code></pre> Level Meaning Action Warning Stale path references, missing files Fix or remove Violation Constitution rule heuristic failures, heavy clutter Fix soon Staleness Files not updated recently Review content <p>Exit codes: <code>0</code> equals clean, <code>1</code> equals warnings, <code>3</code> equals violations.</p> <p>For CI integration:</p> <pre><code>ctx drift --json | jq '.warnings | length'\n</code></pre>","path":["Detecting and Fixing Drift"],"tags":[]},{"location":"recipes/context-health/#ctx-drift-fix","level":3,"title":"<code>ctx drift --fix</code>","text":"<p>Auto-fix mechanical issues:</p> <pre><code>ctx drift --fix\n</code></pre> <p>This handles removing dead path references, updating unambiguous renames, clearing empty sections. Issues requiring judgment are flagged but left for you.</p> <p>Run <code>ctx drift</code> again afterward to confirm what remains.</p>","path":["Detecting and Fixing Drift"],"tags":[]},{"location":"recipes/context-health/#ctx-sync","level":3,"title":"<code>ctx sync</code>","text":"<p>After a refactor, reconcile context with the actual codebase structure:</p> <pre><code>ctx sync --dry-run   # preview first\nctx sync             # apply\n</code></pre> <p><code>ctx sync</code> scans for structural changes, compares with <code>ARCHITECTURE.md</code>,  checks for new dependencies worth documenting, and identifies context referring  to code that no longer exists.</p>","path":["Detecting and Fixing Drift"],"tags":[]},{"location":"recipes/context-health/#ctx-compact","level":3,"title":"<code>ctx compact</code>","text":"<p>Archive completed tasks and deduplicate learnings:</p> <pre><code>ctx compact --archive\n</code></pre> <ul> <li>Tasks: moves completed tasks older than 7 days to   <code>.context/archive/tasks-YYYY-MM-DD.md</code></li> <li>Learnings: deduplicates entries with similar content</li> <li>All files: removes empty sections left behind</li> </ul> <p>The <code>--archive</code> flag preserves old content. Skip the auto-save with <code>--no-auto-save</code>.</p>","path":["Detecting and Fixing Drift"],"tags":[]},{"location":"recipes/context-health/#ctx-status","level":3,"title":"<code>ctx status</code>","text":"<p>Quick health overview:</p> <pre><code>ctx status --verbose\n</code></pre> <p>Shows file counts, token estimates, modification times, and drift warnings in a single glance.</p>","path":["Detecting and Fixing Drift"],"tags":[]},{"location":"recipes/context-health/#ctx-alignment-audit-and-ctx-prompt-audit","level":3,"title":"<code>/ctx-alignment-audit</code> and <code>/ctx-prompt-audit</code>","text":"<p>These are both audits, but they answer different questions:</p> <ul> <li><code>/ctx-alignment-audit</code>: are our behavioral claims backed by actual   instructions?</li> <li><code>/ctx-prompt-audit</code>: are our context files readable, compact, and efficient?</li> </ul> <p>Run them inside your AI assistant:</p> <pre><code>/ctx-alignment-audit\n/ctx-prompt-audit\n</code></pre>","path":["Detecting and Fixing Drift"],"tags":[]},{"location":"recipes/context-health/#putting-it-all-together","level":2,"title":"Putting It All Together","text":"<p>Conversational approach (recommended):</p> <pre><code>Is our context clean?   -&gt; agent runs structural plus semantic checks\nFix what you can        -&gt; agent auto-fixes and proposes edits\nArchive the done tasks  -&gt; agent runs ctx compact --archive\nHow's token usage?      -&gt; agent checks ctx status\n</code></pre> <p>CLI approach (for CI, scripts, or direct control):</p> <pre><code>ctx drift                      # 1. Detect problems\nctx drift --fix                # 2. Auto-fix the easy ones\nctx sync --dry-run &amp;&amp; ctx sync # 3. Reconcile after refactors\nctx compact --archive          # 4. Archive old completed tasks\nctx status                     # 5. Verify\n</code></pre>","path":["Detecting and Fixing Drift"],"tags":[]},{"location":"recipes/context-health/#tips","level":2,"title":"Tips","text":"<p>Your agent is your first line of defense. It cross-references context files with source code during normal work. It will often notice a renamed package, a deleted directory, or an outdated convention before <code>ctx drift</code> runs. </p> <p>When an agent says \"this reference looks stale,\" it is usually right.</p> <p>Semantic drift is more damaging than structural drift. <code>ctx drift</code> catches dead paths. But <code>CONVENTIONS.md</code> describing a pattern your code stopped following three weeks ago is worse. When you ask \"is our context clean?\", the agent can  do both checks.</p> <p>Use <code>ctx status</code> as a quick check. It shows file counts, token estimates, and drift warnings in a single glance. Good for a fast \"is everything ok?\" before diving into work.</p> <p>Drift detection in CI: add <code>ctx drift --json</code> to your CI pipeline and fail on exit code 3 (violations). This catches constitution-level problems before they reach upstream.</p> <p>Do not over-compact. Completed tasks have historical value. The <code>--archive</code> flag preserves them in <code>.context/archive/</code> so you can search past work without cluttering active context.</p> <p>Sync is cautious by default. Use <code>--dry-run</code> after large refactors, then apply.</p>","path":["Detecting and Fixing Drift"],"tags":[]},{"location":"recipes/context-health/#next-up","level":2,"title":"Next Up","text":"<p>Browsing and Enriching Past Sessions: Export session history to a browsable journal and enrich entries with metadata.</p>","path":["Detecting and Fixing Drift"],"tags":[]},{"location":"recipes/context-health/#see-also","level":2,"title":"See Also","text":"<ul> <li>Tracking Work Across Sessions: task lifecycle and archival</li> <li>Persisting Decisions, Learnings, and Conventions:    keeping knowledge files current</li> <li>The Complete Session: where maintenance fits in the daily workflow</li> <li>CLI Reference: full flag documentation for all commands</li> <li>Context Files: structure and purpose of each <code>.context/</code> file</li> </ul>","path":["Detecting and Fixing Drift"],"tags":[]},{"location":"recipes/knowledge-capture/","level":1,"title":"Persisting Decisions, Learnings, and Conventions","text":"","path":["Persisting Decisions, Learnings, and Conventions"],"tags":[]},{"location":"recipes/knowledge-capture/#problem","level":2,"title":"Problem","text":"<p>You debug a subtle issue, discover the root cause, and move on.</p> <p>Three weeks later, a different session hits the same issue. The knowledge existed briefly in one session's memory but was never written down.</p> <p>Architectural decisions suffer the same fate: you weigh trade-offs, pick an approach, and six sessions later the AI suggests the alternative you already rejected.</p> <p>How do you make sure important context survives across sessions?</p>","path":["Persisting Decisions, Learnings, and Conventions"],"tags":[]},{"location":"recipes/knowledge-capture/#commands-and-skills-used","level":2,"title":"Commands and Skills Used","text":"Tool Type Purpose <code>ctx add decision</code> Command Record an architectural decision <code>ctx add learning</code> Command Record a gotcha, tip, or lesson <code>ctx add convention</code> Command Record a coding pattern or standard <code>ctx decisions reindex</code> Command Rebuild the quick-reference index <code>ctx learnings reindex</code> Command Rebuild the quick-reference index <code>/ctx-add-decision</code> Skill AI-guided decision capture with validation <code>/ctx-add-learning</code> Skill AI-guided learning capture with validation <code>/ctx-add-convention</code> Skill AI-guided convention recording with placement <code>/ctx-reflect</code> Skill Surface items worth persisting at breakpoints","path":["Persisting Decisions, Learnings, and Conventions"],"tags":[]},{"location":"recipes/knowledge-capture/#the-workflow","level":2,"title":"The Workflow","text":"","path":["Persisting Decisions, Learnings, and Conventions"],"tags":[]},{"location":"recipes/knowledge-capture/#step-1-understand-what-to-persist","level":3,"title":"Step 1: Understand What to Persist","text":"<p>Three context files serve different purposes:</p> <p>Decisions (<code>DECISIONS.md</code>) answer \"why is it this way?\" They record trade-offs between alternatives with structured fields: context, rationale, and consequences. Decisions prevent re-debating settled questions.</p> <p>Learnings (<code>LEARNINGS.md</code>) answer \"what did we discover the hard way?\" They record gotchas and debugging insights specific to this project with structured fields: context, lesson, and application. Learnings prevent repeating past mistakes.</p> <p>Conventions (<code>CONVENTIONS.md</code>) answer \"how do we do things here?\" They record patterns and standards. No structured fields required: just a name, a rule, and an example. Conventions keep code consistent across sessions.</p> <p>Decision, Learning, or Convention?</p> <ul> <li>If you chose between alternatives, it is a decision.</li> <li>If you discovered something surprising, it is a learning.</li> <li>If you are codifying a repeated pattern, it is a convention.</li> </ul>","path":["Persisting Decisions, Learnings, and Conventions"],"tags":[]},{"location":"recipes/knowledge-capture/#step-2-record-decisions","level":3,"title":"Step 2: Record Decisions","text":"<p>Decisions have three structured fields: context, rationale, and consequences.</p> <p>The easiest way to record one is to tell your agent:</p> <pre><code>You: \"Save that as a decision: we picked file-based cooldown\n      tokens over env vars.\"\n\nAgent: \"Recorded in DECISIONS.md:\n  - Decision: Use file-based cooldown tokens instead of env vars\n  - Context: Hook subprocesses cannot persist env vars to parent shell\n  - Rationale: File tokens survive across processes. Simpler than\n    IPC. Cleanup is automatic via TTL.\n  - Consequences: Tombstone files accumulate in /tmp. Cannot share\n    state across machines.\"\n</code></pre> <p>The agent was present for the trade-off discussion. It fills in the structured fields from what it observed, which is hard to reconstruct later as a terminal one-liner.</p> <p>When multiple options were considered, the agent includes rejected alternatives in the rationale automatically.</p> <p>The <code>/ctx-add-decision</code> skill also guides you through the fields interactively. For quick decisions, it supports a Y-statement:</p> <p>\"In the context of [situation], facing [constraint], we decided for [choice] and against [alternatives], to achieve [benefit], accepting that [trade-off].\"</p> CLI command for scripting and automation <p>When no agent is in the loop (CI pipelines, shell scripts, hooks), use the CLI directly with structured flags:</p> <pre><code>ctx add decision \"Use file-based cooldown tokens instead of env vars\" \\\n  --context \"Hook subprocesses cannot persist env vars to parent shell\" \\\n  --rationale \"File tokens survive across processes. Simpler than IPC. Cleanup is automatic via TTL.\" \\\n  --consequences \"Tombstone files accumulate in /tmp. Cannot share state across machines.\"\n</code></pre>","path":["Persisting Decisions, Learnings, and Conventions"],"tags":[]},{"location":"recipes/knowledge-capture/#step-3-record-learnings","level":3,"title":"Step 3: Record Learnings","text":"<p>Learnings have three structured fields: context, lesson, and application.</p> <p>Again, your agent is the best tool for this. It was there when you discovered the gotcha and can express it more completely than a backslash-escaped terminal command:</p> <pre><code>You: \"That subprocess thing was painful. Save it as a learning.\"\n\nAgent: \"Added to LEARNINGS.md:\n  - Learning: Claude Code hooks run in a subprocess\n  - Context: Set env var in PreToolUse hook, but it was not visible\n    in the main session\n  - Lesson: Hook scripts execute in a child process. Env changes do\n    not propagate to parent.\n  - Application: Use tombstone files for hook-to-session\n    communication. Never rely on hook env vars.\"\n</code></pre> <p>You said one sentence. The agent produced a structured entry with all three fields filled from the session context.</p> <p>That is the point: the agent has the full conversation and can be far more expressive than what you would type at a command prompt.</p> <p>The <code>/ctx-add-learning</code> skill applies three quality filters:</p> <ul> <li>(1) Could someone Google this in 5 minutes?</li> <li>(2) Is it specific to this codebase?</li> <li>(3) Did it take real effort to discover?</li> </ul> <p>All three must pass.</p> <p>Learnings capture principles and heuristics, not code snippets.</p> CLI command for scripting and automation <p>When no agent is in the loop:</p> <pre><code>ctx add learning \"Claude Code hooks run in a subprocess\" \\\n  --context \"Set env var in PreToolUse hook, but it was not visible in the main session\" \\\n  --lesson \"Hook scripts execute in a child process. Env changes do not propagate to parent.\" \\\n  --application \"Use tombstone files for hook-to-session communication. Never rely on hook env vars.\"\n</code></pre>","path":["Persisting Decisions, Learnings, and Conventions"],"tags":[]},{"location":"recipes/knowledge-capture/#step-4-record-conventions","level":3,"title":"Step 4: Record Conventions","text":"<p>Conventions are simpler: just a name, a rule, and optionally a section.</p> <p>These are short enough that either approach works:</p> <pre><code>You: \"We've been using kebab-case for every CLI flag. Codify that.\"\n\nAgent: \"Added to CONVENTIONS.md under Naming:\n  'Use kebab-case for all CLI flag names.'\"\n</code></pre> <p>Or from the terminal:</p> <pre><code>ctx add convention \"Use kebab-case for all CLI flag names\" --section \"Naming\"\n</code></pre> <p>Conventions work best for rules that come up repeatedly. Codify a pattern the third time you see it, not the first.</p>","path":["Persisting Decisions, Learnings, and Conventions"],"tags":[]},{"location":"recipes/knowledge-capture/#step-5-reindex-after-manual-edits","level":3,"title":"Step 5: Reindex After Manual Edits","text":"<p><code>DECISIONS.md</code> and <code>LEARNINGS.md</code> maintain a quick-reference index at the top: a compact table of date and title for each entry. The index updates automatically via <code>ctx add</code>, but falls out of sync after hand edits.</p> <pre><code>ctx decisions reindex\nctx learnings reindex\n</code></pre> <p>Run reindex after any manual edit. The index lets AI tools scan all entries without reading the full file, which matters when token budgets are tight.</p>","path":["Persisting Decisions, Learnings, and Conventions"],"tags":[]},{"location":"recipes/knowledge-capture/#step-6-use-ctx-reflect-to-surface-what-to-capture","level":3,"title":"Step 6: Use /ctx-reflect to Surface What to Capture","text":"<p>At natural breakpoints (after completing a feature, fixing a bug, or before ending a session) use <code>/ctx-reflect</code> to identify items worth persisting.</p> <pre><code>/ctx-reflect\n</code></pre> <p>The skill walks through learnings, decisions, tasks, and session notes, skipping categories with nothing to report. The output includes specific commands for each suggested persist:</p> <pre><code>This session implemented file-based cooldown for `ctx agent` and\ndiscovered that hook subprocesses cannot set env vars in the parent.\n\nI'd suggest persisting:\n- **Learning**: Hook subprocesses cannot propagate env vars\n  `ctx add learning \"...\" --context \"...\" --lesson \"...\" --application \"...\"`\n- **Decision**: File-based cooldown tokens over env vars\n  `ctx add decision \"...\" --context \"...\" --rationale \"...\" --consequences \"...\"`\n\nWant me to persist any of these?\n</code></pre> <p>The skill always asks before persisting.</p> <p>Keep It Conversational</p> <p><code>/ctx-reflect</code> is not the only way to trigger reflection.</p> <p>Agents trained on the ctx playbook naturally surface persist-worthy items at breakpoints, even without invoking the skill explicitly.</p> <p>A conversational prompt like \"anything worth saving?\" or \"let's wrap up\" can trigger the same review.</p> <p>The skill provides a structured checklist, but the behavior is available through natural conversation.</p>","path":["Persisting Decisions, Learnings, and Conventions"],"tags":[]},{"location":"recipes/knowledge-capture/#step-7-the-conversational-approach","level":3,"title":"Step 7: The Conversational Approach","text":"<p>The commands shown in Steps 2 to 4 are precise, but you rarely need to type them yourself. When working with an agent that has loaded the ctx playbook, natural language triggers the same operations.</p> <p>You ask, the agent acts:</p> You say What the agent does \"What have we learned this session?\" Reviews recent work, identifies learnings, offers to persist \"Save that as a decision\" Captures the trade-off you just discussed with structured fields \"Any gotchas worth remembering?\" Scans recent work for non-obvious lessons \"Record that convention\" Adds the pattern you just agreed on to CONVENTIONS.md \"Let's wrap up\" Runs through the reflect checklist conversationally <p>Example exchange:</p> <pre><code>You: \"What did we learn from that debugging session?\"\n\nAgent: \"We discovered three things worth persisting:\n  1. Hook subprocesses can't propagate env vars to the parent. We\n     spent 20 minutes on this before switching to tombstone files.\n  2. Tombstone files need a TTL or they accumulate in /tmp.\n  3. The cooldown logic must check file mtime, not just existence.\n  Want me to save these as learnings?\"\n\nYou: \"Yes, all of them.\"\n\nAgent: \"Done. Added all three to LEARNINGS.md with structured fields.\"\n</code></pre> <p>The agent can also be proactive without being asked. The playbook encourages agents to persist context at natural milestones.</p> <p>You may see:</p> <ul> <li>After fixing a tricky bug: \"I noticed this was a non-obvious issue.   Want me to save it as a learning?\"</li> <li>After choosing between approaches: \"We just made a trade-off between   file-based tokens and IPC. Should I record this as a decision?\"</li> <li>At session milestones: the agent checks what is worth persisting and offers a   brief summary.</li> </ul> <p>When agents run unattended (no human in the loop), they may persist directly:</p> <ul> <li>\"I've added the subprocess env var gotcha to LEARNINGS.md so we don't hit it again.\"</li> <li>\"Recorded the decision to use file-based tokens over env vars in DECISIONS.md.\"</li> <li>\"Marked the cooldown task done and added a follow-up for TTL cleanup.\"</li> </ul> <p>This is behavior by design.</p> <p>The playbook's self-check prompt, \"If this session ended right now, would the next session know what happened?\" drives agents to persist early and often rather than waiting for explicit instructions.</p>","path":["Persisting Decisions, Learnings, and Conventions"],"tags":[]},{"location":"recipes/knowledge-capture/#putting-it-all-together","level":2,"title":"Putting It All Together","text":"","path":["Persisting Decisions, Learnings, and Conventions"],"tags":[]},{"location":"recipes/knowledge-capture/#command-line-approach-scripting-and-automation","level":3,"title":"Command-line approach (scripting and automation)","text":"<pre><code># Decision: record the trade-off\nctx add decision \"Use PostgreSQL over SQLite\" \\\n  --context \"Need concurrent multi-user access\" \\\n  --rationale \"SQLite locks on writes; Postgres handles concurrency\" \\\n  --consequences \"Requires a database server; team needs Postgres training\"\n\n# Learning: record the gotcha\nctx add learning \"SQL migrations must be idempotent\" \\\n  --context \"Deploy failed when migration ran twice after rollback\" \\\n  --lesson \"CREATE TABLE without IF NOT EXISTS fails on retry\" \\\n  --application \"Always use IF NOT EXISTS guards in migrations\"\n\n# Convention: record the pattern\nctx add convention \"API handlers return structured errors\" --section \"API\"\n\n# Reindex after manual edits\nctx decisions reindex\nctx learnings reindex\n\n# Reflect at breakpoints (from AI assistant)\n# /ctx-reflect\n</code></pre>","path":["Persisting Decisions, Learnings, and Conventions"],"tags":[]},{"location":"recipes/knowledge-capture/#conversational-approach-interactive-sessions","level":3,"title":"Conversational approach (interactive sessions)","text":"<pre><code>You: \"We just picked Postgres over SQLite for the concurrency\n      reasons. Save that?\"\n\nAgent: \"Recorded. Added to DECISIONS.md:\n  - Decision: Use PostgreSQL over SQLite\n  - Context: Need concurrent multi-user access\n  - Rationale: SQLite locks on writes; Postgres handles concurrency\n  - Consequences: Requires a database server; team needs Postgres\n    training\"\n\nYou: \"Also that migration thing. The deploy blew up when the\n      migration ran twice.\"\n\nAgent: \"Got it. Added to LEARNINGS.md:\n  - Learning: SQL migrations must be idempotent\n  - Lesson: CREATE TABLE without IF NOT EXISTS fails on retry\n  - Application: Always use IF NOT EXISTS guards in migrations\"\n\nYou: \"Good. Anything else worth saving before we wrap up?\"\n\nAgent: \"We've been using structured error returns in every API\n  handler this session. Want me to codify that as a convention?\"\n\nYou: \"Do it.\"\n\nAgent: \"Done. Added 'API handlers return structured errors' to\n  CONVENTIONS.md under the API section.\"\n</code></pre> <p>Both approaches produce the same structured entries in the same context files.</p> <ul> <li>The conversational approach is the natural fit for interactive sessions; </li> <li>the CLI commands are better suited for scripts, hooks, and automation pipelines.</li> </ul>","path":["Persisting Decisions, Learnings, and Conventions"],"tags":[]},{"location":"recipes/knowledge-capture/#tips","level":2,"title":"Tips","text":"<ul> <li>Record decisions at the moment of choice. The alternatives you considered and   the reasons you rejected them fade quickly. Capture trade-offs while they are   fresh.</li> <li>Learnings should fail the Google test. If someone could find it in a 5-minute   search, it does not belong in LEARNINGS.md.</li> <li>Conventions earn their place through repetition. Add a convention the third   time you see a pattern, not the first.</li> <li>Use <code>/ctx-reflect</code> at natural breakpoints. The checklist catches items you   might otherwise lose.</li> <li>**Keep the entries self-contained^^. Each entry should make sense on its own. A   future session may load only one due to token budget constraints.</li> <li>Reindex after every hand edit. It takes less than a second. A stale index   causes AI tools to miss entries.</li> <li>Prefer the structured fields. The verbosity forces clarity. A decision without   a rationale is just a fact. A learning without an application is just a story.</li> <li>Talk to your agent, do not type commands. In interactive sessions, the   conversational approach is the recommended way to capture knowledge. Say   \"save that as a learning\" or \"any decisions worth recording?\" and let the   agent handle the structured fields. Reserve the CLI commands for scripting,   automation, and CI/CD pipelines where there is no agent in the loop.</li> <li>Trust the agent's proactive instincts. Agents trained on the ctx playbook will   offer to persist context at milestones. A brief \"want me to save this?\" is   cheaper than re-discovering the same lesson three sessions later.</li> </ul>","path":["Persisting Decisions, Learnings, and Conventions"],"tags":[]},{"location":"recipes/knowledge-capture/#next-up","level":2,"title":"Next Up","text":"<p>Detecting and Fixing Drift: Keep context files accurate as your codebase evolves.</p>","path":["Persisting Decisions, Learnings, and Conventions"],"tags":[]},{"location":"recipes/knowledge-capture/#see-also","level":2,"title":"See Also","text":"<ul> <li>Tracking Work Across Sessions: managing the tasks that   decisions and learnings support</li> <li>The Complete Session: full session lifecycle including   reflection and context persistence</li> <li>Detecting and Fixing Drift: keeping knowledge files   accurate as the codebase evolves</li> <li>CLI Reference: full documentation for <code>ctx add</code>,   <code>ctx decisions</code>, <code>ctx learnings</code></li> <li>Context Files: format and conventions for <code>DECISIONS.md</code>,   <code>LEARNINGS.md</code>, and <code>CONVENTIONS.md</code></li> </ul>","path":["Persisting Decisions, Learnings, and Conventions"],"tags":[]},{"location":"recipes/multi-tool-setup/","level":1,"title":"Setting Up ctx Across AI Tools","text":"","path":["Setting Up ctx Across AI Tools"],"tags":[]},{"location":"recipes/multi-tool-setup/#the-problem","level":2,"title":"The Problem","text":"<p>You have installed <code>ctx</code> and want to set it up with your AI coding assistant so that context persists across sessions. Different tools have different integration depths. For example: </p> <ul> <li>Claude Code supports native hooks that load and save context automatically</li> <li>Cursor injects context via its system prompt</li> <li>Aider reads context files through its <code>--read</code> flag</li> </ul> <p>This recipe walks through the complete setup for each tool, from initialization through verification, so you end up with a working memory layer regardless of which AI tool you use.</p>","path":["Setting Up ctx Across AI Tools"],"tags":[]},{"location":"recipes/multi-tool-setup/#commands-and-skills-used","level":2,"title":"Commands and Skills Used","text":"Command/Skill Role in this workflow <code>ctx init</code> Create <code>.context/</code> directory, templates, and tool hooks <code>ctx hook</code> Generate integration configuration for a specific AI tool <code>ctx agent</code> Print a token-budgeted context packet for AI consumption <code>ctx load</code> Output assembled context in read order (for manual pasting) <code>ctx watch</code> Auto-apply context updates from AI output (non-native tools) <code>ctx completion</code> Generate shell autocompletion for bash, zsh, or fish <code>ctx session parse</code> Convert JSONL transcripts to readable markdown","path":["Setting Up ctx Across AI Tools"],"tags":[]},{"location":"recipes/multi-tool-setup/#the-workflow","level":2,"title":"The Workflow","text":"","path":["Setting Up ctx Across AI Tools"],"tags":[]},{"location":"recipes/multi-tool-setup/#step-1-initialize-ctx","level":3,"title":"Step 1: Initialize ctx","text":"<p>Run <code>ctx init</code> in your project root. This creates the <code>.context/</code> directory with all template files and, if Claude Code is detected, generates hooks and Agent Skills automatically.</p> <pre><code>cd your-project\nctx init\n</code></pre> <p>This produces the following structure:</p> <pre><code>.context/\n  CONSTITUTION.md     # Hard rules the AI must never violate\n  TASKS.md            # Current and planned work\n  CONVENTIONS.md      # Code patterns and standards\n  ARCHITECTURE.md     # System overview\n  DECISIONS.md        # Architectural decisions with rationale\n  LEARNINGS.md        # Lessons learned, gotchas, tips\n  GLOSSARY.md         # Domain terms and abbreviations\n  AGENT_PLAYBOOK.md   # How AI tools should use this system\n  sessions/           # Session snapshots\n\n.claude/              # Claude Code integration (auto-generated)\n  hooks/              # Auto-save and enforcement scripts\n  skills/             # ctx Agent Skills (agentskills.io spec)\n  settings.local.json # Hook configuration\n</code></pre> <p>If you only need the core files (useful for lightweight setups with Cursor or Copilot), use the <code>--minimal</code> flag:</p> <pre><code>ctx init --minimal\n</code></pre> <p>This creates only <code>TASKS.md</code>, <code>DECISIONS.md</code>, and <code>CONSTITUTION.md</code>.</p>","path":["Setting Up ctx Across AI Tools"],"tags":[]},{"location":"recipes/multi-tool-setup/#step-2-generate-tool-specific-hooks","level":3,"title":"Step 2: Generate Tool-Specific Hooks","text":"<p>If you are using a tool other than Claude Code (which is configured automatically by <code>ctx init</code>), generate its integration configuration:</p> <pre><code># For Cursor\nctx hook cursor\n\n# For Aider\nctx hook aider\n\n# For GitHub Copilot\nctx hook copilot\n\n# For Windsurf\nctx hook windsurf\n</code></pre> <p>Each command prints the configuration you need. How you apply it depends on the tool.</p> <p>Claude is a First-Class Citizen</p> <p>You don't need any extra steps to integrate with Claude Code.</p> <p><code>ctx init</code> already wrote <code>.claude/settings.local.json</code> with <code>PreToolUse</code> and <code>SessionEnd</code> hooks.</p> <p>The <code>PreToolUse</code> hook runs <code>ctx agent --budget 4000 --session $PPID</code> on every tool call (with a 10-minute cooldown so it only fires once per window).</p> <p>The <code>SessionEnd</code> hook saves a snapshot to <code>.context/sessions/</code>.</p> <p>Cursor: Add the system prompt snippet to <code>.cursor/settings.json</code>:</p> <pre><code>{\n  \"ai.systemPrompt\": \"Read .context/TASKS.md and .context/CONVENTIONS.md before responding. Follow rules in .context/CONSTITUTION.md.\"\n}\n</code></pre> <p>Context files appear in Cursor's file tree. You can also paste a context packet directly into chat:</p> <pre><code>ctx agent --budget 4000 | xclip    # Linux\nctx agent --budget 4000 | pbcopy   # macOS\n</code></pre> <p>Aider: Create <code>.aider.conf.yml</code> so context files are loaded on every session:</p> <pre><code>read:\n  - .context/CONSTITUTION.md\n  - .context/TASKS.md\n  - .context/CONVENTIONS.md\n  - .context/DECISIONS.md\n</code></pre> <p>Then start Aider normally:</p> <pre><code>aider\n</code></pre> <p>Or specify files on the command line:</p> <pre><code>aider --read .context/TASKS.md --read .context/CONVENTIONS.md\n</code></pre>","path":["Setting Up ctx Across AI Tools"],"tags":[]},{"location":"recipes/multi-tool-setup/#step-3-set-up-shell-completion","level":3,"title":"Step 3: Set Up Shell Completion","text":"<p>Shell completion lets you tab-complete ctx subcommands and flags, which is especially useful while learning the CLI.</p> <pre><code># Bash (add to ~/.bashrc)\nsource &lt;(ctx completion bash)\n\n# Zsh (add to ~/.zshrc)\nsource &lt;(ctx completion zsh)\n\n# Fish\nctx completion fish &gt; ~/.config/fish/completions/ctx.fish\n</code></pre> <p>After sourcing, typing <code>ctx a&lt;TAB&gt;</code> completes to <code>ctx agent</code>, and <code>ctx session &lt;TAB&gt;</code> shows <code>save</code>, <code>list</code>, <code>load</code>, and <code>parse</code>.</p>","path":["Setting Up ctx Across AI Tools"],"tags":[]},{"location":"recipes/multi-tool-setup/#step-4-verify-the-setup-works","level":3,"title":"Step 4: Verify the Setup Works","text":"<p>Start a fresh session in your AI tool and ask:</p> <p>\"Do you remember?\"</p> <p>A correctly configured tool responds with specific context: current tasks from <code>TASKS.md</code>, recent decisions, and previous session topics. It should not say \"I don't have memory\" or \"Let me search for files.\"</p> <p>This question checks the passive side of memory. A properly set-up agent is also proactive: it treats context maintenance as part of its job.</p> <ul> <li>After a debugging session, it offers to save a learning</li> <li>After a trade-off discussion, it asks whether to record the decision</li> <li>After completing a task, it suggests follow-up items</li> </ul> <p>The \"do you remember?\" check verifies both halves: recall and responsibility.</p> <p>For example, after resolving a tricky bug, a proactive agent might say:</p> <p>That Redis timeout issue was subtle. Want me to save this as a learning so we don't hit it again?</p> <p>If you see behavior like this, the setup is working end to end.</p> <p>In Claude Code, you can also invoke the <code>/ctx-status</code> skill:</p> <pre><code>/ctx-status\n</code></pre> <p>This prints a summary of all context files, token counts, and recent activity, confirming that hooks are loading context.</p> <p>If context is not loading, check the basics:</p> Symptom Fix <code>ctx: command not found</code> Ensure ctx is in your PATH: <code>which ctx</code> No sessions saved (Claude Code) Verify <code>.claude/settings.local.json</code> has <code>SessionEnd</code> hook Hook permission errors Run <code>chmod +x .claude/hooks/*.sh</code> Missing sessions directory Run <code>mkdir -p .context/sessions</code> Context not refreshing Cooldown may be active; wait 10 minutes or set <code>--cooldown 0</code>","path":["Setting Up ctx Across AI Tools"],"tags":[]},{"location":"recipes/multi-tool-setup/#step-5-enable-watch-mode-for-non-native-tools","level":3,"title":"Step 5: Enable Watch Mode for Non-Native Tools","text":"<p>Tools like Aider, Copilot, and Windsurf do not support native hooks for saving context automatically. For these, run <code>ctx watch</code> alongside your AI tool.</p> <p>Pipe the AI tool's output through <code>ctx watch</code>:</p> <pre><code># Terminal 1: Run Aider with output logged\naider 2&gt;&amp;1 | tee /tmp/aider.log\n\n# Terminal 2: Watch the log for context updates\nctx watch --log /tmp/aider.log\n</code></pre> <p>Or for any generic tool:</p> <pre><code>your-ai-tool 2&gt;&amp;1 | tee /tmp/ai.log &amp;\nctx watch --log /tmp/ai.log\n</code></pre> <p>When the AI emits structured update commands, <code>ctx watch</code> parses and applies them automatically:</p> <pre><code>&lt;context-update type=\"learning\"\n  context=\"Debugging rate limiter\"\n  lesson=\"Redis MULTI/EXEC does not roll back on error\"\n  application=\"Wrap rate-limit checks in Lua scripts instead\"\n&gt;Redis Transaction Behavior&lt;/context-update&gt;\n</code></pre> <p>To preview changes without modifying files:</p> <pre><code>ctx watch --dry-run --log /tmp/ai.log\n</code></pre>","path":["Setting Up ctx Across AI Tools"],"tags":[]},{"location":"recipes/multi-tool-setup/#step-6-parse-session-transcripts-optional","level":3,"title":"Step 6: Parse Session Transcripts (Optional)","text":"<p>If you have JSONL transcripts from Claude Code sessions, convert them to readable Markdown:</p> <pre><code>ctx session parse ~/.claude/projects/.../session.jsonl -o conversation.md\n</code></pre> <p>To also extract decisions and learnings:</p> <pre><code>ctx session parse transcript.jsonl --extract\n</code></pre> <p>This scans the conversation and appends relevant entries to <code>DECISIONS.md</code> and <code>LEARNINGS.md</code>.</p>","path":["Setting Up ctx Across AI Tools"],"tags":[]},{"location":"recipes/multi-tool-setup/#putting-it-together","level":2,"title":"Putting It Together","text":"<p>Here is the condensed setup for all three tools:</p> <pre><code># -- Common (run once per project) --\ncd your-project\nctx init\nsource &lt;(ctx completion zsh)       # or bash/fish\n\n# -- Claude Code (automatic, just verify) --\n# Start Claude Code, then ask: \"Do you remember?\"\n\n# -- Cursor --\nctx hook cursor\n# Add the system prompt to .cursor/settings.json\n# Paste context: ctx agent --budget 4000 | pbcopy\n\n# -- Aider --\nctx hook aider\n# Create .aider.conf.yml with read: paths\n# Run watch mode alongside: ctx watch --log /tmp/aider.log\n\n# -- Verify any tool --\n# Ask your AI: \"Do you remember?\"\n# Expect: specific tasks, decisions, session history\n</code></pre>","path":["Setting Up ctx Across AI Tools"],"tags":[]},{"location":"recipes/multi-tool-setup/#tips","level":2,"title":"Tips","text":"<ul> <li>Start with <code>ctx init</code> (not <code>--minimal</code>) for your first project. The full   template set gives the agent more to work with, and you can always delete   files later.</li> <li>For Claude Code, adjust the token budget in <code>.claude/settings.local.json</code>   as your project grows.</li> <li>The <code>--session $PPID</code> flag isolates cooldowns per Claude Code process, so   parallel sessions do not suppress each other.</li> <li>Commit your <code>.context/</code> directory to version control. Several ctx features   (journals, changelogs, blog generation) rely on git history.</li> <li>For Cursor and Copilot, keep <code>CONVENTIONS.md</code> visible. These tools treat   open files as higher-priority context.</li> <li>Run <code>ctx drift</code> periodically to catch stale references before they confuse   the agent.</li> <li>The agent playbook instructs the agent to persist context at natural   milestones (completed tasks, decisions, gotchas). In practice, this   works best when you reinforce the habit: a quick \"anything worth saving?\"   after a debugging session goes a long way.</li> </ul>","path":["Setting Up ctx Across AI Tools"],"tags":[]},{"location":"recipes/multi-tool-setup/#next-up","level":2,"title":"Next Up","text":"<p>The Complete Session: Walk through a full <code>ctx</code> session from start to finish.</p>","path":["Setting Up ctx Across AI Tools"],"tags":[]},{"location":"recipes/multi-tool-setup/#see-also","level":2,"title":"See Also","text":"<ul> <li>The Complete Session: full session lifecycle recipe</li> <li>CLI Reference: all commands and flags</li> <li>Integrations: detailed per-tool integration docs</li> </ul>","path":["Setting Up ctx Across AI Tools"],"tags":[]},{"location":"recipes/publishing/","level":1,"title":"Turning Activity into Content","text":"","path":["Turning Activity into Content"],"tags":[]},{"location":"recipes/publishing/#the-problem","level":2,"title":"The Problem","text":"<p>Your <code>.context/</code> directory is full of decisions, learnings, and session history. Your git log tells the story of a project evolving. But none of this is visible to anyone outside your terminal. You want to turn this raw activity into a browsable journal site, blog posts, and changelog posts.</p>","path":["Turning Activity into Content"],"tags":[]},{"location":"recipes/publishing/#commands-and-skills-used","level":2,"title":"Commands and Skills Used","text":"Tool Type Purpose <code>ctx recall export</code> Command Export session JSONL to editable markdown <code>ctx journal site</code> Command Generate a static site from journal entries <code>ctx serve</code> Command Serve the journal site locally <code>make journal</code> Makefile Shortcut for export + site rebuild <code>/ctx-journal-normalize</code> Skill Fix markdown rendering in exported entries <code>/ctx-journal-enrich</code> Skill Add metadata, summaries, and tags to entries <code>/ctx-blog</code> Skill Draft a blog post from recent project activity <code>/ctx-blog-changelog</code> Skill Write a themed post from a commit range","path":["Turning Activity into Content"],"tags":[]},{"location":"recipes/publishing/#the-workflow","level":2,"title":"The Workflow","text":"","path":["Turning Activity into Content"],"tags":[]},{"location":"recipes/publishing/#step-1-export-sessions-to-markdown","level":3,"title":"Step 1: Export Sessions to Markdown","text":"<p>Raw session data lives as JSONL files in Claude Code's internal storage. The first step is converting these into readable, editable markdown.</p> <pre><code># Export all sessions from the current project\nctx recall export --all\n\n# Export from all projects (if you work across multiple repos)\nctx recall export --all --all-projects\n\n# Export a single session by ID or slug\nctx recall export abc123\nctx recall export gleaming-wobbling-sutherland\n</code></pre> <p>Exported files land in <code>.context/journal/</code> as individual markdown files with session metadata and the full conversation transcript. Re-exporting preserves any YAML frontmatter added by enrichment. Use <code>--skip-existing</code> to leave existing files untouched, or <code>--force</code> to overwrite everything.</p>","path":["Turning Activity into Content"],"tags":[]},{"location":"recipes/publishing/#step-2-normalize-exported-entries","level":3,"title":"Step 2: Normalize Exported Entries","text":"<p>Raw exports can have rendering issues: nested code fences that break syntax highlighting, metadata blocks that render as raw bold text, and malformed lists. The <code>/ctx-journal-normalize</code> skill fixes these in the source files before site generation.</p> <pre><code>/ctx-journal-normalize\n</code></pre> <p>The skill:</p> <ol> <li>Backs up <code>.context/journal/</code> before modifying anything</li> <li>Converts <code>**Key**: value</code> metadata blocks into collapsible HTML tables</li> <li>Fixes fence nesting so code blocks render with proper highlighting</li> <li>Marks processed files with <code>&lt;!-- normalized --&gt;</code> so re-runs skip them</li> </ol> <p>Run normalize before enrich. Clean markdown produces better metadata extraction in the next step.</p>","path":["Turning Activity into Content"],"tags":[]},{"location":"recipes/publishing/#step-3-enrich-entries-with-metadata","level":3,"title":"Step 3: Enrich Entries with Metadata","text":"<p>Raw entries have timestamps and conversations but lack the structured metadata that makes a journal searchable. The <code>/ctx-journal-enrich</code> skill analyzes each conversation and adds semantic frontmatter.</p> <pre><code>/ctx-journal-enrich twinkly-stirring-kettle\n/ctx-journal-enrich 2026-01-24\n/ctx-journal-enrich 76fe2ab9\n</code></pre> <p>The skill reads the conversation, proposes metadata, and asks for confirmation before writing. After enrichment, an entry gains YAML frontmatter:</p> <pre><code>---\ntitle: \"Implement Redis caching for API endpoints\"\ndate: 2026-01-24\ntype: feature\noutcome: completed\ntopics:\n  - caching\n  - api-performance\ntechnologies:\n  - go\n  - redis\nkey_files:\n  - internal/api/middleware/cache.go\n  - internal/cache/redis.go\n---\n</code></pre> <p>This metadata powers better navigation in the journal site: titles replace slugs, summaries appear in the index, and search covers topics and technologies.</p>","path":["Turning Activity into Content"],"tags":[]},{"location":"recipes/publishing/#step-4-generate-the-journal-site","level":3,"title":"Step 4: Generate the Journal Site","text":"<p>With entries exported, normalized, and enriched, generate the static site:</p> <pre><code># Generate site files\nctx journal site\n\n# Generate and build static HTML\nctx journal site --build\n\n# Generate and serve locally (opens at http://localhost:8000)\nctx journal site --serve\n\n# Custom output directory\nctx journal site --output ~/my-journal\n</code></pre> <p>The site is generated in <code>.context/journal-site/</code> by default. It uses zensical for static site generation (<code>pip install zensical</code>).</p> <p>Or use the Makefile shortcut that combines export and rebuild:</p> <pre><code>make journal\n</code></pre> <p>This runs <code>ctx recall export --all</code> followed by <code>ctx journal site --build</code>, then reminds you to normalize and enrich before rebuilding. To serve the built site: <code>make journal-serve</code> or <code>ctx serve</code>.</p>","path":["Turning Activity into Content"],"tags":[]},{"location":"recipes/publishing/#step-5-draft-blog-posts-from-activity","level":3,"title":"Step 5: Draft Blog Posts from Activity","text":"<p>When your project reaches a milestone worth sharing, use <code>/ctx-blog</code> to draft a post from your recent activity. The skill gathers context from multiple sources: git log, DECISIONS.md, LEARNINGS.md, completed tasks, and journal entries.</p> <pre><code>/ctx-blog about the caching layer we just built\n/ctx-blog last week's refactoring work\n/ctx-blog lessons learned from the migration\n</code></pre> <p>The skill gathers recent commits, decisions, and learnings; identifies a narrative arc; drafts an outline for approval; writes the full post; and saves it to <code>docs/blog/YYYY-MM-DD-slug.md</code>. Posts are written in first person with actual code snippets, commit references, and honest discussion of what went wrong.</p>","path":["Turning Activity into Content"],"tags":[]},{"location":"recipes/publishing/#step-6-write-changelog-posts-from-commit-ranges","level":3,"title":"Step 6: Write Changelog Posts from Commit Ranges","text":"<p>For release notes or \"what changed\" posts, <code>/ctx-blog-changelog</code> takes a starting commit and a theme, then analyzes everything that changed:</p> <pre><code>/ctx-blog-changelog 040ce99 \"building the journal system\"\n/ctx-blog-changelog HEAD~30 \"what's new in v0.2.0\"\n/ctx-blog-changelog v0.1.0 \"the road to v0.2.0\"\n</code></pre> <p>The skill diffs the commit range, identifies the most-changed files, and constructs a narrative organized by theme rather than chronology, including a key commits table and before/after comparisons.</p>","path":["Turning Activity into Content"],"tags":[]},{"location":"recipes/publishing/#the-conversational-approach","level":2,"title":"The Conversational Approach","text":"<p>You do not need to remember any of the commands above. When the Agent Playbook is active, your AI agent tracks what you are working on and proactively suggests content at natural moments:</p> <p>\"We just shipped the caching layer and closed 3 tasks. Want me to draft a blog post about it?\"</p> <p>\"Your journal has 6 new entries since last rebuild. Want me to normalize, enrich, and regenerate the site?\"</p> <p>You can also drive it with natural language instead of skills:</p> <pre><code>\"write about what we did this week\"\n\"turn today's session into a blog post\"\n\"make a changelog post covering everything since the last release\"\n\"enrich the last few journal entries\"\n</code></pre> <p>The agent has full visibility into your <code>.context/</code> state — tasks completed, decisions recorded, learnings captured — so its suggestions are grounded in what actually happened, not guesswork.</p>","path":["Turning Activity into Content"],"tags":[]},{"location":"recipes/publishing/#putting-it-together","level":2,"title":"Putting It Together","text":"<p>The full pipeline from raw transcripts to published content:</p> <pre><code># 1. Export all sessions\nctx recall export --all\n\n# 2. In Claude Code: normalize rendering\n/ctx-journal-normalize\n\n# 3. In Claude Code: enrich entries with metadata\n/ctx-journal-enrich twinkly-stirring-kettle\n/ctx-journal-enrich gleaming-wobbling-sutherland\n\n# 4. Build and serve the journal site\nmake journal\nmake journal-serve\n\n# 5. In Claude Code: draft a blog post\n/ctx-blog about the features we shipped this week\n\n# 6. In Claude Code: write a changelog post\n/ctx-blog-changelog v0.1.0 \"what's new in v0.2.0\"\n</code></pre> <p>The journal pipeline is idempotent at every stage. You can re-run <code>ctx recall export --all</code> without losing enrichment. You can re-run <code>/ctx-journal-normalize</code> and it skips already-normalized files. You can rebuild the site as many times as you want.</p>","path":["Turning Activity into Content"],"tags":[]},{"location":"recipes/publishing/#tips","level":2,"title":"Tips","text":"<ul> <li> <p>Export regularly. Run <code>ctx recall export --all --skip-existing</code>   after each session to keep your journal current without re-processing   old entries.</p> </li> <li> <p>Normalize before enriching. The enrichment skill reads the   conversation content to extract metadata. Clean markdown with proper   formatting produces significantly better results than raw exports   with broken fences.</p> </li> <li> <p>Enrich selectively. Not every session needs enrichment.   Short suggestion sessions and trivial debugging sessions can be   left as-is. Focus enrichment on sessions where meaningful work   happened.</p> </li> <li> <p>Keep journal files gitignored. Session journals contain sensitive   data: file contents, commands, API keys, internal discussions, and   error messages with stack traces. The <code>.context/journal/</code> and   <code>.context/journal-site/</code> directories must be in <code>.gitignore</code>.</p> </li> <li> <p>Use <code>/ctx-blog</code> for narrative posts, <code>/ctx-blog-changelog</code> for   release posts. The blog skill looks at recent activity and finds a   story. The changelog skill takes a commit range and a theme. They   complement each other: one for \"what I learned\" posts, the other   for \"what changed\" posts.</p> </li> <li> <p>Let the agent remind you. You do not need to remember to run   <code>/ctx-blog</code> or <code>/ctx-journal-enrich</code>. A proactive agent will suggest   content generation after productive milestones — shipping a feature,   closing a batch of tasks, or finishing a long debugging session. The   best content gets written while the context is fresh.</p> </li> <li> <p>Edit the drafts. Both blog skills produce drafts, not final   posts. Review the narrative, add your personal perspective, and   remove anything that does not serve the reader.</p> </li> </ul>","path":["Turning Activity into Content"],"tags":[]},{"location":"recipes/publishing/#next-up","level":2,"title":"Next Up","text":"<p>Back to the beginning: Setting Up ctx Across AI Tools -- or explore the full recipe list.</p>","path":["Turning Activity into Content"],"tags":[]},{"location":"recipes/publishing/#see-also","level":2,"title":"See Also","text":"<ul> <li>Session Journal: Full documentation of the   journal system, enrichment schema, and context monitor</li> <li>CLI Reference: ctx recall:   Export, list, and show session history</li> <li>CLI Reference: ctx journal:   Site generation commands</li> <li>CLI Reference: ctx serve: Local   site serving</li> <li>Browsing and Enriching Past Sessions:   Recipe focused on the journal browsing workflow</li> <li>The Complete Session: How to capture   context during a session so there is material to publish later</li> </ul>","path":["Turning Activity into Content"],"tags":[]},{"location":"recipes/session-archaeology/","level":1,"title":"Browsing and Enriching Past Sessions","text":"","path":["Browsing and Enriching Past Sessions"],"tags":[]},{"location":"recipes/session-archaeology/#the-problem","level":2,"title":"The Problem","text":"<p>After weeks of AI-assisted development you have dozens of sessions scattered across JSONL files in <code>~/.claude/projects/</code>. Finding the session where you debugged the Redis connection pool, or remembering what you decided about the caching strategy three Tuesdays ago, often means grepping raw JSON.</p> <p>There is no table of contents, no search, and no summaries.</p> <p>This recipe shows how to turn that raw session history into a browsable, searchable, and enriched **journal site you can navigate  in your browser.</p>","path":["Browsing and Enriching Past Sessions"],"tags":[]},{"location":"recipes/session-archaeology/#commands-and-skills-used","level":2,"title":"Commands and Skills Used","text":"Tool Type Purpose <code>ctx recall list</code> Command List parsed sessions with metadata <code>ctx recall show</code> Command Inspect a specific session in detail <code>ctx recall export</code> Command Export sessions to editable journal Markdown <code>ctx journal site</code> Command Generate a static site from journal entries <code>ctx serve</code> Command Serve the journal site locally <code>/ctx-recall</code> Skill Browse sessions inside your AI assistant <code>/ctx-journal-normalize</code> Skill Fix rendering issues in exported Markdown <code>/ctx-journal-enrich</code> Skill Add frontmatter metadata to a single entry <code>/ctx-journal-enrich-all</code> Skill Batch-enrich all unenriched entries","path":["Browsing and Enriching Past Sessions"],"tags":[]},{"location":"recipes/session-archaeology/#the-workflow","level":2,"title":"The Workflow","text":"<p>The session journal follows a four-stage pipeline.</p> <p>Each stage is idempotent and safe to re-run. Each stage skips entries that have already been processed.</p> <pre><code>export -&gt; normalize -&gt; enrich -&gt; rebuild\n</code></pre> Stage Tool What it does Skips if Where Export <code>ctx recall export --all</code> Converts session JSONL to Markdown <code>--skip-existing</code> flag CLI or agent Normalize <code>/ctx-journal-normalize</code> Fixes nested fences and metadata formatting <code>&lt;!-- normalized --&gt;</code> marker Agent only Enrich <code>/ctx-journal-enrich-all</code> Adds frontmatter, summaries, topic tags Frontmatter already present Agent only Rebuild <code>ctx journal site --build</code> Generates browsable static HTML N/A CLI only <p>Where to run Each Stage</p> <p>Export (Steps 1 to 3) works equally well from the terminal or inside your AI assistant via <code>/ctx-recall</code>. The CLI is fine here: the agent adds no special intelligence, it just runs the same command.</p> <p>Normalize and enrich (Steps 4 to 5) require the agent: they need it to read, analyze, and edit Markdown.</p> <p>Rebuild and serve (Step 6) is a terminal operation that starts a long-running server.</p>","path":["Browsing and Enriching Past Sessions"],"tags":[]},{"location":"recipes/session-archaeology/#step-1-list-your-sessions","level":3,"title":"Step 1: List Your Sessions","text":"<p>Start by seeing what sessions exist for the current project:</p> <pre><code>ctx recall list\n</code></pre> <p>Sample output:</p> <pre><code>Sessions (newest first)\n=======================\n\n  Slug                           Project   Date         Duration  Turns  Tokens\n  gleaming-wobbling-sutherland   ctx       2026-02-07   1h 23m    47     82,341\n  twinkly-stirring-kettle        ctx       2026-02-06   0h 45m    22     38,102\n  bright-dancing-hopper          ctx       2026-02-05   2h 10m    63     124,500\n  quiet-flowing-dijkstra         ctx       2026-02-04   0h 18m    11     15,230\n  ...\n</code></pre> <p>Slugs Look Cryptic?</p> <p>These auto-generated slugs (<code>gleaming-wobbling-sutherland</code>) are hard to recognize later.</p> <p>If you save sessions with <code>/ctx-save</code> before ending, you also get human-readable filenames like <code>2026-02-07-redis-caching.md</code> in <code>.context/sessions/</code>, which are easier to find and reference.</p> <p>Filter by project or tool if you work across multiple codebases:</p> <pre><code>ctx recall list --project ctx --limit 10\nctx recall list --tool claude-code\nctx recall list --all-projects\n</code></pre>","path":["Browsing and Enriching Past Sessions"],"tags":[]},{"location":"recipes/session-archaeology/#step-2-inspect-a-specific-session","level":3,"title":"Step 2: Inspect a Specific Session","text":"<p>Before exporting everything, inspect a single session to see its metadata and conversation summary:</p> <pre><code>ctx recall show --latest\n</code></pre> <p>Or look up a specific session by its slug, partial ID, or UUID:</p> <pre><code>ctx recall show gleaming-wobbling-sutherland\nctx recall show twinkly\nctx recall show abc123\n</code></pre> <p>Add <code>--full</code> to see the complete message content instead of the summary view:</p> <pre><code>ctx recall show --latest --full\n</code></pre> <p>This is useful for checking what happened before deciding whether to export and enrich it.</p>","path":["Browsing and Enriching Past Sessions"],"tags":[]},{"location":"recipes/session-archaeology/#step-3-export-sessions-to-the-journal","level":3,"title":"Step 3: Export Sessions to the Journal","text":"<p>Export converts raw session data into editable Markdown files in <code>.context/journal/</code>:</p> <pre><code># Export all sessions from the current project\nctx recall export --all\n\n# Export a single session\nctx recall export gleaming-wobbling-sutherland\n\n# Include sessions from all projects\nctx recall export --all --all-projects\n</code></pre> <p>Each exported file contains session metadata (date, time, duration, model, project, git branch), a tool usage summary, and the full conversation transcript.</p> <p>Re-exporting is safe. By default, re-running <code>ctx recall export --all</code> regenerates conversation content while preserving any YAML frontmatter you or the enrichment skill have added.</p> <p>You can also use <code>--skip-existing</code> to leave exported files completely untouched.</p> <p>--force Overwrites Journal Files</p> <p>If you want to overwrite existing files, use <code>--force</code>.</p> <p>This triggers a full overwrite and frontmatter will be lost.</p> <p>Back up your journal before using this flag.</p>","path":["Browsing and Enriching Past Sessions"],"tags":[]},{"location":"recipes/session-archaeology/#step-4-normalize-rendering","level":3,"title":"Step 4: Normalize Rendering","text":"<p>Raw exported sessions often have rendering problems: nested code fences that break Markdown parsers, malformed metadata tables, or broken list formatting.</p> <p>The <code>/ctx-journal-normalize</code> skill fixes these issues in the source files before site generation.</p> <p>Inside your AI assistant:</p> <pre><code>/ctx-journal-normalize\n</code></pre> <p>The skill backs up <code>.context/journal/</code> before modifying anything and marks each processed file with a <code>&lt;!-- normalized: YYYY-MM-DD --&gt;</code> comment so subsequent runs skip already-normalized entries.</p> <p>Run normalize before enrich. The enrichment skill reads conversation content to extract metadata, and clean Markdown produces better results.</p>","path":["Browsing and Enriching Past Sessions"],"tags":[]},{"location":"recipes/session-archaeology/#step-5-enrich-with-metadata","level":3,"title":"Step 5: Enrich with Metadata","text":"<p>Raw exports have timestamps and transcripts but lack the semantic metadata that makes sessions searchable: topics, technology tags, outcome status, and summaries. The <code>/ctx-journal-enrich*</code> skills add this structured frontmatter.</p> <p>Batch enrichment (recommended):</p> <pre><code>/ctx-journal-enrich-all\n</code></pre> <p>The skill finds all unenriched entries, filters out noise (suggestion sessions, very short sessions, multipart continuations), and processes each one by extracting titles, topics, technologies, and  summaries from the conversation.</p> <p>It shows you a grouped summary before applying changes so you can scan quickly rather than reviewing one by one.</p> <p>For large backlogs (20+ entries), the skill can spawn subagents to process entries in parallel.</p> <p>Single-entry enrichment:</p> <pre><code>/ctx-journal-enrich twinkly\n/ctx-journal-enrich 2026-02-06\n</code></pre> <p>Each enriched entry gets YAML frontmatter like this:</p> <pre><code>---\ntitle: \"Implement Redis caching middleware\"\ndate: 2026-02-06\ntype: feature\noutcome: completed\ntopics:\n  - caching\n  - api-performance\ntechnologies:\n  - go\n  - redis\nlibraries:\n  - go-redis/redis\nkey_files:\n  - internal/cache/redis.go\n  - internal/api/middleware/cache.go\n---\n</code></pre> <p>The skill also generates a summary and can extract decisions,  learnings, and tasks mentioned during the session.</p>","path":["Browsing and Enriching Past Sessions"],"tags":[]},{"location":"recipes/session-archaeology/#step-6-generate-and-serve-the-site","level":3,"title":"Step 6: Generate and Serve the Site","text":"<p>With exported, normalized, and enriched journal files, generate the static site:</p> <pre><code># Generate site structure only\nctx journal site\n\n# Generate and build static HTML\nctx journal site --build\n\n# Generate, build, and serve locally\nctx journal site --serve\n</code></pre> <p>Then open <code>http://localhost:8000</code> to browse.</p> <p>The site includes a date-sorted index, individual session pages with full conversations, search (press <code>/</code>), dark mode, and enriched titles in the navigation when frontmatter exists.</p> <p>You can also serve an existing site without regenerating using <code>ctx serve</code>.</p> <p>The site generator requires <code>zensical</code> (<code>pip install zensical</code>).</p>","path":["Browsing and Enriching Past Sessions"],"tags":[]},{"location":"recipes/session-archaeology/#where-the-agent-adds-value","level":2,"title":"Where the Agent Adds Value","text":"<p>Export, list, and show are mechanical. The agent runs the same CLI commands you would, so you can stay in your terminal for those.</p> <p>The agent earns its keep in normalize and enrich. </p> <p>These require reading conversation content, understanding what happened,  and producing structured metadata. That is agent work, not CLI work.</p> <p>You can also ask your agent to browse sessions conversationally instead of remembering flags:</p> <pre><code>What did we work on last week?\nShow me the session about Redis.\nExport everything to the journal.\n</code></pre> <p>This is convenient but not required: <code>ctx recall list</code> gives you the same inventory.</p> <p>Where the agent genuinely helps is chaining the pipeline:</p> <pre><code>You:   What happened last Tuesday?\nAgent: Last Tuesday you worked on two sessions:\n       - bright-dancing-hopper (2h 10m): refactored the middleware\n         pipeline and added Redis caching\n       - quiet-flowing-dijkstra (18m): quick fix for a nil pointer\n         in the config loader\n       Want me to export and enrich them?\nYou:   Yes, do it.\nAgent: Exports both, normalizes, enriches, then proposes frontmatter.\n</code></pre> <p>The value is staying in one context while the agent runs export -&gt; normalize -&gt; enrich without you manually switching tools.</p>","path":["Browsing and Enriching Past Sessions"],"tags":[]},{"location":"recipes/session-archaeology/#putting-it-all-together","level":2,"title":"Putting It All Together","text":"<p>A typical pipeline from raw sessions to a browsable site:</p> <pre><code># Terminal: export and generate\nctx recall export --all\nctx journal site --serve\n</code></pre> <pre><code># AI assistant: normalize and enrich\n/ctx-journal-normalize\n/ctx-journal-enrich-all\n</code></pre> <pre><code># Terminal: rebuild with enrichments\nctx journal site --serve\n</code></pre> <p>If your project includes <code>Makefile.ctx</code> (deployed by <code>ctx init</code>), use <code>make journal</code> to combine export and rebuild stages. Then normalize and enrich inside Claude Code, then <code>make journal</code> again to pick up enrichments.</p>","path":["Browsing and Enriching Past Sessions"],"tags":[]},{"location":"recipes/session-archaeology/#tips","level":2,"title":"Tips","text":"<ul> <li>Start with <code>/ctx-recall</code> inside your AI assistant. If you want to quickly check what happened in a recent session without leaving your editor, <code>/ctx-recall</code> lets you browse interactively without exporting.</li> <li>Large sessions may be split automatically. Sessions with 200+ messages can be split into multiple parts (<code>session-abc123.md</code>, <code>session-abc123-p2.md</code>, <code>session-abc123-p3.md</code>) with navigation links between them. The site generator can handle this.</li> <li>Suggestion sessions can be separated. Claude Code can generate short suggestion sessions for autocomplete. These may appear under a separate section in the site index, so they do not clutter your main session list.</li> <li>Your agent is a good session browser. You do not need to remember slugs, dates, or flags. Ask \"what did we do yesterday?\" or \"find the session about Redis\"  and it can map the question to recall commands.</li> </ul> <p>Journal files are sensitive</p> <p>Journal files MUST be <code>.gitignore</code>d.</p> <p>Session transcripts can contain sensitive data such as file contents, commands, error messages with stack traces, and potentially API keys.</p> <p>Add <code>.context/journal/</code> and <code>.context/journal-site/</code> to your <code>.gitignore</code>.</p>","path":["Browsing and Enriching Past Sessions"],"tags":[]},{"location":"recipes/session-archaeology/#next-up","level":2,"title":"Next Up","text":"<p>Running an Unattended AI Agent: Set up an AI agent that works through tasks overnight without you at the keyboard.</p>","path":["Browsing and Enriching Past Sessions"],"tags":[]},{"location":"recipes/session-archaeology/#see-also","level":2,"title":"See Also","text":"<ul> <li>The Complete Session: where session saving fits in the daily workflow</li> <li>Turning Activity into Content: generating blog posts from session history</li> <li>Session Journal: full documentation of the journal system</li> <li>CLI Reference: ctx recall: all recall subcommands and flags</li> <li>CLI Reference: ctx journal: site generation options</li> <li>CLI Reference: ctx serve: local serving options</li> <li>Context Files: the <code>.context/</code> directory structure</li> </ul>","path":["Browsing and Enriching Past Sessions"],"tags":[]},{"location":"recipes/session-lifecycle/","level":1,"title":"The Complete Session","text":"","path":["The Complete Session"],"tags":[]},{"location":"recipes/session-lifecycle/#the-problem","level":2,"title":"The Problem","text":"<p>\"What does a full ctx session look like start to finish?\"</p> <p>You have <code>ctx</code> installed and your <code>.context/</code> directory initialized, but the individual commands and skills feel disconnected.</p> <p>How do they fit together into a coherent workflow?</p> <p>This recipe walks through a complete session, from opening your editor to saving a snapshot before you close it, so you can see how each piece connects.</p>","path":["The Complete Session"],"tags":[]},{"location":"recipes/session-lifecycle/#commands-and-skills-used","level":2,"title":"Commands and Skills Used","text":"Tool Type Purpose <code>ctx status</code> CLI command Quick health check on context files <code>ctx agent</code> CLI command Load token-budgeted context packet <code>ctx session save</code> CLI command Save a session snapshot <code>ctx session list</code> CLI command List previous session snapshots <code>ctx session load</code> CLI command Load a previous session by index, date, or topic <code>/ctx-remember</code> Skill Recall project context with structured readback <code>/ctx-agent</code> Skill Load full context packet inside the assistant <code>/ctx-status</code> Skill Show context summary with commentary <code>/ctx-next</code> Skill Suggest what to work on with rationale <code>/ctx-commit</code> Skill Commit code and prompt for context capture <code>/ctx-reflect</code> Skill Structured reflection checkpoint <code>/ctx-save</code> Skill Save and enrich a session snapshot <code>/ctx-context-monitor</code> Skill Automatic context capacity monitoring","path":["The Complete Session"],"tags":[]},{"location":"recipes/session-lifecycle/#the-workflow","level":2,"title":"The Workflow","text":"<p>The session lifecycle has seven steps. You will not always use every step (for example, a quick bugfix might skip reflection, and a research session might skip committing) but the full arc looks like this:</p> <p>Load context &gt; Orient &gt; Pick a Task &gt; Work &gt; Commit &gt; Reflect &gt; Save a Snapshot</p>","path":["The Complete Session"],"tags":[]},{"location":"recipes/session-lifecycle/#step-1-load-context","level":3,"title":"Step 1: Load Context","text":"<p>Start every session by loading what you know. The fastest way is a single prompt:</p> <pre><code>Do you remember what we were working on?\n</code></pre> <p>This triggers the <code>/ctx-remember</code> skill. Behind the scenes, the assistant runs <code>ctx agent --budget 4000</code>, reads the files listed in the context packet (<code>TASKS.md</code>, <code>DECISIONS.md</code>, <code>LEARNINGS.md</code>, <code>CONVENTIONS.md</code>), checks <code>ctx session list --limit 3</code> for recent sessions, and then presents a structured readback:</p> <p>What is a Readback?</p> <p>A readback is a structured summary where the agent plays back what it knows:</p> <ul> <li>last session</li> <li>active tasks</li> <li>recent decisions</li> </ul> <p>This way, you can confirm it loaded the right context.</p> <p>The term \"readback\" comes from aviation, where pilots repeat instructions back to air traffic control to confirm they heard correctly.</p> <p>Same idea in <code>ctx</code>: The agent tells you what it \"thinks\" is going on, and you correct anything that's off before the work begins.</p> <ul> <li>Last session: topic, date, what was accomplished</li> <li>Active work: pending and in-progress tasks</li> <li>Recent context: 1-2 decisions or learnings that matter now</li> <li>Next step: suggestion or question about what to focus on</li> </ul> <p>The readback should feel like a recall, not a file system tour. If you see \"Let me check if there are files...\" instead of a confident summary, the context system is not loaded properly.</p> <p>As an alternative, if you want raw data instead of a readback, run <code>ctx status</code> in your terminal or invoke <code>/ctx-status</code> for a summarized health check showing file counts, token usage, and recent activity.</p>","path":["The Complete Session"],"tags":[]},{"location":"recipes/session-lifecycle/#step-2-orient","level":3,"title":"Step 2: Orient","text":"<p>After loading context, verify you understand the current state.</p> <pre><code>/ctx-status\n</code></pre> <p>The status output shows which context files are populated, how many tokens they consume, and which files were recently modified. Look for:</p> <ul> <li>Empty core files: <code>TASKS.md</code> or <code>CONVENTIONS.md</code> with no content means   the context is sparse</li> <li>High token count (over 30k): the context is bloated and might   need <code>ctx compact</code></li> <li>No recent activity: files may be stale and need updating</li> </ul> <p>If the status looks healthy and the readback from Step 1 gave you enough context, skip ahead.</p> <p>If something seems off (stale tasks, missing decisions...), spend a minute reading the relevant file before proceeding.</p>","path":["The Complete Session"],"tags":[]},{"location":"recipes/session-lifecycle/#step-3-pick-what-to-work-on","level":3,"title":"Step 3: Pick What to Work On","text":"<p>With context loaded, choose a task. You can pick one yourself, or ask the assistant to recommend:</p> <pre><code>/ctx-next\n</code></pre> <p>The skill reads <code>TASKS.md</code>, checks recent sessions to avoid re-suggesting completed work, and presents 1-3 ranked recommendations with rationale.</p> <p>It prioritizes in-progress tasks over new starts (finishing is better than starting), respects explicit priority tags, and favors momentum: continuing a thread from a recent session is cheaper than context-switching.</p> <p>If you already know what you want to work on, state it directly:</p> <pre><code>Let's work on the session enrichment feature.\n</code></pre>","path":["The Complete Session"],"tags":[]},{"location":"recipes/session-lifecycle/#step-4-do-the-work","level":3,"title":"Step 4: Do the Work","text":"<p>This is the main body of the session: write code, fix bugs, refactor, research—whatever the task requires.</p> <p>During this phase, a few <code>ctx</code>-specific patterns help:</p> <p>Check decisions before choosing: when you face a design choice, check if a prior decision covers it.</p> <pre><code>Is this consistent with our decisions?\n</code></pre> <p>Constrain scope: keep the assistant focused on the task at hand.</p> <pre><code>Only change files in internal/cli/session/. Nothing else.\n</code></pre> <p>Use <code>/ctx-implement</code> for multistep plans: if the task has multiple steps, this skill executes them one at a time with build/test verification between each step.</p> <p>Context monitoring runs automatically: the <code>/ctx-context-monitor</code> skill is triggered by a hook at adaptive intervals. Early in a session it stays silent. After 16+ prompts it starts monitoring, and past 30 prompts it checks frequently. If context capacity is running high, it will suggest saving unsaved work. You typically do not need to invoke this skill manually.</p>","path":["The Complete Session"],"tags":[]},{"location":"recipes/session-lifecycle/#step-5-commit-with-context","level":3,"title":"Step 5: Commit with Context","text":"<p>When the work is ready, use the context-aware commit instead of raw <code>git commit</code>:</p> <pre><code>/ctx-commit\n</code></pre> <p>As an alternative, you can ask the assistant \"can we commit this?\" and it will pick up the <code>/ctx-commit</code> skill for you.</p> <p>The skill runs a pre-commit build check (for Go projects, <code>go build</code>), reviews the staged changes, drafts a commit message focused on \"why\" rather than \"what\", and then commits.</p> <p>After the commit succeeds, it prompts you:</p> <p>Any context to capture?</p> <ul> <li>Decision: Did you make a design choice or trade-off?</li> <li>Learning: Did you hit a gotcha or discover something?</li> <li>Neither: No context to capture; we are done.</li> </ul> <p>If you made a decision, the skill records it with <code>ctx add decision</code>. If you learned something, it records it with <code>ctx add learning</code> including context, lesson, and application fields. This is the bridge between committing code and remembering why the code looks the way it does.</p> <p>If source code changed in areas that affect documentation, the skill also offers to check for doc drift.</p> <p>The Agent May Recommend Committing</p> <p>You do not always need to invoke <code>/ctx-commit</code> explicitly.</p> <p>After a commit, the agent may proactively offer to capture context:</p> <p>\"We just made a trade-off there. Want me to record it as a decision?\"</p> <p>This is normal: The Agent Playbook encourages persisting at milestones, and a commit is a natural milestone.</p>","path":["The Complete Session"],"tags":[]},{"location":"recipes/session-lifecycle/#step-6-reflect","level":3,"title":"Step 6: Reflect","text":"<p>At natural breakpoints (after finishing a feature, resolving a complex bug, or before switching tasks) pause to reflect:</p> <pre><code>/ctx-reflect\n</code></pre> <p>The skill works through a checklist: learnings discovered, decisions made, tasks completed or created, and whether the session is worth a full snapshot. It then presents a summary with specific items to persist, each with the exact command to run:</p> <p>I would suggest persisting:</p> <ul> <li>Learning: <code>$PPID</code> in PreToolUse hooks resolves to the Claude Code PID   <code>ctx add learning --context \"...\" --lesson \"...\" --application \"...\"</code></li> <li>Task: mark \"Add cooldown to ctx agent\" as done</li> <li>Decision: tombstone-based cooldown with 10m default   <code>ctx add decision \"...\"</code></li> </ul> <p>Want me to persist any of these?</p> <p>The skill asks before persisting anything. You choose what to keep.</p> <p>Not every commit needs reflection. A typo fix does not. But when you have been debugging for an hour and finally understand the root cause, that is worth a reflection checkpoint.</p> <p>Agents Reflect at Milestones</p> <p>Agents often reflect without explicit invocation.</p> <p>After completing a significant piece of work, the agent may naturally surface items worth persisting:</p> <p>\"We discovered that <code>$PPID</code> resolves differently inside hooks. Should I save that as a learning?\"</p> <p>This is the agent following the Work-Reflect-Persist cycle from the Agent Playbook.</p> <p>You do not need to say <code>/ctx-reflect</code> for this to happen; the agent treats milestones as reflection triggers on its own.</p>","path":["The Complete Session"],"tags":[]},{"location":"recipes/session-lifecycle/#step-7-save-a-snapshot","level":3,"title":"Step 7: Save a Snapshot","text":"<p>Before ending the session, save a snapshot that a future session can load:</p> <pre><code>/ctx-save auth-refactor\n</code></pre> <p>This runs <code>ctx session save</code> with the topic you provide, then enriches the saved file by replacing placeholder sections with real content:</p> <ul> <li>Summary: what was built or fixed, key decisions, problems encountered</li> <li>Tasks for Next Session: concrete items to pick up next time, in checkbox format</li> <li>Files Modified: list of changed files with brief descriptions</li> </ul> <p>The snapshot is written to <code>.context/sessions/YYYY-MM-DD-HHMMSS-&lt;topic&gt;.md</code>.</p> <p>Future sessions can find it with <code>ctx session list</code> and load it with <code>ctx session load</code>.</p> <p>To verify the save worked:</p> <pre><code>ctx session list --limit 3\n</code></pre> <p>Be Conversational</p> <p>You do not need to say <code>/ctx-save</code> verbatim.</p> <p>Phrases like \"let's wrap up\", \"save our progress\", or \"I'm done for today\" will trigger the full save flow.</p> <p>The agent will reflect on what happened, persist outstanding learnings and decisions, and save the session snapshot in one pass.</p>","path":["The Complete Session"],"tags":[]},{"location":"recipes/session-lifecycle/#conversational-session-flow","level":2,"title":"Conversational Session Flow","text":"<p>The steps above describe the mechanics. In practice, a session with a <code>ctx</code>-aware agent feels more like a conversation than a command sequence.</p> <p>The agent knows the lifecycle and moves through it naturally, often without explicit invocation. Here is a realistic example:</p> <p>You: Do you remember what we were working on?</p> <p>Agent (loads context silently, presents structured readback):</p> <p>Last session (Feb 7, caching-layer): we implemented the in-memory cache with TTL expiration and wrote tests for the eviction policy. </p> <p>You have 3 pending tasks; the biggest one is adding Redis as a backend.</p> <p>Recent decision: we chose LRU over LFU because the access pattern is mostly recency-based.</p> <p>Want to continue with the Redis backend, or tackle something else?</p> <p>You: Let's work on the Redis caching backend.</p> <p>Agent (picks up the task, begins implementation):</p> <p>Got it. I see the task in TASKS.md: \"Add Redis backend for cache layer.\"</p> <p>I will start with the connection pool setup. Only touching <code>internal/cache/redis/</code> for now.</p> <p>(The agent works... writes code, runs tests, iterates.)</p> <p>Agent (after implementing the connection pool and choosing a retry strategy):</p> <p>The connection pool is working. I went with exponential backoff with jitter for retries instead of fixed intervals; it handles thundering herd better under reconnection storms. That is a design choice worth recording. </p> <p>Want me to save it as a decision?</p> <p>You: Yes, go ahead.</p> <p>Agent:</p> <p>Done. Added to DECISIONS.md: \"Exponential backoff with jitter for Redis reconnection, to avoid thundering herd on pool recovery.\"</p> <p>(More work happens... the agent implements the cache read/write paths.)</p> <p>You: What else did we learn during this session?</p> <p>Agent:</p> <p>A few things worth capturing:</p> <ul> <li>Learning: Redis <code>SET</code> with <code>NX</code> and <code>PX</code> flags handles atomic   set-if-not-exists with TTL in a single call. No need for a separate   <code>EXPIRE</code> command. We initially did it in two calls and hit a race condition.</li> <li>Learning: The <code>go-redis</code> library's <code>PoolSize</code> default is 10 per CPU.   For our workload, explicit sizing at 20 was more predictable.</li> <li>Task update: The connection pool subtask is done; the read/write path   is implemented but needs integration tests.</li> </ul> <p>Want me to persist these?</p> <p>You: Yes. And let's wrap up.</p> <p>Agent (reflects, persists, saves... all in one flow):</p> <p>Persisted:</p> <ul> <li>2 learnings added to LEARNINGS.md</li> <li>Marked \"connection pool setup\" done in TASKS.md</li> <li>Added \"write integration tests for Redis cache\" as a new task</li> </ul> <p>Saving session snapshot as <code>redis-cache-backend</code>...</p> <p>Session saved to <code>.context/sessions/2026-02-09-163045-redis-cache-backend.md</code> with summary, decisions, and next-session tasks. You are good to close.</p> <p>Notice What Happened</p> <p>In the above workflow, the user never typed <code>/ctx-reflect</code>, <code>/ctx-save</code>, or <code>ctx add learning</code>.</p> <p>The agent moved through Load, Orient, Pick, Work, Commit, Reflect, and Save driven by natural conversation.</p> <p>\"Let's wrap up\" was enough to trigger the full reflect-and-save flow.</p> <p>The agent surfaced persist-worthy items at milestones: after a design choice, after discovering a gotcha—without waiting to be asked.</p> <p>This is the intended experience. </p> <p>The commands and skills still exist for when you want precise control, but  the agent is a proactive partner in the lifecycle, not a passive executor  of slash commands.</p>","path":["The Complete Session"],"tags":[]},{"location":"recipes/session-lifecycle/#putting-it-all-together","level":2,"title":"Putting It All Together","text":"<p>Quick-reference checklist for a complete session:</p> <ul> <li> Load: \"Do you remember?\" or <code>/ctx-remember</code></li> <li> Orient: <code>/ctx-status</code>: check file health and token usage</li> <li> Pick: <code>/ctx-next</code>: choose what to work on</li> <li> Work: implement, test, iterate (scope with \"only change X\")</li> <li> Commit: <code>/ctx-commit</code>: commit and capture decisions/learnings</li> <li> Reflect: <code>/ctx-reflect</code>: identify what to persist (at milestones)</li> <li> Save: <code>/ctx-save &lt;topic&gt;</code>: snapshot for the next session</li> </ul> <p>Conversational equivalents: you can drive the same lifecycle with plain language:</p> Step Slash command Natural language Load <code>/ctx-remember</code> \"Do you remember?\" / \"What were we working on?\" Orient <code>/ctx-status</code> \"How's our context looking?\" Pick <code>/ctx-next</code> \"What should we work on?\" / \"Let's do the caching task\" Work -- \"Only change files in internal/cache/\" Commit <code>/ctx-commit</code> \"Commit this\" / \"Ship it\" Reflect <code>/ctx-reflect</code> \"What did we learn?\" / (agent offers at milestones) Save <code>/ctx-save &lt;topic&gt;</code> \"Let's wrap up\" / \"Save our progress\" / \"I'm done\" <p>The agent understands both columns.</p> <p>In practice, most sessions use a mix:</p> <ul> <li>explicit commands when you want precision</li> <li>natural language when you want flow and agentic autonomy</li> </ul> <p>The agent will also initiate steps on its own (particularly \"Reflect\" and \"Save\") when it recognizes a milestone.</p> <p>Short sessions (quick bugfix) might only use: Load, Work, Commit,  Save.</p> <p>Long sessions should Reflect after each major milestone and Save at  least once before ending.</p>","path":["The Complete Session"],"tags":[]},{"location":"recipes/session-lifecycle/#tips","level":2,"title":"Tips","text":"<p>Save early if context is running low. The <code>/ctx-context-monitor</code> skill will warn you when capacity is high, but do not wait for the warning. If you have been working for a while and have unsaved learnings, save proactively.</p> <p>Use descriptive topic names. <code>ctx session save \"auth-refactor\"</code> is findable later. <code>ctx session save</code> defaults to \"manual save\", which is harder to locate among many sessions.</p> <p>Load previous sessions by topic. If you need context from a prior session, <code>ctx session load auth</code> will match by keyword. You do not need to remember the exact date or index number.</p> <p>Reflection is optional, saving is not. You can skip <code>/ctx-reflect</code> for small changes, but always <code>/ctx-save</code> before ending a session where you did meaningful work. The snapshot is what the next session loads.</p> <p>Let the hook handle context loading. The <code>PreToolUse</code> hook runs <code>ctx agent</code> automatically with a cooldown, so context loads on first tool use without you asking. The <code>/ctx-remember</code> prompt at session start is for your benefit (to get a readback you can verify), not because the assistant needs it.</p> <p>The agent is a proactive partner, not a passive tool. A <code>ctx</code>-aware agent follows the Agent Playbook: it watches for milestones (completed tasks, design decisions, discovered gotchas) and offers to persist them without being asked. If you finish a tricky debugging session, it may say \"That root cause is worth saving as a learning. Want me to record it?\" before you think to ask. This is by design.</p>","path":["The Complete Session"],"tags":[]},{"location":"recipes/session-lifecycle/#next-up","level":2,"title":"Next Up","text":"<p>Tracking Work Across Sessions: Add, prioritize, complete, and archive tasks across sessions.</p>","path":["The Complete Session"],"tags":[]},{"location":"recipes/session-lifecycle/#see-also","level":2,"title":"See Also","text":"<ul> <li>CLI Reference: full documentation for all <code>ctx</code> commands</li> <li>Prompting Guide: effective prompts for ctx-enabled projects</li> <li>Tracking Work Across Sessions: deep dive on task management</li> <li>Persisting Decisions, Learnings, and Conventions:   deep dive on knowledge capture</li> <li>Detecting and Fixing Drift: keeping context files accurate</li> </ul>","path":["The Complete Session"],"tags":[]},{"location":"recipes/task-management/","level":1,"title":"Tracking Work Across Sessions","text":"","path":["Tracking Work Across Sessions"],"tags":[]},{"location":"recipes/task-management/#problem","level":2,"title":"Problem","text":"<p>You have work that spans multiple sessions. Tasks get added during one session, partially finished in another, and completed days later.</p> <p>Without a system, follow-up items fall through the cracks, priorities drift, and you lose track of what was done versus what still needs doing. <code>TASKS.md</code> grows cluttered with completed checkboxes that obscure the remaining work.</p> <p>How do you manage work items that span multiple sessions without losing context?</p>","path":["Tracking Work Across Sessions"],"tags":[]},{"location":"recipes/task-management/#commands-and-skills-used","level":2,"title":"Commands and Skills Used","text":"Tool Type Purpose <code>ctx add task</code> Command Add a new task to TASKS.md <code>ctx complete</code> Command Mark a task as done by number or text <code>ctx tasks snapshot</code> Command Create a point-in-time backup of TASKS.md <code>ctx tasks archive</code> Command Move completed tasks to archive file <code>/ctx-add-task</code> Skill AI-assisted task creation with validation <code>/ctx-archive</code> Skill AI-guided archival with safety checks <code>/ctx-next</code> Skill Pick what to work on based on priorities","path":["Tracking Work Across Sessions"],"tags":[]},{"location":"recipes/task-management/#the-workflow","level":2,"title":"The Workflow","text":"","path":["Tracking Work Across Sessions"],"tags":[]},{"location":"recipes/task-management/#step-1-add-tasks-with-priorities","level":3,"title":"Step 1: Add Tasks with Priorities","text":"<p>Every piece of follow-up work gets a task. Use <code>ctx add task</code> from the terminal or <code>/ctx-add-task</code> from your AI assistant. Tasks should start with a verb and be specific enough that someone unfamiliar with the session could act on them.</p> <pre><code># High-priority bug found during code review\nctx add task \"Fix race condition in session cooldown\" --priority high\n\n# Medium-priority feature work\nctx add task \"Add --format json flag to ctx status for CI integration\" --priority medium\n\n# Low-priority cleanup\nctx add task \"Remove deprecated --raw flag from ctx load\" --priority low\n</code></pre> <p>The <code>/ctx-add-task</code> skill validates your task before recording it. It checks that the description is actionable, not a duplicate, and specific enough for someone else to pick up.</p> <p>If you say \"fix the bug,\" it will ask you to clarify which bug and where.</p> <p>Tasks Are Often Created Proactively</p> <p>In practice, many tasks are created proactively by the agent rather than by explicit CLI commands.</p> <p>After completing a feature, the agent will often identify follow-up work: tests, docs, edge cases, error handling, and offer to add them as tasks.</p> <p>You do not need to dictate <code>ctx add task</code> commands; the agent picks up on work context and suggests tasks naturally.</p>","path":["Tracking Work Across Sessions"],"tags":[]},{"location":"recipes/task-management/#step-2-organize-with-phase-sections","level":3,"title":"Step 2: Organize with Phase Sections","text":"<p>Tasks live in phase sections inside <code>TASKS.md</code>.</p> <p>Phases provide logical groupings that preserve order and enable replay.</p> <p>A task does not move between sections. It stays in its phase permanently, and status is tracked via checkboxes and inline tags.</p> <pre><code>## Phase 1: Core CLI\n\n- [x] Implement ctx add command `#done:2026-02-01-143022`\n- [x] Implement ctx complete command `#done:2026-02-03-091544`\n- [ ] Add --section flag to ctx add task `#priority:medium`\n\n## Phase 2: AI Integration\n\n- [ ] Implement ctx agent cooldown `#priority:high` `#in-progress`\n- [ ] Add ctx watch XML parsing `#priority:medium`\n  - Blocked by: Need to finalize agent output format\n\n## Backlog\n\n- [ ] Performance optimization for large TASKS.md files `#priority:low`\n- [ ] Add metrics dashboard to ctx status `#priority:deferred`\n</code></pre> <p>Use <code>--section</code> when adding a task to a specific phase:</p> <pre><code>ctx add task \"Add ctx watch XML parsing\" --priority medium --section \\\n    \"Phase 2: AI Integration\"\n</code></pre> <p>Without <code>--section</code>, the task is inserted before the first unchecked task in TASKS.md.</p>","path":["Tracking Work Across Sessions"],"tags":[]},{"location":"recipes/task-management/#step-3-pick-what-to-work-on","level":3,"title":"Step 3: Pick What to Work On","text":"<p>At the start of a session, or after finishing a task, use <code>/ctx-next</code> to get prioritized recommendations. </p> <p>The skill reads <code>TASKS.md</code>, checks recent sessions, and ranks candidates using  explicit priority, blocking status, in-progress state, momentum from  recent work, and phase order.</p> <p>You can also ask naturally: \"what should we work on?\" or \"what's the highest priority right now?\"</p> <pre><code>/ctx-next\n</code></pre> <p>The output looks like this:</p> <pre><code>**1. Implement ctx agent cooldown** `#priority:high`\n\n    Still in-progress from yesterday's session. The tombstone file approach is\n    half-built. Finishing is cheaper than context-switching.\n\n**2. Add --section flag to ctx add task** `#priority:medium`\n\n    Last Phase 1 item. Quick win that unblocks organized task entry.\n\n---\n\n*Based on 8 pending tasks across 3 phases.\n\nLast session: agent-cooldown (2026-02-06).*\n</code></pre> <p>In-progress tasks almost always come first: </p> <p>Finishing existing work takes priority over starting new work.</p>","path":["Tracking Work Across Sessions"],"tags":[]},{"location":"recipes/task-management/#step-4-complete-tasks","level":3,"title":"Step 4: Complete Tasks","text":"<p>When a task is done, mark it complete by number or partial text match:</p> <pre><code># By task number (as shown in TASKS.md)\nctx complete 3\n\n# By partial text match\nctx complete \"agent cooldown\"\n</code></pre> <p>The task's checkbox changes from <code>[ ]</code> to <code>[x]</code> and a <code>#done</code> timestamp is added. Tasks are never deleted: they stay in their phase section so history is preserved.</p> <p>Be Conversational</p> <p>You rarely need to run <code>ctx complete</code> yourself during an interactive session.</p> <p>When you say something like \"the rate limiter is done\" or \"we finished that,\" the agent marks the task complete and moves on to suggesting what is next.</p> <p>The CLI commands are most useful for manual housekeeping, scripted workflows, or when you want precision.</p>","path":["Tracking Work Across Sessions"],"tags":[]},{"location":"recipes/task-management/#step-5-snapshot-before-risky-changes","level":3,"title":"Step 5: Snapshot Before Risky Changes","text":"<p>Before a major refactor or any change that might break things, snapshot your current task state. This creates a copy of TASKS.md in <code>.context/archive/</code> without modifying the original.</p> <pre><code># Default snapshot\nctx tasks snapshot\n\n# Named snapshot (recommended before big changes)\nctx tasks snapshot \"before-refactor\"\n</code></pre> <p>This creates a file like <code>.context/archive/tasks-before-refactor-2026-02-08-1430.md</code>. If the refactor goes sideways, and you need to confirm what the task state looked like before you started, the snapshot is there.</p> <p>Snapshots are cheap: Take them before any change you might want to undo or review later.</p>","path":["Tracking Work Across Sessions"],"tags":[]},{"location":"recipes/task-management/#step-6-archive-when-tasksmd-gets-cluttered","level":3,"title":"Step 6: Archive When <code>TASKS.md</code> Gets Cluttered","text":"<p>After several sessions, <code>TASKS.md</code> accumulates completed tasks that make it hard to see what is still pending.</p> <p>Use <code>ctx tasks archive</code> to move all <code>[x]</code> items to a timestamped archive file.</p> <p>Start with a dry run to preview what will be moved:</p> <pre><code>ctx tasks archive --dry-run\n</code></pre> <p>Then archive:</p> <pre><code>ctx tasks archive\n</code></pre> <p>Completed tasks move to <code>.context/archive/tasks-2026-02-08.md</code>. Phase headers are preserved in the archive for traceability. Pending tasks (<code>[ ]</code>) remain in <code>TASKS.md</code>.</p> <p>The <code>/ctx-archive</code> skill adds two safety checks before archiving: it verifies that completed tasks are genuinely cluttering the view and that nothing was marked <code>[x]</code> prematurely.</p>","path":["Tracking Work Across Sessions"],"tags":[]},{"location":"recipes/task-management/#letting-the-agent-drive","level":2,"title":"Letting the Agent Drive","text":"<p>The steps above show the CLI commands for task management.</p> <p>In practice, most task management happens conversationally:</p> <p>An agent that has loaded the context files does not need you to type <code>ctx add task</code>. It tracks work naturally and offers the right operations.</p>","path":["Tracking Work Across Sessions"],"tags":[]},{"location":"recipes/task-management/#use-natural-language-instead-of-commands","level":3,"title":"Use Natural Language Instead of Commands","text":"<p>These conversational prompts replace explicit commands during interactive sessions:</p> Instead of typing... Just say... <code>ctx add task \"Write tests for X\"</code> \"We should add tests for this—track that?\" <code>/ctx-next</code> \"What should we work on?\" <code>ctx complete \"rate limiting\"</code> \"The rate limiter is done, what's next?\" <code>ctx tasks archive</code> \"TASKS.md is getting long, can you clean it up?\" <code>ctx add task ... &amp;&amp; ctx add task ...</code> \"Add follow-ups for what we just built.\" <p>The agent translates these into the right <code>ctx</code> operations behind the scenes.</p>","path":["Tracking Work Across Sessions"],"tags":[]},{"location":"recipes/task-management/#the-agent-creates-tasks-proactively","level":3,"title":"The Agent Creates Tasks Proactively","text":"<p>After completing a piece of work, the agent does not wait for you to dictate follow-up items. It identifies them from the work context and offers:</p> <p>Agent: \"I've finished implementing the rate limiter middleware. I noticed three follow-up items:</p> <ol> <li>Write integration tests for the rate limiter (the unit tests pass but    there's no end-to-end coverage)</li> <li>Add rate limit headers to API responses (X-RateLimit-Remaining, etc.)</li> <li>Document the rate limit configuration in the ops runbook</li> </ol> <p>Want me to add these as tasks?\"</p> <p>This is how an agent behaves once it has read the Agent Playbook.</p> <p>The playbook's \"Work, Reflect, Persist\" cycle means the agent asks itself after every milestone: Did I just complete a task? Did new work emerge?</p> <p>When the answer is yes, it acts.</p>","path":["Tracking Work Across Sessions"],"tags":[]},{"location":"recipes/task-management/#asking-the-agent-what-to-capture","level":3,"title":"Asking the Agent What to Capture","text":"<p>You don't always know what's worth persisting.</p> <p>Instead of reviewing the session yourself and typing specific commands, ask the agent to do the thinking:</p> You say What happens \"What tasks came out of this session?\" Agent reviews the work, identifies follow-ups, and offers to add them \"Are there any tasks, learnings, or decisions worth adding?\" Agent scans the full session for all three types and proposes a batch \"What should we remember from today?\" Agent surfaces everything persist-worthy—not just tasks \"Anything we should track before we move on?\" Agent checks for loose ends specific to the work just completed <p>This is especially powerful after long or exploratory sessions where multiple threads were touched. </p> <p>The agent has the full conversation in context and can spot follow-ups you  might miss:</p> <pre><code>You:   \"Are there any tasks, learnings, or decisions worth adding\n        from this session?\"\n\nAgent: \"Yes—here's what I'd suggest:\n\n  Tasks:\n  - Add retry logic to the webhook delivery (we discussed it when\n    the timeout test failed but never tracked it)\n  - Update the API docs to reflect the new rate limit headers\n\n  Learnings:\n  - net/http's default client has no timeout—we burned 15 minutes\n    on that before adding an explicit 30s timeout\n\n  Decisions:\n  - We chose token-bucket over sliding-window for rate limiting\n    because it handles bursts better and the library is simpler\n\n  Want me to add all of these?\"\n\nYou:   \"All of them.\"\n</code></pre> <p>The agent fills in structured fields from what it observed during the session. You get the same quality entries as if you typed verbose commands, without needing to remember what happened or how to format it.</p>","path":["Tracking Work Across Sessions"],"tags":[]},{"location":"recipes/task-management/#the-agent-completes-tasks-and-moves-on","level":3,"title":"The Agent Completes Tasks and Moves On","text":"<p>When you confirm that work is finished, or when the agent can see that it is, it marks the task done and suggests the next step:</p> <p>You: \"The cooldown logic is working now.\"</p> <p>Agent: \"Marked 'Implement ctx agent cooldown' as done. Your highest- priority remaining task is 'Add --section flag to ctx add task'.</p> <p>It's the last item in Phase 1 and a quick win. Want to start on that?\"</p> <p>The agent chains completion into next-task selection.</p> <p>One sentence from you triggers two operations.</p>","path":["Tracking Work Across Sessions"],"tags":[]},{"location":"recipes/task-management/#end-of-session-capture","level":3,"title":"End-of-Session Capture","text":"<p>At the end of a session, the agent reviews what happened and catches loose ends:</p> <p>You: \"I think we're good for today.\"</p> <p>Agent: \"Before we wrap up: during the middleware work you mentioned wanting to add metrics for rate limit hits. That never made it into TASKS.md.</p> <p>Want me to add it as a task so it's there next session?\"</p> <p>This is the proactive persistence model at work.</p> <p>The agent monitors the conversation for mentioned-but-not-tracked work and surfaces it before context is lost.</p>","path":["Tracking Work Across Sessions"],"tags":[]},{"location":"recipes/task-management/#a-conversational-session-example","level":3,"title":"A Conversational Session Example","text":"<p>Here is what task management looks like in a real session when the agent is driving:</p> <pre><code>You:   What's left to do?\nAgent: You have 5 pending tasks across 2 phases. The highest priority is\n       \"Implement ctx agent cooldown\"—it's marked in-progress from\n       yesterday and half-built. Want to pick that up?\n\nYou:   Yeah, let's finish it.\n       [... 20 minutes of implementation work ...]\n\nYou:   That's working. Tests pass.\nAgent: Nice. I'll mark \"Implement ctx agent cooldown\" as done.\n       I noticed two things from the implementation:\n       1. The tombstone file cleanup should happen on a timer, not just\n          at startup—want me to add that as a task?\n       2. We learned that file locks don't work reliably on NFS. I'll\n          add that to LEARNINGS.md.\n\nYou:   Yes to both. What's next?\nAgent: Added the cleanup task as high priority. Next up is \"Add --section\n       flag to ctx add task\"—last item in Phase 1. It should be\n       straightforward since the flag parsing pattern already exists\n       in the codebase. Ready?\n</code></pre> <p>It's All Conversational</p> <p>Notice what did not happen: The user never typed a <code>ctx</code> command.</p> <p>The agent handled task completion, follow-up creation, learning capture, and next-task selection—all from natural conversation.</p>","path":["Tracking Work Across Sessions"],"tags":[]},{"location":"recipes/task-management/#putting-it-together","level":2,"title":"Putting It Together","text":"<pre><code># Add a task\nctx add task \"Implement rate limiting for API endpoints\" --priority high\n\n# Add to a specific phase\nctx add task \"Write integration tests for rate limiter\" --section \"Phase 2\"\n\n# See what to work on\n# (from AI assistant) /ctx-next\n\n# Mark done by text\nctx complete \"rate limiting\"\n\n# Mark done by number\nctx complete 5\n\n# Snapshot before a risky refactor\nctx tasks snapshot \"before-middleware-rewrite\"\n\n# Archive completed tasks when the list gets long\nctx tasks archive --dry-run     # preview first\nctx tasks archive               # then archive\n</code></pre>","path":["Tracking Work Across Sessions"],"tags":[]},{"location":"recipes/task-management/#tips","level":2,"title":"Tips","text":"<ul> <li>Start tasks with a verb: \"Add,\" \"Fix,\" \"Implement,\" \"Investigate\":    not just a topic like \"Authentication.\"</li> <li>Include the why in the task description. Future sessions lack the context of   why you added the task. \"Add rate limiting\" is worse than \"Add rate limiting   to prevent abuse on the public API after the load test showed 10x traffic spikes.\"</li> <li>Use <code>#in-progress</code> sparingly. Only one or two tasks should carry this tag at   a time. If everything is in-progress, nothing is.</li> <li>Snapshot before, not after. The point of a snapshot is to capture the    state before a change, not to celebrate what you just finished.</li> <li>Archive regularly. Once completed tasks outnumber pending ones, it is time   to archive. A clean TASKS.md helps both you and your AI assistant focus.</li> <li>Never delete tasks. Mark them <code>[x]</code> (completed) or <code>[-]</code> (skipped with a   reason). Deletion breaks the audit trail.</li> <li>Trust the agent's task instincts. When the agent suggests follow-up items   after completing work, it is drawing on the full context of what just happened.</li> <li>Conversational prompts beat commands in interactive sessions. Saying   \"what should we work on?\" is faster and more natural than running <code>/ctx-next</code>.   Save explicit commands for scripts, CI, and unattended runs.</li> <li>Let the agent chain operations. A single statement like \"that's done, what's   next?\" can trigger completion, follow-up identification, and next-task   selection in one flow.</li> <li>Review proactive task suggestions before moving on. The best follow-ups come   from items spotted in-context right after the work completes.</li> </ul>","path":["Tracking Work Across Sessions"],"tags":[]},{"location":"recipes/task-management/#next-up","level":2,"title":"Next Up","text":"<p>Persisting Decisions, Learnings, and Conventions:  Capture the \"why\" behind your work so it survives across sessions.</p>","path":["Tracking Work Across Sessions"],"tags":[]},{"location":"recipes/task-management/#see-also","level":2,"title":"See Also","text":"<ul> <li>The Complete Session: full session lifecycle including   task management in context</li> <li>Persisting Decisions, Learnings, and Conventions:   capturing the \"why\" behind your work</li> <li>Detecting and Fixing Drift: keeping TASKS.md accurate over time</li> <li>CLI Reference: full documentation for <code>ctx add</code>, <code>ctx complete</code>, <code>ctx tasks</code></li> <li>Context Files: TASKS.md: format and conventions for TASKS.md</li> </ul>","path":["Tracking Work Across Sessions"],"tags":[]}]}